    desc = b' '.join(map(bytes.strip, block[b'lines']))
    colwidth = encoding.colwidth(block[b'optstr'])
    usablewidth = width - 1
    hanging = block[b'optstrwidth']
    initindent = b'%s%s  ' % (block[b'optstr'], b' ' * ((hanging - colwidth)))
    hangindent = b' ' * (encoding.colwidth(initindent) + 1)
    return b' %s\n' % (
        stringutil.wrap(
            desc, usablewidth, initindent=initindent, hangindent=hangindent
        )
    )


def formatblock(block, width):
    """Format a block according to width."""
    if width <= 0:
        width = 78
    indent = b' ' * block[b'indent']
    if block[b'type'] == b'admonition':
        admonition = _admonitiontitles[block[b'admonitiontitle']]
        if not block[b'lines']:
            return indent + admonition + b'\n'
        hang = len(block[b'lines'][-1]) - len(block[b'lines'][-1].lstrip())

        defindent = indent + hang * b' '
        text = b' '.join(map(bytes.strip, block[b'lines']))
        return b'%s\n%s\n' % (
            indent + admonition,
            stringutil.wrap(
                text, width=width, initindent=defindent, hangindent=defindent
            ),
        )
    if block[b'type'] == b'margin':
        return b'\n'
    if block[b'type'] == b'literal':
        indent += b'  '
        return indent + (b'\n' + indent).join(block[b'lines']) + b'\n'
    if block[b'type'] == b'section':
        underline = encoding.colwidth(block[b'lines'][0]) * block[b'underline']
        return b"%s%s\n%s%s\n" % (indent, block[b'lines'][0], indent, underline)
    if block[b'type'] == b'table':
        table = block[b'table']
        # compute column widths
        widths = [max([encoding.colwidth(e) for e in c]) for c in zip(*table)]
        text = b''
        span = sum(widths) + len(widths) - 1
        indent = b' ' * block[b'indent']
        hang = b' ' * (len(indent) + span - widths[-1])

        for row in table:
            l = []
            for w, v in zip(widths, row):
                pad = b' ' * (w - encoding.colwidth(v))
                l.append(v + pad)
            l = b' '.join(l)
            l = stringutil.wrap(
                l, width=width, initindent=indent, hangindent=hang
            )
            if not text and block[b'header']:
                text = l + b'\n' + indent + b'-' * (min(width, span)) + b'\n'
            else:
                text += l + b"\n"
        return text
    if block[b'type'] == b'definition':
        term = indent + block[b'lines'][0]
        hang = len(block[b'lines'][-1]) - len(block[b'lines'][-1].lstrip())
        defindent = indent + hang * b' '
        text = b' '.join(map(bytes.strip, block[b'lines'][1:]))
        return b'%s\n%s\n' % (
            term,
            stringutil.wrap(
                text, width=width, initindent=defindent, hangindent=defindent
            ),
        )
    subindent = indent
    if block[b'type'] == b'bullet':
        if block[b'lines'][0].startswith(b'| '):
            # Remove bullet for line blocks and add no extra
            # indentation.
            block[b'lines'][0] = block[b'lines'][0][2:]
        else:
            m = _bulletre.match(block[b'lines'][0])
            subindent = indent + m.end() * b' '
    elif block[b'type'] == b'field':
        key = block[b'key']
        subindent = indent + _fieldwidth * b' '
        if len(key) + 2 > _fieldwidth:
            # key too large, use full line width
            key = key.ljust(width)
        else:
            # key fits within field width
            key = key.ljust(_fieldwidth)
        block[b'lines'][0] = key + block[b'lines'][0]
    elif block[b'type'] == b'option':
        return formatoption(block, width)

    text = b' '.join(map(bytes.strip, block[b'lines']))
    return (
        stringutil.wrap(
            text, width=width, initindent=indent, hangindent=subindent
        )
        + b'\n'
    )


def formathtml(blocks):
    """Format RST blocks as HTML"""

    out = []
    headernest = b''
    listnest = []

    def escape(s):
        return url.escape(s, True)

    def openlist(start, level):
        if not listnest or listnest[-1][0] != start:
            listnest.append((start, level))
            out.append(b'<%s>\n' % start)

    blocks = [b for b in blocks if b[b'type'] != b'margin']

    for pos, b in enumerate(blocks):
        btype = b[b'type']
        level = b[b'indent']
        lines = b[b'lines']

        if btype == b'admonition':
            admonition = escape(_admonitiontitles[b[b'admonitiontitle']])
            text = escape(b' '.join(map(bytes.strip, lines)))
            out.append(b'<p>\n<b>%s</b> %s\n</p>\n' % (admonition, text))
        elif btype == b'paragraph':
            out.append(b'<p>\n%s\n</p>\n' % escape(b'\n'.join(lines)))
        elif btype == b'margin':
            pass
        elif btype == b'literal':
            out.append(b'<pre>\n%s\n</pre>\n' % escape(b'\n'.join(lines)))
        elif btype == b'section':
            i = b[b'underline']
            if i not in headernest:
                headernest += i
            level = headernest.index(i) + 1
            out.append(b'<h%d>%s</h%d>\n' % (level, escape(lines[0]), level))
        elif btype == b'table':
            table = b[b'table']
            out.append(b'<table>\n')
            for row in table:
                out.append(b'<tr>')
                for v in row:
                    out.append(b'<td>')
                    out.append(escape(v))
                    out.append(b'</td>')
                    out.append(b'\n')
                out.pop()
                out.append(b'</tr>\n')
            out.append(b'</table>\n')
        elif btype == b'definition':
            openlist(b'dl', level)
            term = escape(lines[0])
            text = escape(b' '.join(map(bytes.strip, lines[1:])))
            out.append(b' <dt>%s\n <dd>%s\n' % (term, text))
        elif btype == b'bullet':
            bullet, head = lines[0].split(b' ', 1)
            if bullet in (b'*', b'-'):
                openlist(b'ul', level)
            else:
                openlist(b'ol', level)
            out.append(b' <li> %s\n' % escape(b' '.join([head] + lines[1:])))
        elif btype == b'field':
            openlist(b'dl', level)
            key = escape(b[b'key'])
            text = escape(b' '.join(map(bytes.strip, lines)))
            out.append(b' <dt>%s\n <dd>%s\n' % (key, text))
        elif btype == b'option':
            openlist(b'dl', level)
            opt = escape(b[b'optstr'])
            desc = escape(b' '.join(map(bytes.strip, lines)))
            out.append(b' <dt>%s\n <dd>%s\n' % (opt, desc))

        # close lists if indent level of next block is lower
        if listnest:
            start, level = listnest[-1]
            if pos == len(blocks) - 1:
                out.append(b'</%s>\n' % start)
                listnest.pop()
            else:
                nb = blocks[pos + 1]
                ni = nb[b'indent']
                if ni < level or (
                    ni == level
                    and nb[b'type'] not in b'definition bullet field option'
                ):
                    out.append(b'</%s>\n' % start)
                    listnest.pop()

    return b''.join(out)


def parse(text, indent=0, keep=None, admonitions=None):
    """Parse text into a list of blocks"""
    blocks = findblocks(text)
    for b in blocks:
        b[b'indent'] += indent
    blocks = findliteralblocks(blocks)
    blocks = findtables(blocks)
    blocks, pruned = prunecontainers(blocks, keep or [])
    blocks = findsections(blocks)
    blocks = inlineliterals(blocks)
    blocks = hgrole(blocks)
    blocks = splitparagraphs(blocks)
    blocks = updatefieldlists(blocks)
    blocks = updateoptionlists(blocks)
    blocks = findadmonitions(blocks, admonitions=admonitions)
    blocks = addmargins(blocks)
    blocks = prunecomments(blocks)
    return blocks, pruned


def formatblocks(blocks, width):
    text = b''.join(formatblock(b, width) for b in blocks)
    return text


def formatplain(blocks, width):
    """Format parsed blocks as plain text"""
    return b''.join(formatblock(b, width) for b in blocks)


def format(text, width=80, indent=0, keep=None, style=b'plain', section=None):
    """Parse and format the text according to width."""
    blocks, pruned = parse(text, indent, keep or [])
    if section:
        blocks = filtersections(blocks, section)
    if style == b'html':
        return formathtml(blocks)
    else:
        return formatplain(blocks, width=width)


def filtersections(blocks, section):
    """Select parsed blocks under the specified section

    The section name is separated by a dot, and matches the suffix of the
    full section path.
    """
    parents = []
    sections = _getsections(blocks)
    blocks = []
    i = 0
    lastparents = []
    synthetic = []
    collapse = True
    while i < len(sections):
        path, nest, b = sections[i]
        del parents[nest:]
        parents.append(i)
        if path == section or path.endswith(b'.' + section):
            if lastparents != parents:
                llen = len(lastparents)
                plen = len(parents)
                if llen and llen != plen:
                    collapse = False
                s = []
                for j in range(3, plen - 1):
                    parent = parents[j]
                    if j >= llen or lastparents[j] != parent:
                        s.append(len(blocks))
                        sec = sections[parent][2]
                        blocks.append(sec[0])
                        blocks.append(sec[-1])
                if s:
                    synthetic.append(s)

            lastparents = parents[:]
            blocks.extend(b)

            ## Also show all subnested sections
            while i + 1 < len(sections) and sections[i + 1][1] > nest:
                i += 1
                blocks.extend(sections[i][2])
        i += 1
    if collapse:
        synthetic.reverse()
        for s in synthetic:
            path = [blocks[syn][b'lines'][0] for syn in s]
            real = s[-1] + 2
            realline = blocks[real][b'lines']
            realline[0] = b'"%s"' % b'.'.join(path + [realline[0]]).replace(
                b'"', b''
            )
            del blocks[s[0] : real]

    return blocks


def _getsections(blocks):
    '''return a list of (section path, nesting level, blocks) tuples'''
    nest = b""
    names = ()
    secs = []

    def getname(b):
        if b[b'type'] == b'field':
            x = b[b'key']
        else:
            x = b[b'lines'][0]
        x = encoding.lower(x).strip(b'"')
        if b'(' in x:
            x = x.split(b'(')[0]
        return x

    for b in blocks:
        if b[b'type'] == b'section':
            i = b[b'underline']
            if i not in nest:
                nest += i
            level = nest.index(i) + 1
            nest = nest[:level]
            names = names[:level] + (getname(b),)
            secs.append((b'.'.join(names), level, [b]))
        elif b[b'type'] in (b'definition', b'field'):
            i = b' '
            if i not in nest:
                nest += i
            level = nest.index(i) + 1
            nest = nest[:level]
            for i in range(1, len(secs) + 1):
                sec = secs[-i]
                if sec[1] < level:
                    break
                siblings = [a for a in sec[2] if a[b'type'] == b'definition']
                if siblings:
                    siblingindent = siblings[-1][b'indent']
                    indent = b[b'indent']
                    if siblingindent < indent:
                        level += 1
                        break
                    elif siblingindent == indent:
                        level = sec[1]
                        break
            names = names[:level] + (getname(b),)
            secs.append((b'.'.join(names), level, [b]))
        else:
            if not secs:
                # add an initial empty section
                secs = [(b'', 0, [])]
            if b[b'type'] != b'margin':
                pointer = 1
                bindent = b[b'indent']
                while pointer < len(secs):
                    section = secs[-pointer][2][0]
                    if section[b'type'] != b'margin':
                        sindent = section[b'indent']
                        if len(section[b'lines']) > 1:
                            sindent += len(section[b'lines'][1]) - len(
                                section[b'lines'][1].lstrip(b' ')
                            )
                        if bindent >= sindent:
                            break
                    pointer += 1
                if pointer > 1:
                    blevel = secs[-pointer][1]
                    if section[b'type'] != b[b'type']:
                        blevel += 1
                    secs.append((b'', blevel, []))
            secs[-1][2].append(b)
    return secs


def maketable(data, indent=0, header=False):
    '''Generate an RST table for the given table data as a list of lines'''

    widths = [max(encoding.colwidth(e) for e in c) for c in zip(*data)]
    indent = b' ' * indent
    div = indent + b' '.join(b'=' * w for w in widths) + b'\n'

    out = [div]
    for row in data:
        l = []
        for w, v in zip(widths, row):
            if b'\n' in v:
                # only remove line breaks and indentation, long lines are
                # handled by the next tool
                v = b' '.join(e.lstrip() for e in v.split(b'\n'))
            pad = b' ' * (w - encoding.colwidth(v))
            l.append(v + pad)
        out.append(indent + b' '.join(l) + b"\n")
    if header and len(data) > 1:
        out.insert(2, div)
    out.append(div)
    return out
                                                                                                                                                                                                                                                                                                                                                                                                                                                           usr/lib/python3/dist-packages/mercurial/namespaces.py                                               0000644 0000000 0000000 00000020145 14355257011 021427  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        from .i18n import _
from . import (
    registrar,
    templatekw,
    util,
)


def tolist(val):
    """
    a convenience method to return an empty list instead of None
    """
    if val is None:
        return []
    else:
        return [val]


class namespaces:
    """provides an interface to register and operate on multiple namespaces. See
    the namespace class below for details on the namespace object.

    """

    _names_version = 0

    def __init__(self):
        self._names = util.sortdict()
        columns = templatekw.getlogcolumns()

        # we need current mercurial named objects (bookmarks, tags, and
        # branches) to be initialized somewhere, so that place is here
        bmknames = lambda repo: repo._bookmarks.keys()
        bmknamemap = lambda repo, name: tolist(repo._bookmarks.get(name))
        bmknodemap = lambda repo, node: repo.nodebookmarks(node)
        n = namespace(
            b"bookmarks",
            templatename=b"bookmark",
            logfmt=columns[b'bookmark'],
            listnames=bmknames,
            namemap=bmknamemap,
            nodemap=bmknodemap,
            builtin=True,
        )
        self.addnamespace(n)

        tagnames = lambda repo: [t for t, n in repo.tagslist()]
        tagnamemap = lambda repo, name: tolist(repo._tagscache.tags.get(name))
        tagnodemap = lambda repo, node: repo.nodetags(node)
        n = namespace(
            b"tags",
            templatename=b"tag",
            logfmt=columns[b'tag'],
            listnames=tagnames,
            namemap=tagnamemap,
            nodemap=tagnodemap,
            deprecated={b'tip'},
            builtin=True,
        )
        self.addnamespace(n)

        bnames = lambda repo: repo.branchmap().keys()
        bnamemap = lambda repo, name: tolist(repo.branchtip(name, True))
        bnodemap = lambda repo, node: [repo[node].branch()]
        n = namespace(
            b"branches",
            templatename=b"branch",
            logfmt=columns[b'branch'],
            listnames=bnames,
            namemap=bnamemap,
            nodemap=bnodemap,
            builtin=True,
        )
        self.addnamespace(n)

    def __getitem__(self, namespace):
        """returns the namespace object"""
        return self._names[namespace]

    def __iter__(self):
        return self._names.__iter__()

    def get(self, namespace, default=None):
        return self._names.get(namespace, default)

    def items(self):
        return self._names.items()

    iteritems = items

    def addnamespace(self, namespace, order=None):
        """register a namespace

        namespace: the name to be registered (in plural form)
        order: optional argument to specify the order of namespaces
               (e.g. 'branches' should be listed before 'bookmarks')

        """
        if order is not None:
            self._names.insert(order, namespace.name, namespace)
        else:
            self._names[namespace.name] = namespace

        # we only generate a template keyword if one does not already exist
        if namespace.name not in templatekw.keywords:
            templatekeyword = registrar.templatekeyword(templatekw.keywords)

            @templatekeyword(namespace.name, requires={b'repo', b'ctx'})
            def generatekw(context, mapping):
                return templatekw.shownames(context, mapping, namespace.name)

    def singlenode(self, repo, name):
        """
        Return the 'best' node for the given name. What's best is defined
        by the namespace's singlenode() function. The first match returned by
        a namespace in the defined precedence order is used.

        Raises a KeyError if there is no such node.
        """
        for ns, v in self._names.items():
            n = v.singlenode(repo, name)
            if n:
                return n
        raise KeyError(_(b'no such name: %s') % name)


class namespace:
    """provides an interface to a namespace

    Namespaces are basically generic many-to-many mapping between some
    (namespaced) names and nodes. The goal here is to control the pollution of
    jamming things into tags or bookmarks (in extension-land) and to simplify
    internal bits of mercurial: log output, tab completion, etc.

    More precisely, we define a mapping of names to nodes, and a mapping from
    nodes to names. Each mapping returns a list.

    Furthermore, each name mapping will be passed a name to lookup which might
    not be in its domain. In this case, each method should return an empty list
    and not raise an error.

    This namespace object will define the properties we need:
      'name': the namespace (plural form)
      'templatename': name to use for templating (usually the singular form
                      of the plural namespace name)
      'listnames': list of all names in the namespace (usually the keys of a
                   dictionary)
      'namemap': function that takes a name and returns a list of nodes
      'nodemap': function that takes a node and returns a list of names
      'deprecated': set of names to be masked for ordinary use
      'builtin': bool indicating if this namespace is supported by core
                 Mercurial.
    """

    def __init__(
        self,
        name,
        templatename=None,
        logname=None,
        colorname=None,
        logfmt=None,
        listnames=None,
        namemap=None,
        nodemap=None,
        deprecated=None,
        builtin=False,
        singlenode=None,
    ):
        """create a namespace

        name: the namespace to be registered (in plural form)
        templatename: the name to use for templating
        logname: the name to use for log output; if not specified templatename
                 is used
        colorname: the name to use for colored log output; if not specified
                   logname is used
        logfmt: the format to use for (i18n-ed) log output; if not specified
                it is composed from logname
        listnames: function to list all names
        namemap: function that inputs a name, output node(s)
        nodemap: function that inputs a node, output name(s)
        deprecated: set of names to be masked for ordinary use
        builtin: whether namespace is implemented by core Mercurial
        singlenode: function that inputs a name, output best node (or None)
        """
        self.name = name
        self.templatename = templatename
        self.logname = logname
        self.colorname = colorname
        self.logfmt = logfmt
        self.listnames = listnames
        self.namemap = namemap
        self.nodemap = nodemap
        if singlenode:
            self.singlenode = singlenode

        # if logname is not specified, use the template name as backup
        if self.logname is None:
            self.logname = self.templatename

        # if colorname is not specified, just use the logname as a backup
        if self.colorname is None:
            self.colorname = self.logname

        # if logfmt is not specified, compose it from logname as backup
        if self.logfmt is None:
            # i18n: column positioning for "hg log"
            self.logfmt = (b"%s:" % self.logname).ljust(13) + b"%s\n"

        if deprecated is None:
            self.deprecated = set()
        else:
            self.deprecated = deprecated

        self.builtin = builtin

    def names(self, repo, node):
        """method that returns a (sorted) list of names in a namespace that
        match a given node"""
        return sorted(self.nodemap(repo, node))

    def nodes(self, repo, name):
        """method that returns a list of nodes in a namespace that
        match a given name.

        """
        return sorted(self.namemap(repo, name))

    def singlenode(self, repo, name):
        """returns the best node for the given name

        By default, the best node is the node from nodes() with the highest
        revision number. It can be overriden by the namespace."""
        n = self.namemap(repo, name)
        if n:
            # return max revision number
            if len(n) > 1:
                cl = repo.changelog
                maxrev = max(cl.rev(node) for node in n)
                return cl.node(maxrev)
            return n[0]
        return None
                                                                                                                                                                                                                                                                                                                                                                                                                           usr/lib/python3/dist-packages/mercurial/narrowspec.py                                               0000644 0000000 0000000 00000027044 14355257011 021500  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # narrowspec.py - methods for working with a narrow view of a repository
#
# Copyright 2017 Google, Inc.
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


from .i18n import _
from .pycompat import getattr
from . import (
    error,
    match as matchmod,
    merge,
    mergestate as mergestatemod,
    requirements,
    scmutil,
    sparse,
    util,
)

# The file in .hg/store/ that indicates which paths exit in the store
FILENAME = b'narrowspec'
# The file in .hg/ that indicates which paths exit in the dirstate
DIRSTATE_FILENAME = b'narrowspec.dirstate'

# Pattern prefixes that are allowed in narrow patterns. This list MUST
# only contain patterns that are fast and safe to evaluate. Keep in mind
# that patterns are supplied by clients and executed on remote servers
# as part of wire protocol commands. That means that changes to this
# data structure influence the wire protocol and should not be taken
# lightly - especially removals.
VALID_PREFIXES = (
    b'path:',
    b'rootfilesin:',
)


def normalizesplitpattern(kind, pat):
    """Returns the normalized version of a pattern and kind.

    Returns a tuple with the normalized kind and normalized pattern.
    """
    pat = pat.rstrip(b'/')
    _validatepattern(pat)
    return kind, pat


def _numlines(s):
    """Returns the number of lines in s, including ending empty lines."""
    # We use splitlines because it is Unicode-friendly and thus Python 3
    # compatible. However, it does not count empty lines at the end, so trick
    # it by adding a character at the end.
    return len((s + b'x').splitlines())


def _validatepattern(pat):
    """Validates the pattern and aborts if it is invalid.

    Patterns are stored in the narrowspec as newline-separated
    POSIX-style bytestring paths. There's no escaping.
    """

    # We use newlines as separators in the narrowspec file, so don't allow them
    # in patterns.
    if _numlines(pat) > 1:
        raise error.Abort(_(b'newlines are not allowed in narrowspec paths'))

    components = pat.split(b'/')
    if b'.' in components or b'..' in components:
        raise error.Abort(
            _(b'"." and ".." are not allowed in narrowspec paths')
        )


def normalizepattern(pattern, defaultkind=b'path'):
    """Returns the normalized version of a text-format pattern.

    If the pattern has no kind, the default will be added.
    """
    kind, pat = matchmod._patsplit(pattern, defaultkind)
    return b'%s:%s' % normalizesplitpattern(kind, pat)


def parsepatterns(pats):
    """Parses an iterable of patterns into a typed pattern set.

    Patterns are assumed to be ``path:`` if no prefix is present.
    For safety and performance reasons, only some prefixes are allowed.
    See ``validatepatterns()``.

    This function should be used on patterns that come from the user to
    normalize and validate them to the internal data structure used for
    representing patterns.
    """
    res = {normalizepattern(orig) for orig in pats}
    validatepatterns(res)
    return res


def validatepatterns(pats):
    """Validate that patterns are in the expected data structure and format.

    And that is a set of normalized patterns beginning with ``path:`` or
    ``rootfilesin:``.

    This function should be used to validate internal data structures
    and patterns that are loaded from sources that use the internal,
    prefixed pattern representation (but can't necessarily be fully trusted).
    """
    with util.timedcm('narrowspec.validatepatterns(pats size=%d)', len(pats)):
        if not isinstance(pats, set):
            raise error.ProgrammingError(
                b'narrow patterns should be a set; got %r' % pats
            )

        for pat in pats:
            if not pat.startswith(VALID_PREFIXES):
                # Use a Mercurial exception because this can happen due to user
                # bugs (e.g. manually updating spec file).
                raise error.Abort(
                    _(b'invalid prefix on narrow pattern: %s') % pat,
                    hint=_(
                        b'narrow patterns must begin with one of '
                        b'the following: %s'
                    )
                    % b', '.join(VALID_PREFIXES),
                )


def format(includes, excludes):
    output = b'[include]\n'
    for i in sorted(includes - excludes):
        output += i + b'\n'
    output += b'[exclude]\n'
    for e in sorted(excludes):
        output += e + b'\n'
    return output


def match(root, include=None, exclude=None):
    if not include:
        # Passing empty include and empty exclude to matchmod.match()
        # gives a matcher that matches everything, so explicitly use
        # the nevermatcher.
        return matchmod.never()
    return matchmod.match(
        root, b'', [], include=include or [], exclude=exclude or []
    )


def parseconfig(ui, spec):
    # maybe we should care about the profiles returned too
    includepats, excludepats, profiles = sparse.parseconfig(ui, spec, b'narrow')
    if profiles:
        raise error.Abort(
            _(
                b"including other spec files using '%include' is not"
                b" supported in narrowspec"
            )
        )

    validatepatterns(includepats)
    validatepatterns(excludepats)

    return includepats, excludepats


def load(repo):
    # Treat "narrowspec does not exist" the same as "narrowspec file exists
    # and is empty".
    spec = repo.svfs.tryread(FILENAME)
    return parseconfig(repo.ui, spec)


def save(repo, includepats, excludepats):
    validatepatterns(includepats)
    validatepatterns(excludepats)
    spec = format(includepats, excludepats)
    repo.svfs.write(FILENAME, spec)


def copytoworkingcopy(repo):
    spec = repo.svfs.read(FILENAME)
    repo.vfs.write(DIRSTATE_FILENAME, spec)


def savebackup(repo, backupname):
    if requirements.NARROW_REQUIREMENT not in repo.requirements:
        return
    svfs = repo.svfs
    svfs.tryunlink(backupname)
    util.copyfile(svfs.join(FILENAME), svfs.join(backupname), hardlink=True)


def restorebackup(repo, backupname):
    if requirements.NARROW_REQUIREMENT not in repo.requirements:
        return
    util.rename(repo.svfs.join(backupname), repo.svfs.join(FILENAME))


def savewcbackup(repo, backupname):
    if requirements.NARROW_REQUIREMENT not in repo.requirements:
        return
    vfs = repo.vfs
    vfs.tryunlink(backupname)
    # It may not exist in old repos
    if vfs.exists(DIRSTATE_FILENAME):
        util.copyfile(
            vfs.join(DIRSTATE_FILENAME), vfs.join(backupname), hardlink=True
        )


def restorewcbackup(repo, backupname):
    if requirements.NARROW_REQUIREMENT not in repo.requirements:
        return
    # It may not exist in old repos
    if repo.vfs.exists(backupname):
        util.rename(repo.vfs.join(backupname), repo.vfs.join(DIRSTATE_FILENAME))


def clearwcbackup(repo, backupname):
    if requirements.NARROW_REQUIREMENT not in repo.requirements:
        return
    repo.vfs.tryunlink(backupname)


def restrictpatterns(req_includes, req_excludes, repo_includes, repo_excludes):
    r"""Restricts the patterns according to repo settings,
    results in a logical AND operation

    :param req_includes: requested includes
    :param req_excludes: requested excludes
    :param repo_includes: repo includes
    :param repo_excludes: repo excludes
    :return: include patterns, exclude patterns, and invalid include patterns.
    """
    res_excludes = set(req_excludes)
    res_excludes.update(repo_excludes)
    invalid_includes = []
    if not req_includes:
        res_includes = set(repo_includes)
    elif b'path:.' not in repo_includes:
        res_includes = []
        for req_include in req_includes:
            req_include = util.expandpath(util.normpath(req_include))
            if req_include in repo_includes:
                res_includes.append(req_include)
                continue
            valid = False
            for repo_include in repo_includes:
                if req_include.startswith(repo_include + b'/'):
                    valid = True
                    res_includes.append(req_include)
                    break
            if not valid:
                invalid_includes.append(req_include)
        if len(res_includes) == 0:
            res_excludes = {b'path:.'}
        else:
            res_includes = set(res_includes)
    else:
        res_includes = set(req_includes)
    return res_includes, res_excludes, invalid_includes


# These two are extracted for extensions (specifically for Google's CitC file
# system)
def _deletecleanfiles(repo, files):
    for f in files:
        repo.wvfs.unlinkpath(f)


def _writeaddedfiles(repo, pctx, files):
    mresult = merge.mergeresult()
    mf = repo[b'.'].manifest()
    for f in files:
        if not repo.wvfs.exists(f):
            mresult.addfile(
                f,
                mergestatemod.ACTION_GET,
                (mf.flags(f), False),
                b"narrowspec updated",
            )
    merge.applyupdates(
        repo,
        mresult,
        wctx=repo[None],
        mctx=repo[b'.'],
        overwrite=False,
        wantfiledata=False,
    )


def checkworkingcopynarrowspec(repo):
    # Avoid infinite recursion when updating the working copy
    if getattr(repo, '_updatingnarrowspec', False):
        return
    storespec = repo.svfs.tryread(FILENAME)
    wcspec = repo.vfs.tryread(DIRSTATE_FILENAME)
    if wcspec != storespec:
        raise error.StateError(
            _(b"working copy's narrowspec is stale"),
            hint=_(b"run 'hg tracked --update-working-copy'"),
        )


def updateworkingcopy(repo, assumeclean=False):
    """updates the working copy and dirstate from the store narrowspec

    When assumeclean=True, files that are not known to be clean will also
    be deleted. It is then up to the caller to make sure they are clean.
    """
    oldspec = repo.vfs.tryread(DIRSTATE_FILENAME)
    newspec = repo.svfs.tryread(FILENAME)
    repo._updatingnarrowspec = True

    oldincludes, oldexcludes = parseconfig(repo.ui, oldspec)
    newincludes, newexcludes = parseconfig(repo.ui, newspec)
    oldmatch = match(repo.root, include=oldincludes, exclude=oldexcludes)
    newmatch = match(repo.root, include=newincludes, exclude=newexcludes)
    addedmatch = matchmod.differencematcher(newmatch, oldmatch)
    removedmatch = matchmod.differencematcher(oldmatch, newmatch)

    ds = repo.dirstate
    lookup, status, _mtime_boundary = ds.status(
        removedmatch, subrepos=[], ignored=True, clean=True, unknown=True
    )
    trackeddirty = status.modified + status.added
    clean = status.clean
    if assumeclean:
        clean.extend(lookup)
    else:
        trackeddirty.extend(lookup)
    _deletecleanfiles(repo, clean)
    uipathfn = scmutil.getuipathfn(repo)
    for f in sorted(trackeddirty):
        repo.ui.status(
            _(b'not deleting possibly dirty file %s\n') % uipathfn(f)
        )
    for f in sorted(status.unknown):
        repo.ui.status(_(b'not deleting unknown file %s\n') % uipathfn(f))
    for f in sorted(status.ignored):
        repo.ui.status(_(b'not deleting ignored file %s\n') % uipathfn(f))
    for f in clean + trackeddirty:
        ds.update_file(f, p1_tracked=False, wc_tracked=False)

    pctx = repo[b'.']

    # only update added files that are in the sparse checkout
    addedmatch = matchmod.intersectmatchers(addedmatch, sparse.matcher(repo))
    newfiles = [f for f in pctx.manifest().walk(addedmatch) if f not in ds]
    for f in newfiles:
        ds.update_file(f, p1_tracked=True, wc_tracked=True, possibly_dirty=True)
    _writeaddedfiles(repo, pctx, newfiles)
    repo._updatingnarrowspec = False
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            usr/lib/python3/dist-packages/mercurial/node.py                                                     0000644 0000000 0000000 00000003407 14355257011 020237  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # node.py - basic nodeid manipulation for mercurial
#
# Copyright 2005, 2006 Olivia Mackall <olivia@selenic.com>
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


import binascii

# This ugly style has a noticeable effect in manifest parsing
