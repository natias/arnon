would match the same things.

Another example that shows that within C<\p{...}>, C</x> isn't needed to
have spaces:

 qr!\p{scx= /Hebrew|Greek/ }!

To be safe, we should have anchored the above example, to prevent
matches for something like C<Hebrew_Braille>, but there aren't
any script names like that, so far.
A warning is issued if none of the legal values for a property are
matched by your pattern.  It's likely that a future release will raise a
warning if your pattern ends up causing every possible code point to
match.

Starting in 5.32, the Name, Name Aliases, and Named Sequences properties
are allowed to be matched.  They are considered to be a single
combination property, just as has long been the case for C<\N{}>.  Loose
matching doesn't work in exactly the same way for these as it does for
the values of other properties.  The rules are given in
L<https://www.unicode.org/reports/tr44/tr44-24.html#UAX44-LM2>.  As a
result, Perl doesn't try loose matching for you, like it does in other
properties.  All letters in names are uppercase, but you can add C<(?i)>
to your subpattern to ignore case.  If you're uncertain where a blank
is, you can use C< ?> in your subpattern.  No character name contains an
underscore, so don't bother trying to match one.  The use of hyphens is
particularly problematic; refer to the above link.  But note that, as of
Unicode 13.0, the only script in modern usage which has weirdnesses with
these is Tibetan; also the two Korean characters U+116C HANGUL JUNGSEONG
OE and U+1180 HANGUL JUNGSEONG O-E.  Unicode makes no promises to not
add hyphen-problematic names in the future.

Using wildcards on these is resource intensive, given the hundreds of
thousands of legal names that must be checked against.

An example of using Name property wildcards is

 qr!\p{name=/(SMILING|GRINNING) FACE/}!

Another is

 qr/(?[ \p{name=\/CJK\/} - \p{ideographic} ])/

which is the 200-ish (as of Unicode 13.0) CJK characters that aren't
ideographs.

There are certain properties that wildcard subpatterns don't currently
work with.  These are:

 Bidi Mirroring Glyph
 Bidi Paired Bracket
 Case Folding
 Decomposition Mapping
 Equivalent Unified Ideograph
 Lowercase Mapping
 NFKC Case Fold
 Titlecase Mapping
 Uppercase Mapping

Nor is the C<@I<unicode_property>@> form implemented.

Here's a complete example of matching IPV4 internet protocol addresses
in any (single) script

 no warnings 'experimental::uniprop_wildcards';

 # Can match a substring, so this intermediate regex needs to have
 # context or anchoring in its final use.  Using nt=de yields decimal
 # digits.  When specifying a subset of these, we must include \d to
 # prevent things like U+00B2 SUPERSCRIPT TWO from matching
 my $zero_through_255 =
  qr/ \b (*sr:                                  # All from same sript
            (?[ \p{nv=0} & \d ])*               # Optional leading zeros
        (                                       # Then one of:
                                  \d{1,2}       #   0 - 99
            | (?[ \p{nv=1} & \d ])  \d{2}       #   100 - 199
            | (?[ \p{nv=2} & \d ])
               (  (?[ \p{nv=:[0-4]:} & \d ]) \d #   200 - 249
                | (?[ \p{nv=5}     & \d ])
                  (?[ \p{nv=:[0-5]:} & \d ])    #   250 - 255
               )
        )
      )
    \b
  /x;

 my $ipv4 = qr/ \A (*sr:         $zero_through_255
                         (?: [.] $zero_through_255 ) {3}
                   )
                \z
            /x;

=head2 User-Defined Character Properties

You can define your own binary character properties by defining subroutines
whose names begin with C<"In"> or C<"Is">.  (The regex sets feature
L<perlre/(?[ ])> provides an alternative which allows more complex
definitions.)  The subroutines can be defined in any
package.  They override any Unicode properties expressed as the same
names.  The user-defined properties can be used in the regular
expression
C<\p{}> and C<\P{}> constructs; if you are using a user-defined property from a
package other than the one you are in, you must specify its package in the
C<\p{}> or C<\P{}> construct.

    # assuming property IsForeign defined in Lang::
    package main;  # property package name required
    if ($txt =~ /\p{Lang::IsForeign}+/) { ... }

    package Lang;  # property package name not required
    if ($txt =~ /\p{IsForeign}+/) { ... }


The subroutines are passed a single parameter, which is 0 if
case-sensitive matching is in effect and non-zero if caseless matching
is in effect.  The subroutine may return different values depending on
the value of the flag.  But the subroutine is never called more than
once for each flag value (zero vs non-zero).  The return value is saved
and used instead of calling the sub ever again.  If the sub is defined
at the time the pattern is compiled, it will be called then; if not, it
will be called the first time its value (for that flag) is needed during
execution.

Note that if the regular expression is tainted, then Perl will die rather
than calling the subroutine when the name of the subroutine is
determined by the tainted data.

The subroutines must return a specially-formatted string, with one
or more newline-separated lines.  Each line must be one of the following:

=over 4

=item *

A single hexadecimal number denoting a code point to include.

=item *

Two hexadecimal numbers separated by horizontal whitespace (space or
tabular characters) denoting a range of code points to include.  The
second number must not be smaller than the first.

=item *

Something to include, prefixed by C<"+">: a built-in character
property (prefixed by C<"utf8::">) or a fully qualified (including package
name) user-defined character property,
to represent all the characters in that property; two hexadecimal code
points for a range; or a single hexadecimal code point.

=item *

Something to exclude, prefixed by C<"-">: an existing character
property (prefixed by C<"utf8::">) or a fully qualified (including package
name) user-defined character property,
to represent all the characters in that property; two hexadecimal code
points for a range; or a single hexadecimal code point.

=item *

Something to negate, prefixed C<"!">: an existing character
property (prefixed by C<"utf8::">) or a fully qualified (including package
name) user-defined character property,
to represent all the characters in that property; two hexadecimal code
points for a range; or a single hexadecimal code point.

=item *

Something to intersect with, prefixed by C<"&">: an existing character
property (prefixed by C<"utf8::">) or a fully qualified (including package
name) user-defined character property,
for all the characters except the characters in the property; two
hexadecimal code points for a range; or a single hexadecimal code point.

=back

For example, to define a property that covers both the Japanese
syllabaries (hiragana and katakana), you can define

    sub InKana {
        return <<END;
    3040\t309F
    30A0\t30FF
    END
    }

Imagine that the here-doc end marker is at the beginning of the line.
Now you can use C<\p{InKana}> and C<\P{InKana}>.

You could also have used the existing block property names:

    sub InKana {
        return <<'END';
    +utf8::InHiragana
    +utf8::InKatakana
    END
    }

Suppose you wanted to match only the allocated characters,
not the raw block ranges: in other words, you want to remove
the unassigned characters:

    sub InKana {
        return <<'END';
    +utf8::InHiragana
    +utf8::InKatakana
    -utf8::IsCn
    END
    }

The negation is useful for defining (surprise!) negated classes.

    sub InNotKana {
        return <<'END';
    !utf8::InHiragana
    -utf8::InKatakana
    +utf8::IsCn
    END
    }

This will match all non-Unicode code points, since every one of them is
not in Kana.  You can use intersection to exclude these, if desired, as
this modified example shows:

    sub InNotKana {
        return <<'END';
    !utf8::InHiragana
    -utf8::InKatakana
    +utf8::IsCn
    &utf8::Any
    END
    }

C<&utf8::Any> must be the last line in the definition.

Intersection is used generally for getting the common characters matched
by two (or more) classes.  It's important to remember not to use C<"&"> for
the first set; that would be intersecting with nothing, resulting in an
empty set.  (Similarly using C<"-"> for the first set does nothing).

Unlike non-user-defined C<\p{}> property matches, no warning is ever
generated if these properties are matched against a non-Unicode code
point (see L</Beyond Unicode code points> below).

=head2 User-Defined Case Mappings (for serious hackers only)

B<This feature has been removed as of Perl 5.16.>
The CPAN module C<L<Unicode::Casing>> provides better functionality without
the drawbacks that this feature had.  If you are using a Perl earlier
than 5.16, this feature was most fully documented in the 5.14 version of
this pod:
L<http://perldoc.perl.org/5.14.0/perlunicode.html#User-Defined-Case-Mappings-%28for-serious-hackers-only%29>

=head2 Character Encodings for Input and Output

See L<Encode>.

=head2 Unicode Regular Expression Support Level

The following list of Unicode supported features for regular expressions describes
all features currently directly supported by core Perl.  The references
to "Level I<N>" and the section numbers refer to
L<UTS#18 "Unicode Regular Expressions"|https://www.unicode.org/reports/tr18>,
version 18, October 2016.

=head3 Level 1 - Basic Unicode Support

 RL1.1   Hex Notation                     - Done          [1]
 RL1.2   Properties                       - Done          [2]
 RL1.2a  Compatibility Properties         - Done          [3]
 RL1.3   Subtraction and Intersection     - Done          [4]
 RL1.4   Simple Word Boundaries           - Done          [5]
 RL1.5   Simple Loose Matches             - Done          [6]
 RL1.6   Line Boundaries                  - Partial       [7]
 RL1.7   Supplementary Code Points        - Done          [8]

=over 4

=item [1] C<\N{U+...}> and C<\x{...}>

=item [2]
C<\p{...}> C<\P{...}>.  This requirement is for a minimal list of
properties.  Perl supports these.  See R2.7 for other properties.

=item [3]

Perl has C<\d> C<\D> C<\s> C<\S> C<\w> C<\W> C<\X> C<[:I<prop>:]>
C<[:^I<prop>:]>, plus all the properties specified by
L<https://www.unicode.org/reports/tr18/#Compatibility_Properties>.  These
are described above in L</Other Properties>

=item [4]

The regex sets feature C<"(?[...])"> starting in v5.18 accomplishes
this.  See L<perlre/(?[ ])>.

=item [5]
C<\b> C<\B> meet most, but not all, the details of this requirement, but
C<\b{wb}> and C<\B{wb}> do, as well as the stricter R2.3.

=item [6]

Note that Perl does Full case-folding in matching, not Simple:

For example C<U+1F88> is equivalent to C<U+1F00 U+03B9>, instead of just
C<U+1F80>.  This difference matters mainly for certain Greek capital
letters with certain modifiers: the Full case-folding decomposes the
letter, while the Simple case-folding would map it to a single
character.

=item [7]

The reason this is considered to be only partially implemented is that
Perl has L<C<qrE<sol>\b{lb}E<sol>>|perlrebackslash/\b{lb}> and
C<L<Unicode::LineBreak>> that are conformant with
L<UAX#14 "Unicode Line Breaking Algorithm"|https://www.unicode.org/reports/tr14>.
The regular expression construct provides default behavior, while the
heavier-weight module provides customizable line breaking.

But Perl treats C<\n> as the start- and end-line
delimiter, whereas Unicode specifies more characters that should be
so-interpreted.

These are:

 VT   U+000B  (\v in C)
 FF   U+000C  (\f)
 CR   U+000D  (\r)
 NEL  U+0085
 LS   U+2028
 PS   U+2029

C<^> and C<$> in regular expression patterns are supposed to match all
these, but don't.
These characters also don't, but should, affect C<< <> >> C<$.>, and
script line numbers.

Also, lines should not be split within C<CRLF> (i.e. there is no
empty line between C<\r> and C<\n>).  For C<CRLF>, try the C<:crlf>
layer (see L<PerlIO>).

=item [8]
UTF-8/UTF-EBDDIC used in Perl allows not only C<U+10000> to
C<U+10FFFF> but also beyond C<U+10FFFF>

=back

=head3 Level 2 - Extended Unicode Support

 RL2.1   Canonical Equivalents           - Retracted     [9]
                                           by Unicode
 RL2.2   Extended Grapheme Clusters and  - Partial       [10]
         Character Classes with Strings
 RL2.3   Default Word Boundaries         - Done          [11]
 RL2.4   Default Case Conversion         - Done
 RL2.5   Name Properties                 - Done
 RL2.6   Wildcards in Property Values    - Partial       [12]
 RL2.7   Full Properties                 - Partial       [13]
 RL2.8   Optional Properties             - Partial       [14]

=over 4

=item [9]
Unicode has rewritten this portion of UTS#18 to say that getting
canonical equivalence (see UAX#15
L<"Unicode Normalization Forms"|https://www.unicode.org/reports/tr15>)
is basically to be done at the programmer level.  Use NFD to write
both your regular expressions and text to match them against (you
can use L<Unicode::Normalize>).

=item [10]
Perl has C<\X> and C<\b{gcb}>.  Unicode has retracted their "Grapheme
Cluster Mode", and recently added string properties, which Perl does not
yet support.

=item [11] see
L<UAX#29 "Unicode Text Segmentation"|https://www.unicode.org/reports/tr29>,

=item [12] see
L</Wildcards in Property Values> above.

=item [13]
Perl supports all the properties in the Unicode Character Database
(UCD).  It does not yet support the listed properties that come from
other Unicode sources.

=item [14]
The only optional property that Perl supports is Named Sequence.  None
of these properties are in the UCD.

=back

=head3 Level 3 - Tailored Support

This has been retracted by Unicode.

=head2 Unicode Encodings

Unicode characters are assigned to I<code points>, which are abstract
numbers.  To use these numbers, various encodings are needed.

=over 4

=item *

UTF-8

UTF-8 is a variable-length (1 to 4 bytes), byte-order independent
encoding.  In most of Perl's documentation, including elsewhere in this
document, the term "UTF-8" means also "UTF-EBCDIC".  But in this section,
"UTF-8" refers only to the encoding used on ASCII platforms.  It is a
superset of 7-bit US-ASCII, so anything encoded in ASCII has the
identical representation when encoded in UTF-8.

The following table is from Unicode 3.2.

 Code Points            1st Byte  2nd Byte  3rd Byte 4th Byte

   U+0000..U+007F       00..7F
   U+0080..U+07FF     * C2..DF    80..BF
   U+0800..U+0FFF       E0      * A0..BF    80..BF
   U+1000..U+CFFF       E1..EC    80..BF    80..BF
   U+D000..U+D7FF       ED        80..9F    80..BF
   U+D800..U+DFFF       +++++ utf16 surrogates, not legal utf8 +++++
   U+E000..U+FFFF       EE..EF    80..BF    80..BF
  U+10000..U+3FFFF      F0      * 90..BF    80..BF    80..BF
  U+40000..U+FFFFF      F1..F3    80..BF    80..BF    80..BF
 U+100000..U+10FFFF     F4        80..8F    80..BF    80..BF

Note the gaps marked by "*" before several of the byte entries above.  These are
caused by legal UTF-8 avoiding non-shortest encodings: it is technically
possible to UTF-8-encode a single code point in different ways, but that is
explicitly forbidden, and the shortest possible encoding should always be used
(and that is what Perl does).

Another way to look at it is via bits:

                Code Points  1st Byte  2nd Byte  3rd Byte  4th Byte

                   0aaaaaaa  0aaaaaaa
           00000bbbbbaaaaaa  110bbbbb  10aaaaaa
           ccccbbbbbbaaaaaa  1110cccc  10bbbbbb  10aaaaaa
 00000dddccccccbbbbbbaaaaaa  11110ddd  10cccccc  10bbbbbb  10aaaaaa

As you can see, the continuation bytes all begin with C<"10">, and the
leading bits of the start byte tell how many bytes there are in the
encoded character.

The original UTF-8 specification allowed up to 6 bytes, to allow
encoding of numbers up to C<0x7FFF_FFFF>.  Perl continues to allow those,
and has extended that up to 13 bytes to encode code points up to what
can fit in a 64-bit word.  However, Perl will warn if you output any of
these as being non-portable; and under strict UTF-8 input protocols,
they are forbidden.  In addition, it is now illegal to use a code point
larger than what a signed integer variable on your system can hold.  On
32-bit ASCII systems, this means C<0x7FFF_FFFF> is the legal maximum
(much higher on 64-bit systems).

=item *

UTF-EBCDIC

Like UTF-8, but EBCDIC-safe, in the way that UTF-8 is ASCII-safe.
This means that all the basic characters (which includes all
those that have ASCII equivalents (like C<"A">, C<"0">, C<"%">, I<etc.>)
are the same in both EBCDIC and UTF-EBCDIC.)

UTF-EBCDIC is used on EBCDIC platforms.  It generally requires more
bytes to represent a given code point than UTF-8 does; the largest
Unicode code points take 5 bytes to represent (instead of 4 in UTF-8),
and, extended for 64-bit words, it uses 14 bytes instead of 13 bytes in
UTF-8.

=item *

UTF-16, UTF-16BE, UTF-16LE, Surrogates, and C<BOM>'s (Byte Order Marks)

The followings items are mostly for reference and general Unicode
knowledge, Perl doesn't use these constructs internally.

Like UTF-8, UTF-16 is a variable-width encoding, but where
UTF-8 uses 8-bit code units, UTF-16 uses 16-bit code units.
All code points occupy either 2 or 4 bytes in UTF-16: code points
C<U+0000..U+FFFF> are stored in a single 16-bit unit, and code
points C<U+10000..U+10FFFF> in two 16-bit units.  The latter case is
using I<surrogates>, the first 16-bit unit being the I<high
surrogate>, and the second being the I<low surrogate>.

Surrogates are code points set aside to encode the C<U+10000..U+10FFFF>
range of Unicode code points in pairs of 16-bit units.  The I<high
surrogates> are the range C<U+D800..U+DBFF> and the I<low surrogates>
are the range C<U+DC00..U+DFFF>.  The surrogate encoding is

    $hi = ($uni - 0x10000) / 0x400 + 0xD800;
    $lo = ($uni - 0x10000) % 0x400 + 0xDC00;

and the decoding is

    $uni = 0x10000 + ($hi - 0xD800) * 0x400 + ($lo - 0xDC00);

Because of the 16-bitness, UTF-16 is byte-order dependent.  UTF-16
itself can be used for in-memory computations, but if storage or
transfer is required either UTF-16BE (big-endian) or UTF-16LE
(little-endian) encodings must be chosen.

This introduces another problem: what if you just know that your data
is UTF-16, but you don't know which endianness?  Byte Order Marks, or
C<BOM>'s, are a solution to this.  A special character has been reserved
in Unicode to function as a byte order marker: the character with the
code point C<U+FEFF> is the C<BOM>.

The trick is that if you read a C<BOM>, you will know the byte order,
since if it was written on a big-endian platform, you will read the
bytes C<0xFE 0xFF>, but if it was written on a little-endian platform,
you will read the bytes C<0xFF 0xFE>.  (And if the originating platform
was writing in ASCII platform UTF-8, you will read the bytes
C<0xEF 0xBB 0xBF>.)

The way this trick works is that the character with the code point
C<U+FFFE> is not supposed to be in input streams, so the
sequence of bytes C<0xFF 0xFE> is unambiguously "C<BOM>, represented in
little-endian format" and cannot be C<U+FFFE>, represented in big-endian
format".

Surrogates have no meaning in Unicode outside their use in pairs to
represent other code points.  However, Perl allows them to be
represented individually internally, for example by saying
C<chr(0xD801)>, so that all code points, not just those valid for open
interchange, are
representable.  Unicode does define semantics for them, such as their
C<L</General_Category>> is C<"Cs">.  But because their use is somewhat dangerous,
Perl will warn (using the warning category C<"surrogate">, which is a
sub-category of C<"utf8">) if an attempt is made
to do things like take the lower case of one, or match
case-insensitively, or to output them.  (But don't try this on Perls
before 5.14.)

=item *

UTF-32, UTF-32BE, UTF-32LE

The UTF-32 family is pretty much like the UTF-16 family, except that
the units are 32-bit, and therefore the surrogate scheme is not
needed.  UTF-32 is a fixed-width encoding.  The C<BOM> signatures are
C<0x00 0x00 0xFE 0xFF> for BE and C<0xFF 0xFE 0x00 0x00> for LE.

=item *

UCS-2, UCS-4

Legacy, fixed-width encodings defined by the ISO 10646 standard.  UCS-2 is a 16-bit
encoding.  Unlike UTF-16, UCS-2 is not extensible beyond C<U+FFFF>,
because it does not use surrogates.  UCS-4 is a 32-bit encoding,
functionally identical to UTF-32 (the difference being that
UCS-4 forbids neither surrogates nor code points larger than C<0x10_FFFF>).

=item *

UTF-7

A seven-bit safe (non-eight-bit) encoding, which is useful if the
transport or storage is not eight-bit safe.  Defined by RFC 2152.

=back

=head2 Noncharacter code points

66 code points are set aside in Unicode as "noncharacter code points".
These all have the C<Unassigned> (C<Cn>) C<L</General_Category>>, and
no character will ever be assigned to any of them.  They are the 32 code
points between C<U+FDD0> and C<U+FDEF> inclusive, and the 34 code
points:

 U+FFFE   U+FFFF
 U+1FFFE  U+1FFFF
 U+2FFFE  U+2FFFF
 ...
 U+EFFFE  U+EFFFF
 U+FFFFE  U+FFFFF
 U+10FFFE U+10FFFF

Until Unicode 7.0, the noncharacters were "B<forbidden> for use in open
interchange of Unicode text data", so that code that processed those
streams could use these code points as sentinels that could be mixed in
with character data, and would always be distinguishable from that data.
(Emphasis above and in the next paragraph are added in this document.)

Unicode 7.0 changed the wording so that they are "B<not recommended> for
use in open interchange of Unicode text data".  The 7.0 Standard goes on
to say:

=over 4

"If a noncharacter is received in open interchange, an application is
not required to interpret it in any way.  It is good practice, however,
to recognize it as a noncharacter and to take appropriate action, such
as replacing it with C<U+FFFD> replacement character, to indicate the
problem in the text.  It is not recommended to simply delete
noncharacter code points from such text, because of the potential
security issues caused by deleting uninterpreted characters.  (See
conformance clause C7 in Section 3.2, Conformance Requirements, and
L<Unicode Technical Report #36, "Unicode Security
Considerations"|https://www.unicode.org/reports/tr36/#Substituting_for_Ill_Formed_Subsequences>)."

=back

This change was made because it was found that various commercial tools
like editors, or for things like source code control, had been written
so that they would not handle program files that used these code points,
effectively precluding their use almost entirely!  And that was never
the intent.  They've always been meant to be usable within an
application, or cooperating set of applications, at will.

If you're writing code, such as an editor, that is supposed to be able
to handle any Unicode text data, then you shouldn't be using these code
points yourself, and instead allow them in the input.  If you need
sentinels, they should instead be something that isn't legal Unicode.
For UTF-8 data, you can use the bytes 0xC0 and 0xC1 as sentinels, as
they never appear in well-formed UTF-8.  (There are equivalents for
UTF-EBCDIC).  You can also store your Unicode code points in integer
variables and use negative values as sentinels.

If you're not writing such a tool, then whether you accept noncharacters
as input is up to you (though the Standard recommends that you not).  If
you do strict input stream checking with Perl, these code points
continue to be forbidden.  This is to maintain backward compatibility
(otherwise potential security holes could open up, as an unsuspecting
application that was written assuming the noncharacters would be
filtered out before getting to it, could now, without warning, start
getting them).  To do strict checking, you can use the layer
C<:encoding('UTF-8')>.

Perl continues to warn (using the warning category C<"nonchar">, which
is a sub-category of C<"utf8">) if an attempt is made to output
noncharacters.

=head2 Beyond Unicode code points

The maximum Unicode code point is C<U+10FFFF>, and Unicode only defines
operations on code points up through that.  But Perl works on code
points up to the maximum permissible signed number available on the
platform.  However, Perl will not accept these from input streams unless
lax rules are being used, and will warn (using the warning category
C<"non_unicode">, which is a sub-category of C<"utf8">) if any are output.

Since Unicode rules are not defined on these code points, if a
Unicode-defined operation is done on them, Perl uses what we believe are
sensible rules, while generally warning, using the C<"non_unicode">
category.  For example, C<uc("\x{11_0000}")> will generate such a
warning, returning the input parameter as its result, since Perl defines
the uppercase of every non-Unicode code point to be the code point
itself.  (All the case changing operations, not just uppercasing, work
this way.)

The situation with matching Unicode properties in regular expressions,
the C<\p{}> and C<\P{}> constructs, against these code points is not as
clear cut, and how these are handled has changed as we've gained
experience.

One possibility is to treat any match against these code points as
undefined.  But since Perl doesn't have the concept of a match being
undefined, it converts this to failing or C<FALSE>.  This is almost, but
not quite, what Perl did from v5.14 (when use of these code points
became generally reliable) through v5.18.  The difference is that Perl
treated all C<\p{}> matches as failing, but all C<\P{}> matches as
succeeding.

One problem with this is that it leads to unexpected, and confusing
results in some cases:

 chr(0x110000) =~ \p{ASCII_Hex_Digit=True}      # Failed on <= v5.18
 chr(0x110000) =~ \p{ASCII_Hex_Digit=False}     # Failed! on <= v5.18

That is, it treated both matches as undefined, and converted that to
false (raising a warning on each).  The first case is the expected
result, but the second is likely counterintuitive: "How could both be
false when they are complements?"  Another problem was that the
implementation optimized many Unicode property matches down to already
existing simpler, faster operations, which don't raise the warning.  We
chose to not forgo those optimizations, which help the vast majority of
matches, just to generate a warning for the unlikely event that an
above-Unicode code point is being matched against.

As a result of these problems, starting in v5.20, what Perl does is
to treat non-Unicode code points as just typical unassigned Unicode
characters, and matches accordingly.  (Note: Unicode has atypical
unassigned code points.  For example, it has noncharacter code points,
and ones that, when they do get assigned, are destined to be written
Right-to-left, as Arabic and Hebrew are.  Perl assumes that no
non-Unicode code point has any atypical properties.)

Perl, in most cases, will raise a warning when matching an above-Unicode
code point against a Unicode property when the result is C<TRUE> for
C<\p{}>, and C<FALSE> for C<\P{}>.  For example:

 chr(0x110000) =~ \p{ASCII_Hex_Digit=True}      # Fails, no warning
 chr(0x110000) =~ \p{ASCII_Hex_Digit=False}     # Succeeds, with warning

In both these examples, the character being matched is non-Unicode, so
Unicode doesn't define how it should match.  It clearly isn't an ASCII
hex digit, so the first example clearly should fail, and so it does,
with no warning.  But it is arguable that the second example should have
an undefined, hence C<FALSE>, result.  So a warning is raised for it.

Thus the warning is raised for many fewer cases than in earlier Perls,
and only when what the result is could be arguable.  It turns out that
none of the optimizations made by Perl (or are ever likely to be made)
cause the warning to be skipped, so it solves both problems of Perl's
earlier approach.  The most commonly used property that is affected by
this change is C<\p{Unassigned}> which is a short form for
C<\p{General_Category=Unassigned}>.  Starting in v5.20, all non-Unicode
code points are considered C<Unassigned>.  In earlier releases the
matches failed because the result was considered undefined.

The only place where the warning is not raised when it might ought to
have been is if optimizations cause the whole pattern match to not even
be attempted.  For example, Perl may figure out that for a string to
match a certain regular expression pattern, the string has to contain
the substring C<"foobar">.  Before attempting the match, Perl may look
for that substring, and if not found, immediately fail the match without
actually trying it; so no warning gets generated even if the string
contains an above-Unicode code point.

This behavior is more "Do what I mean" than in earlier Perls for most
applications.  But it catches fewer issues for code that needs to be
strictly Unicode compliant.  Therefore there is an additional mode of
operation available to accommodate such code.  This mode is enabled if a
regular expression pattern is compiled within the lexical scope where
the C<"non_unicode"> warning class has been made fatal, say by:

 use warnings FATAL => "non_unicode"

(see L<warnings>).  In this mode of operation, Perl will raise the
warning for all matches against a non-Unicode code point (not just the
arguable ones), and it skips the optimizations that might cause the
warning to not be output.  (It currently still won't warn if the match
isn't even attempted, like in the C<"foobar"> example above.)

In summary, Perl now normally treats non-Unicode code points as typical
Unicode unassigned code points for regular expression matches, raising a
warning only when it is arguable what the result should be.  However, if
this warning has been made fatal, it isn't skipped.

There is one exception to all this.  C<\p{All}> looks like a Unicode
property, but it is a Perl extension that is defined to be true for all
possible code points, Unicode or not, so no warning is ever generated
when matching this against a non-Unicode code point.  (Prior to v5.20,
it was an exact synonym for C<\p{Any}>, matching code points C<0>
through C<0x10FFFF>.)

=head2 Security Implications of Unicode

First, read
L<Unicode Security Considerations|https://www.unicode.org/reports/tr36>.

Also, note the following:

=over 4

=item *

Malformed UTF-8

UTF-8 is very structured, so many combinations of bytes are invalid.  In
the past, Perl tried to soldier on and make some sense of invalid
combinations, but this can lead to security holes, so now, if the Perl
core needs to process an invalid combination, it will either raise a
fatal error, or will replace those bytes by the sequence that forms the
Unicode REPLACEMENT CHARACTER, for which purpose Unicode created it.

Every code point can be represented by more than one possible
syntactically valid UTF-8 sequence.  Early on, both Unicode and Perl
considered any of these to be valid, but now, all sequences longer
than the shortest possible one are considered to be malformed.

Unicode considers many code points to be illegal, or to be avoided.
Perl generally accepts them, once they have passed through any input
filters that may try to exclude them.  These have been discussed above
(see "Surrogates" under UTF-16 in L</Unicode Encodings>,
L</Noncharacter code points>, and L</Beyond Unicode code points>).

=item *

Regular expression pattern matching may surprise you if you're not
accustomed to Unicode.  Starting in Perl 5.14, several pattern
modifiers are available to control this, called the character set
modifiers.  Details are given in L<perlre/Character set modifiers>.

=back

As discussed elsewhere, Perl has one foot (two hooves?) planted in
each of two worlds: the old world of ASCII and single-byte locales, and
the new world of Unicode, upgrading when necessary.
If your legacy code does not explicitly use Unicode, no automatic
switch-over to Unicode should happen.

=head2 Unicode in Perl on EBCDIC

Unicode is supported on EBCDIC platforms.  See L<perlebcdic>.

Unless ASCII vs. EBCDIC issues are specifically being discussed,
references to UTF-8 encoding in this document and elsewhere should be
read as meaning UTF-EBCDIC on EBCDIC platforms.
See L<perlebcdic/Unicode and UTF>.

Because UTF-EBCDIC is so similar to UTF-8, the differences are mostly
hidden from you; S<C<use utf8>> (and NOT something like
S<C<use utfebcdic>>) declares the script is in the platform's
"native" 8-bit encoding of Unicode.  (Similarly for the C<":utf8">
layer.)

=head2 Locales

See L<perllocale/Unicode and UTF-8>

=head2 When Unicode Does Not Happen

There are still many places where Unicode (in some encoding or
another) could be given as arguments or received as results, or both in
Perl, but it is not, in spite of Perl having extensive ways to input and
output in Unicode, and a few other "entry points" like the C<@ARGV>
array (which can sometimes be interpreted as UTF-8).

The following are such interfaces.  Also, see L</The "Unicode Bug">.
For all of these interfaces Perl
currently (as of v5.16.0) simply assumes byte strings both as arguments
and results, or UTF-8 strings if the (deprecated) C<encoding> pragma has been used.

One reason that Perl does not attempt to resolve the role of Unicode in
these situations is that the answers are highly dependent on the operating
system and the file system(s).  For example, whether filenames can be
in Unicode and in exactly what kind of encoding, is not exactly a
portable concept.  Similarly for C<qx> and C<system>: how well will the
"command-line interface" (and which of them?) handle Unicode?

=over 4

=item *

C<chdir>, C<chmod>, C<chown>, C<chroot>, C<exec>, C<link>, C<lstat>, C<mkdir>,
C<rename>, C<rmdir>, C<stat>, C<symlink>, C<truncate>, C<unlink>, C<utime>, C<-X>

=item *

C<%ENV>

=item *

C<glob> (aka the C<E<lt>*E<gt>>)

=item *

C<open>, C<opendir>, C<sysopen>

=item *

C<qx> (aka the backtick operator), C<system>

=item *

C<readdir>, C<readlink>

=back

=head2 The "Unicode Bug"

The term, "Unicode bug" has been applied to an inconsistency with the
code points in the C<Latin-1 Supplement> block, that is, between
128 and 255.  Without a locale specified, unlike all other characters or
code points, these characters can have very different semantics
depending on the rules in effect.  (Characters whose code points are
above 255 force Unicode rules; whereas the rules for ASCII characters
are the same under both ASCII and Unicode rules.)

Under Unicode rules, these upper-Latin1 characters are interpreted as
Unicode code points, which means they have the same semantics as Latin-1
(ISO-8859-1) and C1 controls.

As explained in L</ASCII Rules versus Unicode Rules>, under ASCII rules,
they are considered to be unassigned characters.

This can lead to unexpected results.  For example, a string's
semantics can suddenly change if a code point above 255 is appended to
it, which changes the rules from ASCII to Unicode.  As an
example, consider the following program and its output:

 $ perl -le'
     no feature "unicode_strings";
     $s1 = "\xC2";
     $s2 = "\x{2660}";
     for ($s1, $s2, $s1.$s2) {
         print /\w/ || 0;
     }
 '
 0
 0
 1

If there's no C<\w> in C<s1> nor in C<s2>, why does their concatenation
have one?

This anomaly stems from Perl's attempt to not disturb older programs that
didn't use Unicode, along with Perl's desire to add Unicode support
seamlessly.  But the result turned out to not be seamless.  (By the way,
you can choose to be warned when things like this happen.  See
C<L<encoding::warnings>>.)

L<S<C<use feature 'unicode_strings'>>|feature/The 'unicode_strings' feature>
was added, starting in Perl v5.12, to address this problem.  It affects
these things:

=over 4

=item *

Changing the case of a scalar, that is, using C<uc()>, C<ucfirst()>, C<lc()>,
and C<lcfirst()>, or C<\L>, C<\U>, C<\u> and C<\l> in double-quotish
contexts, such as regular expression substitutions.

Under C<unicode_strings> starting in Perl 5.12.0, Unicode rules are
generally used.  See L<perlfunc/lc> for details on how this works
in combination with various other pragmas.

=item *

Using caseless (C</i>) regular expression matching.

Starting in Perl 5.14.0, regular expressions compiled within
the scope of C<unicode_strings> use Unicode rules
even when executed or compiled into larger
regular expressions outside the scope.

=item *

Matching any of several properties in regular expressions.

These properties are C<\b> (without braces), C<\B> (without braces),
C<\s>, C<\S>, C<\w>, C<\W>, and all the Posix character classes
I<except> C<[[:ascii:]]>.

Starting in Perl 5.14.0, regular expressions compiled within
the scope of C<unicode_strings> use Unicode rules
even when executed or compiled into larger
regular expressions outside the scope.

=item *

In C<quotemeta> or its inline equivalent C<\Q>.

Starting in Perl 5.16.0, consistent quoting rules are used within the
scope of C<unicode_strings>, as described in L<perlfunc/quotemeta>.
Prior to that, or outside its scope, no code points above 127 are quoted
in UTF-8 encoded strings, but in byte encoded strings, code points
between 128-255 are always quoted.

=item *

In the C<..> or L<range|perlop/Range Operators> operator.

Starting in Perl 5.26.0, the range operator on strings treats their lengths
consistently within the scope of C<unicode_strings>. Prior to that, or
outside its scope, it could produce strings whose length in characters
exceeded that of the right-hand side, where the right-hand side took up more
bytes than the correct range endpoint.

=item *

In L<< C<split>'s special-case whitespace splitting|perlfunc/split >>.

Starting in Perl 5.28.0, the C<split> function with a pattern specified as
a string containing a single space handles whitespace characters consistently
within the scope of C<unicode_strings>. Prior to that, or outside its scope,
characters that are whitespace according to Unicode rules but not according to
ASCII rules were treated as field contents rather than field separators when
they appear in byte-encoded strings.

=back

You can see from the above that the effect of C<unicode_strings>
increased over several Perl releases.  (And Perl's support for Unicode
continues to improve; it's best to use the latest available release in
order to get the most complete and accurate results possible.)  Note that
C<unicode_strings> is automatically chosen if you S<C<use v5.12>> or
higher.

For Perls earlier than those described above, or when a string is passed
to a function outside the scope of C<unicode_strings>, see the next section.

=head2 Forcing Unicode in Perl (Or Unforcing Unicode in Perl)

Sometimes (see L</"When Unicode Does Not Happen"> or L</The "Unicode Bug">)
there are situations where you simply need to force a byte
string into UTF-8, or vice versa.  The standard module L<Encode> can be
used for this, or the low-level calls
L<C<utf8::upgrade($bytestring)>|utf8/Utility functions> and
L<C<utf8::downgrade($utf8string[, FAIL_OK])>|utf8/Utility functions>.

Note that C<utf8::downgrade()> can fail if the string contains characters
that don't fit into a byte.

