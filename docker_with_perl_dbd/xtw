    # subrepo inherently violates our import layering rules
    # because it wants to make repo objects from deep inside the stack
    # so we manually delay the circular imports to not break
    # scripts that don't use our demand-loading
    global hg
    from . import hg as h

    hg = h

    repo = ctx.repo()
    _auditsubrepopath(repo, path)
    state = ctx.substate[path]
    _checktype(repo.ui, state[2])
    subrev = b''
    if state[2] == b'hg':
        subrev = b"0" * 40
    return types[state[2]](pctx, path, (state[0], subrev), True)


# subrepo classes need to implement the following abstract class:


class abstractsubrepo:
    def __init__(self, ctx, path):
        """Initialize abstractsubrepo part

        ``ctx`` is the context referring this subrepository in the
        parent repository.

        ``path`` is the path to this subrepository as seen from
        innermost repository.
        """
        self.ui = ctx.repo().ui
        self._ctx = ctx
        self._path = path

    def addwebdirpath(self, serverpath, webconf):
        """Add the hgwebdir entries for this subrepo, and any of its subrepos.

        ``serverpath`` is the path component of the URL for this repo.

        ``webconf`` is the dictionary of hgwebdir entries.
        """
        pass

    def storeclean(self, path):
        """
        returns true if the repository has not changed since it was last
        cloned from or pushed to a given repository.
        """
        return False

    def dirty(self, ignoreupdate=False, missing=False):
        """returns true if the dirstate of the subrepo is dirty or does not
        match current stored state. If ignoreupdate is true, only check
        whether the subrepo has uncommitted changes in its dirstate.  If missing
        is true, check for deleted files.
        """
        raise NotImplementedError

    def dirtyreason(self, ignoreupdate=False, missing=False):
        """return reason string if it is ``dirty()``

        Returned string should have enough information for the message
        of exception.

        This returns None, otherwise.
        """
        if self.dirty(ignoreupdate=ignoreupdate, missing=missing):
            return _(b'uncommitted changes in subrepository "%s"') % subrelpath(
                self
            )

    def bailifchanged(self, ignoreupdate=False, hint=None):
        """raise Abort if subrepository is ``dirty()``"""
        dirtyreason = self.dirtyreason(ignoreupdate=ignoreupdate, missing=True)
        if dirtyreason:
            raise error.Abort(dirtyreason, hint=hint)

    def basestate(self):
        """current working directory base state, disregarding .hgsubstate
        state and working directory modifications"""
        raise NotImplementedError

    def checknested(self, path):
        """check if path is a subrepository within this repository"""
        return False

    def commit(self, text, user, date):
        """commit the current changes to the subrepo with the given
        log message. Use given user and date if possible. Return the
        new state of the subrepo.
        """
        raise NotImplementedError

    def phase(self, state):
        """returns phase of specified state in the subrepository."""
        return phases.public

    def remove(self):
        """remove the subrepo

        (should verify the dirstate is not dirty first)
        """
        raise NotImplementedError

    def get(self, state, overwrite=False):
        """run whatever commands are needed to put the subrepo into
        this state
        """
        raise NotImplementedError

    def merge(self, state):
        """merge currently-saved state with the new state."""
        raise NotImplementedError

    def push(self, opts):
        """perform whatever action is analogous to 'hg push'

        This may be a no-op on some systems.
        """
        raise NotImplementedError

    def add(self, ui, match, prefix, uipathfn, explicitonly, **opts):
        return []

    def addremove(self, matcher, prefix, uipathfn, opts):
        self.ui.warn(b"%s: %s" % (prefix, _(b"addremove is not supported")))
        return 1

    def cat(self, match, fm, fntemplate, prefix, **opts):
        return 1

    def status(self, rev2, **opts):
        return scmutil.status([], [], [], [], [], [], [])

    def diff(self, ui, diffopts, node2, match, prefix, **opts):
        pass

    def outgoing(self, ui, dest, opts):
        return 1

    def incoming(self, ui, source, opts):
        return 1

    def files(self):
        """return filename iterator"""
        raise NotImplementedError

    def filedata(self, name, decode):
        """return file data, optionally passed through repo decoders"""
        raise NotImplementedError

    def fileflags(self, name):
        """return file flags"""
        return b''

    def matchfileset(self, cwd, expr, badfn=None):
        """Resolve the fileset expression for this repo"""
        return matchmod.never(badfn=badfn)

    def printfiles(self, ui, m, uipathfn, fm, fmt, subrepos):
        """handle the files command for this subrepo"""
        return 1

    def archive(self, archiver, prefix, match=None, decode=True):
        if match is not None:
            files = [f for f in self.files() if match(f)]
        else:
            files = self.files()
        total = len(files)
        relpath = subrelpath(self)
        progress = self.ui.makeprogress(
            _(b'archiving (%s)') % relpath, unit=_(b'files'), total=total
        )
        progress.update(0)
        for name in files:
            flags = self.fileflags(name)
            mode = b'x' in flags and 0o755 or 0o644
            symlink = b'l' in flags
            archiver.addfile(
                prefix + name, mode, symlink, self.filedata(name, decode)
            )
            progress.increment()
        progress.complete()
        return total

    def walk(self, match):
        """
        walk recursively through the directory tree, finding all files
        matched by the match function
        """

    def forget(self, match, prefix, uipathfn, dryrun, interactive):
        return ([], [])

    def removefiles(
        self,
        matcher,
        prefix,
        uipathfn,
        after,
        force,
        subrepos,
        dryrun,
        warnings,
    ):
        """remove the matched files from the subrepository and the filesystem,
        possibly by force and/or after the file has been removed from the
        filesystem.  Return 0 on success, 1 on any warning.
        """
        warnings.append(
            _(b"warning: removefiles not implemented (%s)") % self._path
        )
        return 1

    def revert(self, substate, *pats, **opts):
        self.ui.warn(
            _(b'%s: reverting %s subrepos is unsupported\n')
            % (substate[0], substate[2])
        )
        return []

    def shortid(self, revid):
        return revid

    def unshare(self):
        """
        convert this repository from shared to normal storage.
        """

    def verify(self, onpush=False):
        """verify the revision of this repository that is held in `_state` is
        present and not hidden.  Return 0 on success or warning, 1 on any
        error.  In the case of ``onpush``, warnings or errors will raise an
        exception if the result of pushing would be a broken remote repository.
        """
        return 0

    @propertycache
    def wvfs(self):
        """return vfs to access the working directory of this subrepository"""
        return vfsmod.vfs(self._ctx.repo().wvfs.join(self._path))

    @propertycache
    def _relpath(self):
        """return path to this subrepository as seen from outermost repository"""
        return self.wvfs.reljoin(reporelpath(self._ctx.repo()), self._path)


class hgsubrepo(abstractsubrepo):
    def __init__(self, ctx, path, state, allowcreate):
        super(hgsubrepo, self).__init__(ctx, path)
        self._state = state
        r = ctx.repo()
        root = r.wjoin(util.localpath(path))
        create = allowcreate and not r.wvfs.exists(b'%s/.hg' % path)
        # repository constructor does expand variables in path, which is
        # unsafe since subrepo path might come from untrusted source.
        norm_root = os.path.normcase(root)
        real_root = os.path.normcase(os.path.realpath(util.expandpath(root)))
        if real_root != norm_root:
            raise error.Abort(
                _(b'subrepo path contains illegal component: %s') % path
            )
        self._repo = hg.repository(r.baseui, root, create=create)
        if os.path.normcase(self._repo.root) != os.path.normcase(root):
            raise error.ProgrammingError(
                b'failed to reject unsafe subrepo '
                b'path: %s (expanded to %s)' % (root, self._repo.root)
            )

        # Propagate the parent's --hidden option
        if r is r.unfiltered():
            self._repo = self._repo.unfiltered()

        self.ui = self._repo.ui
        for s, k in [(b'ui', b'commitsubrepos')]:
            v = r.ui.config(s, k)
            if v:
                self.ui.setconfig(s, k, v, b'subrepo')
        # internal config: ui._usedassubrepo
        self.ui.setconfig(b'ui', b'_usedassubrepo', b'True', b'subrepo')
        self._initrepo(r, state[0], create)

    @annotatesubrepoerror
    def addwebdirpath(self, serverpath, webconf):
        cmdutil.addwebdirpath(self._repo, subrelpath(self), webconf)

    def storeclean(self, path):
        with self._repo.lock():
            return self._storeclean(path)

    def _storeclean(self, path):
        clean = True
        itercache = self._calcstorehash(path)
        for filehash in self._readstorehashcache(path):
            if filehash != next(itercache, None):
                clean = False
                break
        if clean:
            # if not empty:
            # the cached and current pull states have a different size
            clean = next(itercache, None) is None
        return clean

    def _calcstorehash(self, remotepath):
        """calculate a unique "store hash"

        This method is used to to detect when there are changes that may
        require a push to a given remote path."""
        # sort the files that will be hashed in increasing (likely) file size
        filelist = (b'bookmarks', b'store/phaseroots', b'store/00changelog.i')
        yield b'# %s\n' % _expandedabspath(remotepath)
        vfs = self._repo.vfs
        for relname in filelist:
            filehash = hex(hashutil.sha1(vfs.tryread(relname)).digest())
            yield b'%s = %s\n' % (relname, filehash)

    @propertycache
    def _cachestorehashvfs(self):
        return vfsmod.vfs(self._repo.vfs.join(b'cache/storehash'))

    def _readstorehashcache(self, remotepath):
        '''read the store hash cache for a given remote repository'''
        cachefile = _getstorehashcachename(remotepath)
        return self._cachestorehashvfs.tryreadlines(cachefile, b'r')

    def _cachestorehash(self, remotepath):
        """cache the current store hash

        Each remote repo requires its own store hash cache, because a subrepo
        store may be "clean" versus a given remote repo, but not versus another
        """
        cachefile = _getstorehashcachename(remotepath)
        with self._repo.lock():
            storehash = list(self._calcstorehash(remotepath))
            vfs = self._cachestorehashvfs
            vfs.writelines(cachefile, storehash, mode=b'wb', notindexed=True)

    def _getctx(self):
        """fetch the context for this subrepo revision, possibly a workingctx"""
        if self._ctx.rev() is None:
            return self._repo[None]  # workingctx if parent is workingctx
        else:
            rev = self._state[1]
            return self._repo[rev]

    @annotatesubrepoerror
    def _initrepo(self, parentrepo, source, create):
        self._repo._subparent = parentrepo
        self._repo._subsource = source

        if create:
            lines = [b'[paths]\n']

            def addpathconfig(key, value):
                if value:
                    lines.append(b'%s = %s\n' % (key, value))
                    self.ui.setconfig(b'paths', key, value, b'subrepo')

            defpath = _abssource(self._repo, abort=False)
            defpushpath = _abssource(self._repo, True, abort=False)
            addpathconfig(b'default', defpath)
            if defpath != defpushpath:
                addpathconfig(b'default-push', defpushpath)

            self._repo.vfs.write(b'hgrc', util.tonativeeol(b''.join(lines)))

    @annotatesubrepoerror
    def add(self, ui, match, prefix, uipathfn, explicitonly, **opts):
        return cmdutil.add(
            ui, self._repo, match, prefix, uipathfn, explicitonly, **opts
        )

    @annotatesubrepoerror
    def addremove(self, m, prefix, uipathfn, opts):
        # In the same way as sub directories are processed, once in a subrepo,
        # always entry any of its subrepos.  Don't corrupt the options that will
        # be used to process sibling subrepos however.
        opts = copy.copy(opts)
        opts[b'subrepos'] = True
        return scmutil.addremove(self._repo, m, prefix, uipathfn, opts)

    @annotatesubrepoerror
    def cat(self, match, fm, fntemplate, prefix, **opts):
        rev = self._state[1]
        ctx = self._repo[rev]
        return cmdutil.cat(
            self.ui, self._repo, ctx, match, fm, fntemplate, prefix, **opts
        )

    @annotatesubrepoerror
    def status(self, rev2, **opts):
        try:
            rev1 = self._state[1]
            ctx1 = self._repo[rev1]
            ctx2 = self._repo[rev2]
            return self._repo.status(ctx1, ctx2, **opts)
        except error.RepoLookupError as inst:
            self.ui.warn(
                _(b'warning: error "%s" in subrepository "%s"\n')
                % (inst, subrelpath(self))
            )
            return scmutil.status([], [], [], [], [], [], [])

    @annotatesubrepoerror
    def diff(self, ui, diffopts, node2, match, prefix, **opts):
        try:
            node1 = bin(self._state[1])
            # We currently expect node2 to come from substate and be
            # in hex format
            if node2 is not None:
                node2 = bin(node2)
            logcmdutil.diffordiffstat(
                ui,
                self._repo,
                diffopts,
                self._repo[node1],
                self._repo[node2],
                match,
                prefix=prefix,
                listsubrepos=True,
                **opts
            )
        except error.RepoLookupError as inst:
            self.ui.warn(
                _(b'warning: error "%s" in subrepository "%s"\n')
                % (inst, subrelpath(self))
            )

    @annotatesubrepoerror
    def archive(self, archiver, prefix, match=None, decode=True):
        self._get(self._state + (b'hg',))
        files = self.files()
        if match:
            files = [f for f in files if match(f)]
        rev = self._state[1]
        ctx = self._repo[rev]
        scmutil.prefetchfiles(
            self._repo, [(ctx.rev(), scmutil.matchfiles(self._repo, files))]
        )
        total = abstractsubrepo.archive(self, archiver, prefix, match)
        for subpath in ctx.substate:
            s = subrepo(ctx, subpath, True)
            submatch = matchmod.subdirmatcher(subpath, match)
            subprefix = prefix + subpath + b'/'
            total += s.archive(archiver, subprefix, submatch, decode)
        return total

    @annotatesubrepoerror
    def dirty(self, ignoreupdate=False, missing=False):
        r = self._state[1]
        if r == b'' and not ignoreupdate:  # no state recorded
            return True
        w = self._repo[None]
        if r != w.p1().hex() and not ignoreupdate:
            # different version checked out
            return True
        return w.dirty(missing=missing)  # working directory changed

    def basestate(self):
        return self._repo[b'.'].hex()

    def checknested(self, path):
        return self._repo._checknested(self._repo.wjoin(path))

    @annotatesubrepoerror
    def commit(self, text, user, date):
        # don't bother committing in the subrepo if it's only been
        # updated
        if not self.dirty(True):
            return self._repo[b'.'].hex()
        self.ui.debug(b"committing subrepo %s\n" % subrelpath(self))
        n = self._repo.commit(text, user, date)
        if not n:
            return self._repo[b'.'].hex()  # different version checked out
        return hex(n)

    @annotatesubrepoerror
    def phase(self, state):
        return self._repo[state or b'.'].phase()

    @annotatesubrepoerror
    def remove(self):
        # we can't fully delete the repository as it may contain
        # local-only history
        self.ui.note(_(b'removing subrepo %s\n') % subrelpath(self))
        hg.clean(self._repo, self._repo.nullid, False)

    def _get(self, state):
        source, revision, kind = state
        parentrepo = self._repo._subparent

        if revision in self._repo.unfiltered():
            # Allow shared subrepos tracked at null to setup the sharedpath
            if len(self._repo) != 0 or not parentrepo.shared():
                return True
        self._repo._subsource = source
        srcurl = _abssource(self._repo)

        # Defer creating the peer until after the status message is logged, in
        # case there are network problems.
        getpeer = lambda: hg.peer(self._repo, {}, srcurl)

        if len(self._repo) == 0:
            # use self._repo.vfs instead of self.wvfs to remove .hg only
            self._repo.vfs.rmtree()

            # A remote subrepo could be shared if there is a local copy
            # relative to the parent's share source.  But clone pooling doesn't
            # assemble the repos in a tree, so that can't be consistently done.
            # A simpler option is for the user to configure clone pooling, and
            # work with that.
            if parentrepo.shared() and hg.islocal(srcurl):
                self.ui.status(
                    _(b'sharing subrepo %s from %s\n')
                    % (subrelpath(self), srcurl)
                )
                peer = getpeer()
                try:
                    shared = hg.share(
                        self._repo._subparent.baseui,
                        peer,
                        self._repo.root,
                        update=False,
                        bookmarks=False,
                    )
                finally:
                    peer.close()
                self._repo = shared.local()
            else:
                # TODO: find a common place for this and this code in the
                # share.py wrap of the clone command.
                if parentrepo.shared():
                    pool = self.ui.config(b'share', b'pool')
                    if pool:
                        pool = util.expandpath(pool)

                    shareopts = {
                        b'pool': pool,
                        b'mode': self.ui.config(b'share', b'poolnaming'),
                    }
                else:
                    shareopts = {}

                self.ui.status(
                    _(b'cloning subrepo %s from %s\n')
                    % (subrelpath(self), urlutil.hidepassword(srcurl))
                )
                peer = getpeer()
                try:
                    other, cloned = hg.clone(
                        self._repo._subparent.baseui,
                        {},
                        peer,
                        self._repo.root,
                        update=False,
                        shareopts=shareopts,
                    )
                finally:
                    peer.close()
                self._repo = cloned.local()
            self._initrepo(parentrepo, source, create=True)
            self._cachestorehash(srcurl)
        else:
            self.ui.status(
                _(b'pulling subrepo %s from %s\n')
                % (subrelpath(self), urlutil.hidepassword(srcurl))
            )
            cleansub = self.storeclean(srcurl)
            peer = getpeer()
            try:
                exchange.pull(self._repo, peer)
            finally:
                peer.close()
            if cleansub:
                # keep the repo clean after pull
                self._cachestorehash(srcurl)
        return False

    @annotatesubrepoerror
    def get(self, state, overwrite=False):
        inrepo = self._get(state)
        source, revision, kind = state
        repo = self._repo
        repo.ui.debug(b"getting subrepo %s\n" % self._path)
        if inrepo:
            urepo = repo.unfiltered()
            ctx = urepo[revision]
            if ctx.hidden():
                urepo.ui.warn(
                    _(b'revision %s in subrepository "%s" is hidden\n')
                    % (revision[0:12], self._path)
                )
                repo = urepo
        if overwrite:
            merge.clean_update(repo[revision])
        else:
            merge.update(repo[revision])

    @annotatesubrepoerror
    def merge(self, state):
        self._get(state)
        cur = self._repo[b'.']
        dst = self._repo[state[1]]
        anc = dst.ancestor(cur)

        def mergefunc():
            if anc == cur and dst.branch() == cur.branch():
                self.ui.debug(
                    b'updating subrepository "%s"\n' % subrelpath(self)
                )
                hg.update(self._repo, state[1])
            elif anc == dst:
                self.ui.debug(
                    b'skipping subrepository "%s"\n' % subrelpath(self)
                )
            else:
                self.ui.debug(
                    b'merging subrepository "%s"\n' % subrelpath(self)
                )
                hg.merge(dst, remind=False)

        wctx = self._repo[None]
        if self.dirty():
            if anc != dst:
                if _updateprompt(self.ui, self, wctx.dirty(), cur, dst):
                    mergefunc()
            else:
                mergefunc()
        else:
            mergefunc()

    @annotatesubrepoerror
    def push(self, opts):
        force = opts.get(b'force')
        newbranch = opts.get(b'new_branch')
        ssh = opts.get(b'ssh')

        # push subrepos depth-first for coherent ordering
        c = self._repo[b'.']
        subs = c.substate  # only repos that are committed
        for s in sorted(subs):
            if c.sub(s).push(opts) == 0:
                return False

        dsturl = _abssource(self._repo, True)
        if not force:
            if self.storeclean(dsturl):
                self.ui.status(
                    _(b'no changes made to subrepo %s since last push to %s\n')
                    % (subrelpath(self), urlutil.hidepassword(dsturl))
                )
                return None
        self.ui.status(
            _(b'pushing subrepo %s to %s\n')
            % (subrelpath(self), urlutil.hidepassword(dsturl))
        )
        other = hg.peer(self._repo, {b'ssh': ssh}, dsturl)
        try:
            res = exchange.push(self._repo, other, force, newbranch=newbranch)
        finally:
            other.close()

        # the repo is now clean
        self._cachestorehash(dsturl)
        return res.cgresult

    @annotatesubrepoerror
    def outgoing(self, ui, dest, opts):
        if b'rev' in opts or b'branch' in opts:
            opts = copy.copy(opts)
            opts.pop(b'rev', None)
            opts.pop(b'branch', None)
        subpath = subrepoutil.repo_rel_or_abs_source(self._repo)
        return hg.outgoing(ui, self._repo, dest, opts, subpath=subpath)

    @annotatesubrepoerror
    def incoming(self, ui, source, opts):
        if b'rev' in opts or b'branch' in opts:
            opts = copy.copy(opts)
            opts.pop(b'rev', None)
            opts.pop(b'branch', None)
        subpath = subrepoutil.repo_rel_or_abs_source(self._repo)
        return hg.incoming(ui, self._repo, source, opts, subpath=subpath)

    @annotatesubrepoerror
    def files(self):
        rev = self._state[1]
        ctx = self._repo[rev]
        return ctx.manifest().keys()

    def filedata(self, name, decode):
        rev = self._state[1]
        data = self._repo[rev][name].data()
        if decode:
            data = self._repo.wwritedata(name, data)
        return data

    def fileflags(self, name):
        rev = self._state[1]
        ctx = self._repo[rev]
        return ctx.flags(name)

    @annotatesubrepoerror
    def printfiles(self, ui, m, uipathfn, fm, fmt, subrepos):
        # If the parent context is a workingctx, use the workingctx here for
        # consistency.
        if self._ctx.rev() is None:
            ctx = self._repo[None]
        else:
            rev = self._state[1]
            ctx = self._repo[rev]
        return cmdutil.files(ui, ctx, m, uipathfn, fm, fmt, subrepos)

    @annotatesubrepoerror
    def matchfileset(self, cwd, expr, badfn=None):
        if self._ctx.rev() is None:
            ctx = self._repo[None]
        else:
            rev = self._state[1]
            ctx = self._repo[rev]

        matchers = [ctx.matchfileset(cwd, expr, badfn=badfn)]

        for subpath in ctx.substate:
            sub = ctx.sub(subpath)

            try:
                sm = sub.matchfileset(cwd, expr, badfn=badfn)
                pm = matchmod.prefixdirmatcher(subpath, sm, badfn=badfn)
                matchers.append(pm)
            except error.LookupError:
                self.ui.status(
                    _(b"skipping missing subrepository: %s\n")
                    % self.wvfs.reljoin(reporelpath(self), subpath)
                )
        if len(matchers) == 1:
            return matchers[0]
        return matchmod.unionmatcher(matchers)

    def walk(self, match):
        ctx = self._repo[None]
        return ctx.walk(match)

    @annotatesubrepoerror
    def forget(self, match, prefix, uipathfn, dryrun, interactive):
        return cmdutil.forget(
            self.ui,
            self._repo,
            match,
            prefix,
            uipathfn,
            True,
            dryrun=dryrun,
            interactive=interactive,
        )

    @annotatesubrepoerror
    def removefiles(
        self,
        matcher,
        prefix,
        uipathfn,
        after,
        force,
        subrepos,
        dryrun,
        warnings,
    ):
        return cmdutil.remove(
            self.ui,
            self._repo,
            matcher,
            prefix,
            uipathfn,
            after,
            force,
            subrepos,
            dryrun,
        )

    @annotatesubrepoerror
    def revert(self, substate, *pats, **opts):
        # reverting a subrepo is a 2 step process:
        # 1. if the no_backup is not set, revert all modified
        #    files inside the subrepo
        # 2. update the subrepo to the revision specified in
        #    the corresponding substate dictionary
        self.ui.status(_(b'reverting subrepo %s\n') % substate[0])
        if not opts.get('no_backup'):
            # Revert all files on the subrepo, creating backups
            # Note that this will not recursively revert subrepos
            # We could do it if there was a set:subrepos() predicate
            opts = opts.copy()
            opts['date'] = None
            opts['rev'] = substate[1]

            self.filerevert(*pats, **opts)

        # Update the repo to the revision specified in the given substate
        if not opts.get('dry_run'):
            self.get(substate, overwrite=True)

    def filerevert(self, *pats, **opts):
        ctx = self._repo[opts['rev']]
        if opts.get('all'):
            pats = [b'set:modified()']
        else:
            pats = []
        cmdutil.revert(self.ui, self._repo, ctx, *pats, **opts)

    def shortid(self, revid):
        return revid[:12]

    @annotatesubrepoerror
    def unshare(self):
        # subrepo inherently violates our import layering rules
        # because it wants to make repo objects from deep inside the stack
        # so we manually delay the circular imports to not break
        # scripts that don't use our demand-loading
        global hg
        from . import hg as h

        hg = h

        # Nothing prevents a user from sharing in a repo, and then making that a
        # subrepo.  Alternately, the previous unshare attempt may have failed
        # part way through.  So recurse whether or not this layer is shared.
        if self._repo.shared():
            self.ui.status(_(b"unsharing subrepo '%s'\n") % self._relpath)

        hg.unshare(self.ui, self._repo)

    def verify(self, onpush=False):
        try:
            rev = self._state[1]
            ctx = self._repo.unfiltered()[rev]
            if ctx.hidden():
                # Since hidden revisions aren't pushed/pulled, it seems worth an
                # explicit warning.
                msg = _(b"subrepo '%s' is hidden in revision %s") % (
                    self._relpath,
                    short(self._ctx.node()),
                )

                if onpush:
                    raise error.Abort(msg)
                else:
                    self._repo.ui.warn(b'%s\n' % msg)
            return 0
        except error.RepoLookupError:
            # A missing subrepo revision may be a case of needing to pull it, so
            # don't treat this as an error for `hg verify`.
            msg = _(b"subrepo '%s' not found in revision %s") % (
                self._relpath,
                short(self._ctx.node()),
            )

            if onpush:
                raise error.Abort(msg)
            else:
                self._repo.ui.warn(b'%s\n' % msg)
            return 0

    @propertycache
    def wvfs(self):
        """return own wvfs for efficiency and consistency"""
        return self._repo.wvfs

    @propertycache
    def _relpath(self):
        """return path to this subrepository as seen from outermost repository"""
        # Keep consistent dir separators by avoiding vfs.join(self._path)
        return reporelpath(self._repo)


class svnsubrepo(abstractsubrepo):
    def __init__(self, ctx, path, state, allowcreate):
        super(svnsubrepo, self).__init__(ctx, path)
        self._state = state
        self._exe = procutil.findexe(b'svn')
        if not self._exe:
            raise error.Abort(
                _(b"'svn' executable not found for subrepo '%s'") % self._path
            )

    def _svncommand(self, commands, filename=b'', failok=False):
        cmd = [self._exe]
        extrakw = {}
        if not self.ui.interactive():
            # Making stdin be a pipe should prevent svn from behaving
            # interactively even if we can't pass --non-interactive.
            extrakw['stdin'] = subprocess.PIPE
            # Starting in svn 1.5 --non-interactive is a global flag
            # instead of being per-command, but we need to support 1.4 so
            # we have to be intelligent about what commands take
            # --non-interactive.
            if commands[0] in (b'update', b'checkout', b'commit'):
                cmd.append(b'--non-interactive')
        if util.safehasattr(subprocess, 'CREATE_NO_WINDOW'):
            # On Windows, prevent command prompts windows from popping up when
            # running in pythonw.
            extrakw['creationflags'] = getattr(subprocess, 'CREATE_NO_WINDOW')
        cmd.extend(commands)
        if filename is not None:
            path = self.wvfs.reljoin(
                self._ctx.repo().origroot, self._path, filename
            )
            cmd.append(path)
        env = dict(encoding.environ)
        # Avoid localized output, preserve current locale for everything else.
        lc_all = env.get(b'LC_ALL')
        if lc_all:
            env[b'LANG'] = lc_all
            del env[b'LC_ALL']
        env[b'LC_MESSAGES'] = b'C'
        p = subprocess.Popen(
            pycompat.rapply(procutil.tonativestr, cmd),
            bufsize=-1,
            close_fds=procutil.closefds,
            stdout=subprocess.PIPE,
            stderr=subprocess.PIPE,
            env=procutil.tonativeenv(env),
            **extrakw
        )
        stdout, stderr = map(util.fromnativeeol, p.communicate())
        stderr = stderr.strip()
        if not failok:
            if p.returncode:
                raise error.Abort(
                    stderr or b'exited with code %d' % p.returncode
                )
            if stderr:
                self.ui.warn(stderr + b'\n')
        return stdout, stderr

    @propertycache
    def _svnversion(self):
        output, err = self._svncommand(
            [b'--version', b'--quiet'], filename=None
        )
        m = re.search(br'^(\d+)\.(\d+)', output)
        if not m:
            raise error.Abort(_(b'cannot retrieve svn tool version'))
        return (int(m.group(1)), int(m.group(2)))

    def _svnmissing(self):
        return not self.wvfs.exists(b'.svn')

    def _wcrevs(self):
        # Get the working directory revision as well as the last
        # commit revision so we can compare the subrepo state with
        # both. We used to store the working directory one.
        output, err = self._svncommand([b'info', b'--xml'])
        doc = xml.dom.minidom.parseString(output)  # pytype: disable=pyi-error
        entries = doc.getElementsByTagName('entry')
        lastrev, rev = b'0', b'0'
        if entries:
            rev = pycompat.bytestr(entries[0].getAttribute('revision')) or b'0'
            commits = entries[0].getElementsByTagName('commit')
            if commits:
                lastrev = (
                    pycompat.bytestr(commits[0].getAttribute('revision'))
                    or b'0'
                )
        return (lastrev, rev)

    def _wcrev(self):
        return self._wcrevs()[0]

    def _wcchanged(self):
        """Return (changes, extchanges, missing) where changes is True
        if the working directory was changed, extchanges is
        True if any of these changes concern an external entry and missing
        is True if any change is a missing entry.
        """
        output, err = self._svncommand([b'status', b'--xml'])
        externals, changes, missing = [], [], []
        doc = xml.dom.minidom.parseString(output)  # pytype: disable=pyi-error
        for e in doc.getElementsByTagName('entry'):
            s = e.getElementsByTagName('wc-status')
            if not s:
                continue
            item = s[0].getAttribute('item')
            props = s[0].getAttribute('props')
            path = e.getAttribute('path').encode('utf8')
            if item == 'external':
                externals.append(path)
            elif item == 'missing':
                missing.append(path)
            if (
                item
                not in (
                    '',
                    'normal',
                    'unversioned',
                    'external',
                )
