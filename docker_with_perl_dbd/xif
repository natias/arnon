                    b"multiple revisions"
                )
            )

    def setrevmap(self, revmap):
        """Sets the parsed revmap dictionary.

        Revmap stores mappings from a source revision to a target revision.
        It is set in convertcmd.convert and provided by the user as a file
        on the commandline.

        Revisions in the map are considered beeing present in the
        repository and ignored during _parse(). This allows for incremental
        imports if a revmap is provided.
        """
        self.revmap = revmap

    def _parse_view(self, path):
        """Read changes affecting the path"""
        cmd = b'p4 -G changes -s submitted %s' % procutil.shellquote(path)
        stdout = procutil.popen(cmd, mode=b'rb')
        p4changes = {}
        for d in loaditer(stdout):
            c = d.get(b"change", None)
            if c:
                p4changes[c] = True
        return p4changes

    def _parse(self, ui, path):
        """Prepare list of P4 filenames and revisions to import"""
        p4changes = {}
        changeset = {}
        files_map = {}
        copies_map = {}
        localname = {}
        depotname = {}
        heads = []

        ui.status(_(b'reading p4 views\n'))

        # read client spec or view
        if b"/" in path:
            p4changes.update(self._parse_view(path))
            if path.startswith(b"//") and path.endswith(b"/..."):
                views = {path[:-3]: b""}
            else:
                views = {b"//": b""}
        else:
            cmd = b'p4 -G client -o %s' % procutil.shellquote(path)
            clientspec = marshal.load(procutil.popen(cmd, mode=b'rb'))

            views = {}
            for client in clientspec:
                if client.startswith(b"View"):
                    sview, cview = clientspec[client].split()
                    p4changes.update(self._parse_view(sview))
                    if sview.endswith(b"...") and cview.endswith(b"..."):
                        sview = sview[:-3]
                        cview = cview[:-3]
                    cview = cview[2:]
                    cview = cview[cview.find(b"/") + 1 :]
                    views[sview] = cview

        # list of changes that affect our source files
        p4changes = sorted(p4changes.keys(), key=int)

        # list with depot pathnames, longest first
        vieworder = sorted(views.keys(), key=len, reverse=True)

        # handle revision limiting
        startrev = self.ui.config(b'convert', b'p4.startrev')

        # now read the full changelists to get the list of file revisions
        ui.status(_(b'collecting p4 changelists\n'))
        lastid = None
        for change in p4changes:
            if startrev and int(change) < int(startrev):
                continue
            if self.revs and int(change) > int(self.revs[0]):
                continue
            if change in self.revmap:
                # Ignore already present revisions, but set the parent pointer.
                lastid = change
                continue

            if lastid:
                parents = [lastid]
            else:
                parents = []

            d = self._fetch_revision(change)
            c = self._construct_commit(d, parents)

            descarr = c.desc.splitlines(True)
            if len(descarr) > 0:
                shortdesc = descarr[0].rstrip(b'\r\n')
            else:
                shortdesc = b'**empty changelist description**'

            t = b'%s %s' % (c.rev, shortdesc)
            ui.status(stringutil.ellipsis(t, 80) + b'\n')

            files = []
            copies = {}
            copiedfiles = []
            i = 0
            while (b"depotFile%d" % i) in d and (b"rev%d" % i) in d:
                oldname = d[b"depotFile%d" % i]
                filename = None
                for v in vieworder:
                    if oldname.lower().startswith(v.lower()):
                        filename = decodefilename(views[v] + oldname[len(v) :])
                        break
                if filename:
                    files.append((filename, d[b"rev%d" % i]))
                    depotname[filename] = oldname
                    if d.get(b"action%d" % i) == b"move/add":
                        copiedfiles.append(filename)
                    localname[oldname] = filename
                i += 1

            # Collect information about copied files
            for filename in copiedfiles:
                oldname = depotname[filename]

                flcmd = b'p4 -G filelog %s' % procutil.shellquote(oldname)
                flstdout = procutil.popen(flcmd, mode=b'rb')

                copiedfilename = None
                for d in loaditer(flstdout):
                    copiedoldname = None

                    i = 0
                    while (b"change%d" % i) in d:
                        if (
                            d[b"change%d" % i] == change
                            and d[b"action%d" % i] == b"move/add"
                        ):
                            j = 0
                            while (b"file%d,%d" % (i, j)) in d:
                                if d[b"how%d,%d" % (i, j)] == b"moved from":
                                    copiedoldname = d[b"file%d,%d" % (i, j)]
                                    break
                                j += 1
                        i += 1

                    if copiedoldname and copiedoldname in localname:
                        copiedfilename = localname[copiedoldname]
                        break

                if copiedfilename:
                    copies[filename] = copiedfilename
                else:
                    ui.warn(
                        _(b"cannot find source for copied file: %s@%s\n")
                        % (filename, change)
                    )

            changeset[change] = c
            files_map[change] = files
            copies_map[change] = copies
            lastid = change

        if lastid and len(changeset) > 0:
            heads = [lastid]

        return {
            b'changeset': changeset,
            b'files': files_map,
            b'copies': copies_map,
            b'heads': heads,
            b'depotname': depotname,
        }

    @util.propertycache
    def _parse_once(self):
        return self._parse(self.ui, self.path)

    @util.propertycache
    def copies(self):
        return self._parse_once[b'copies']

    @util.propertycache
    def files(self):
        return self._parse_once[b'files']

    @util.propertycache
    def changeset(self):
        return self._parse_once[b'changeset']

    @util.propertycache
    def heads(self):
        return self._parse_once[b'heads']

    @util.propertycache
    def depotname(self):
        return self._parse_once[b'depotname']

    def getheads(self):
        return self.heads

    def getfile(self, name, rev):
        cmd = b'p4 -G print %s' % procutil.shellquote(
            b"%s#%s" % (self.depotname[name], rev)
        )

        lasterror = None
        while True:
            stdout = procutil.popen(cmd, mode=b'rb')

            mode = None
            contents = []
            keywords = None

            for d in loaditer(stdout):
                code = d[b"code"]
                data = d.get(b"data")

                if code == b"error":
                    # if this is the first time error happened
                    # re-attempt getting the file
                    if not lasterror:
                        lasterror = IOError(d[b"generic"], data)
                        # this will exit inner-most for-loop
                        break
                    else:
                        raise lasterror

                elif code == b"stat":
                    action = d.get(b"action")
                    if action in [b"purge", b"delete", b"move/delete"]:
                        return None, None
                    p4type = self.re_type.match(d[b"type"])
                    if p4type:
                        mode = b""
                        flags = (p4type.group(1) or b"") + (
                            p4type.group(3) or b""
                        )
                        if b"x" in flags:
                            mode = b"x"
                        if p4type.group(2) == b"symlink":
                            mode = b"l"
                        if b"ko" in flags:
                            keywords = self.re_keywords_old
                        elif b"k" in flags:
                            keywords = self.re_keywords

                elif code == b"text" or code == b"binary":
                    contents.append(data)

                lasterror = None

            if not lasterror:
                break

        if mode is None:
            return None, None

        contents = b''.join(contents)

        if keywords:
            contents = keywords.sub(b"$\\1$", contents)
        if mode == b"l" and contents.endswith(b"\n"):
            contents = contents[:-1]

        return contents, mode

    def getchanges(self, rev, full):
        if full:
            raise error.Abort(_(b"convert from p4 does not support --full"))
        return self.files[rev], self.copies[rev], set()

    def _construct_commit(self, obj, parents=None):
        """
        Constructs a common.commit object from an unmarshalled
        `p4 describe` output
        """
        desc = self.recode(obj.get(b"desc", b""))
        date = (int(obj[b"time"]), 0)  # timezone not set
        if parents is None:
            parents = []

        return common.commit(
            author=self.recode(obj[b"user"]),
            date=dateutil.datestr(date, b'%Y-%m-%d %H:%M:%S %1%2'),
            parents=parents,
            desc=desc,
            branch=None,
            rev=obj[b'change'],
            extra={b"p4": obj[b'change'], b"convert_revision": obj[b'change']},
        )

    def _fetch_revision(self, rev):
        """Return an output of `p4 describe` including author, commit date as
        a dictionary."""
        cmd = b"p4 -G describe -s %s" % rev
        stdout = procutil.popen(cmd, mode=b'rb')
        return marshal.load(stdout)

    def getcommit(self, rev):
        if rev in self.changeset:
            return self.changeset[rev]
        elif rev in self.revmap:
            d = self._fetch_revision(rev)
            return self._construct_commit(d, parents=None)
        raise error.Abort(
            _(b"cannot find %s in the revmap or parsed changesets") % rev
        )

    def gettags(self):
        return {}

    def getchangedfiles(self, rev, i):
        return sorted([x[0] for x in self.files[rev]])
                                                                                                                                                                                                                                                                                              usr/lib/python3/dist-packages/hgext/convert/subversion.py                                           0000644 0000000 0000000 00000171060 14374730616 022336  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # Subversion 1.4/1.5 Python API backend
#
# Copyright(C) 2007 Daniel Holth et al

import codecs
import locale
import os
import pickle
import re
import xml.dom.minidom

from mercurial.i18n import _
from mercurial.pycompat import open
from mercurial import (
    encoding,
    error,
    pycompat,
    util,
    vfs as vfsmod,
)
from mercurial.utils import (
    dateutil,
    procutil,
    stringutil,
)

from . import common

stringio = util.stringio
propertycache = util.propertycache
urlerr = util.urlerr
urlreq = util.urlreq

commandline = common.commandline
commit = common.commit
converter_sink = common.converter_sink
converter_source = common.converter_source
decodeargs = common.decodeargs
encodeargs = common.encodeargs
makedatetimestamp = common.makedatetimestamp
mapfile = common.mapfile
MissingTool = common.MissingTool
NoRepo = common.NoRepo

# Subversion stuff. Works best with very recent Python SVN bindings
# e.g. SVN 1.5 or backports. Thanks to the bzr folks for enhancing
# these bindings.

try:
    import svn
    import svn.client
    import svn.core
    import svn.ra
    import svn.delta
    from . import transport
    import warnings

    warnings.filterwarnings(
        'ignore', module='svn.core', category=DeprecationWarning
    )
    svn.core.SubversionException  # trigger import to catch error

except ImportError:
    svn = None


# In Subversion, paths and URLs are Unicode (encoded as UTF-8), which
# Subversion converts from / to native strings when interfacing with the OS.
# When passing paths and URLs to Subversion, we have to recode them such that
# it roundstrips with what Subversion is doing.

fsencoding = None


def init_fsencoding():
    global fsencoding, fsencoding_is_utf8
    if fsencoding is not None:
        return
    if pycompat.iswindows:
        # On Windows, filenames are Unicode, but we store them using the MBCS
        # encoding.
        fsencoding = 'mbcs'
    else:
        # This is the encoding used to convert UTF-8 back to natively-encoded
        # strings in Subversion 1.14.0 or earlier with APR 1.7.0 or earlier.
        with util.with_lc_ctype():
            fsencoding = locale.nl_langinfo(locale.CODESET) or 'ISO-8859-1'
    fsencoding = codecs.lookup(fsencoding).name
    fsencoding_is_utf8 = fsencoding == codecs.lookup('utf-8').name


def fs2svn(s):
    if fsencoding_is_utf8:
        return s
    else:
        return s.decode(fsencoding).encode('utf-8')


def formatsvndate(date):
    return dateutil.datestr(date, b'%Y-%m-%dT%H:%M:%S.000000Z')


def parsesvndate(s):
    # Example SVN datetime. Includes microseconds.
    # ISO-8601 conformant
    # '2007-01-04T17:35:00.902377Z'
    return dateutil.parsedate(s[:19] + b' UTC', [b'%Y-%m-%dT%H:%M:%S'])


class SvnPathNotFound(Exception):
    pass


def revsplit(rev):
    """Parse a revision string and return (uuid, path, revnum).
    >>> revsplit(b'svn:a2147622-4a9f-4db4-a8d3-13562ff547b2'
    ...          b'/proj%20B/mytrunk/mytrunk@1')
    ('a2147622-4a9f-4db4-a8d3-13562ff547b2', '/proj%20B/mytrunk/mytrunk', 1)
    >>> revsplit(b'svn:8af66a51-67f5-4354-b62c-98d67cc7be1d@1')
    ('', '', 1)
    >>> revsplit(b'@7')
    ('', '', 7)
    >>> revsplit(b'7')
    ('', '', 0)
    >>> revsplit(b'bad')
    ('', '', 0)
    """
    parts = rev.rsplit(b'@', 1)
    revnum = 0
    if len(parts) > 1:
        revnum = int(parts[1])
    parts = parts[0].split(b'/', 1)
    uuid = b''
    mod = b''
    if len(parts) > 1 and parts[0].startswith(b'svn:'):
        uuid = parts[0][4:]
        mod = b'/' + parts[1]
    return uuid, mod, revnum


def quote(s):
    # As of svn 1.7, many svn calls expect "canonical" paths. In
    # theory, we should call svn.core.*canonicalize() on all paths
    # before passing them to the API.  Instead, we assume the base url
    # is canonical and copy the behaviour of svn URL encoding function
    # so we can extend it safely with new components. The "safe"
    # characters were taken from the "svn_uri__char_validity" table in
    # libsvn_subr/path.c.
    return urlreq.quote(s, b"!$&'()*+,-./:=@_~")


def geturl(path):
    """Convert path or URL to a SVN URL, encoded in UTF-8.

    This can raise UnicodeDecodeError if the path or URL can't be converted to
    unicode using `fsencoding`.
    """
    try:
        return svn.client.url_from_path(
            svn.core.svn_path_canonicalize(fs2svn(path))
        )
    except svn.core.SubversionException:
        # svn.client.url_from_path() fails with local repositories
        pass
    if os.path.isdir(path):
        path = os.path.normpath(util.abspath(path))
        if pycompat.iswindows:
            path = b'/' + util.normpath(path)
        # Module URL is later compared with the repository URL returned
        # by svn API, which is UTF-8.
        path = fs2svn(path)
        path = b'file://%s' % quote(path)
    return svn.core.svn_path_canonicalize(path)


def optrev(number):
    optrev = svn.core.svn_opt_revision_t()
    optrev.kind = svn.core.svn_opt_revision_number
    optrev.value.number = number
    return optrev


class changedpath:
    def __init__(self, p):
        self.copyfrom_path = p.copyfrom_path
        self.copyfrom_rev = p.copyfrom_rev
        self.action = p.action


def get_log_child(
    fp,
    url,
    paths,
    start,
    end,
    limit=0,
    discover_changed_paths=True,
    strict_node_history=False,
):
    protocol = -1

    def receiver(orig_paths, revnum, author, date, message, pool):
        paths = {}
        if orig_paths is not None:
            for k, v in orig_paths.items():
                paths[k] = changedpath(v)
        pickle.dump((paths, revnum, author, date, message), fp, protocol)

    try:
        # Use an ra of our own so that our parent can consume
        # our results without confusing the server.
        t = transport.SvnRaTransport(url=url)
        svn.ra.get_log(
            t.ra,
            paths,
            start,
            end,
            limit,
            discover_changed_paths,
            strict_node_history,
            receiver,
        )
    except IOError:
        # Caller may interrupt the iteration
        pickle.dump(None, fp, protocol)
    except Exception as inst:
        pickle.dump(stringutil.forcebytestr(inst), fp, protocol)
    else:
        pickle.dump(None, fp, protocol)
    fp.flush()
    # With large history, cleanup process goes crazy and suddenly
    # consumes *huge* amount of memory. The output file being closed,
    # there is no need for clean termination.
    os._exit(0)


def debugsvnlog(ui, **opts):
    """Fetch SVN log in a subprocess and channel them back to parent to
    avoid memory collection issues.
    """
    with util.with_lc_ctype():
        if svn is None:
            raise error.Abort(
                _(b'debugsvnlog could not load Subversion python bindings')
            )

        args = decodeargs(ui.fin.read())
        get_log_child(ui.fout, *args)


class logstream:
    """Interruptible revision log iterator."""

    def __init__(self, stdout):
        self._stdout = stdout

    def __iter__(self):
        while True:
            try:
                entry = pickle.load(self._stdout)
            except EOFError:
                raise error.Abort(
                    _(
                        b'Mercurial failed to run itself, check'
                        b' hg executable is in PATH'
                    )
                )
            try:
                orig_paths, revnum, author, date, message = entry
            except (TypeError, ValueError):
                if entry is None:
                    break
                raise error.Abort(_(b"log stream exception '%s'") % entry)
            yield entry

    def close(self):
        if self._stdout:
            self._stdout.close()
            self._stdout = None


class directlogstream(list):
    """Direct revision log iterator.
    This can be used for debugging and development but it will probably leak
    memory and is not suitable for real conversions."""

    def __init__(
        self,
        url,
        paths,
        start,
        end,
        limit=0,
        discover_changed_paths=True,
        strict_node_history=False,
    ):
        def receiver(orig_paths, revnum, author, date, message, pool):
            paths = {}
            if orig_paths is not None:
                for k, v in orig_paths.items():
                    paths[k] = changedpath(v)
            self.append((paths, revnum, author, date, message))

        # Use an ra of our own so that our parent can consume
        # our results without confusing the server.
        t = transport.SvnRaTransport(url=url)
        svn.ra.get_log(
            t.ra,
            paths,
            start,
            end,
            limit,
            discover_changed_paths,
            strict_node_history,
            receiver,
        )

    def close(self):
        pass


# Check to see if the given path is a local Subversion repo. Verify this by
# looking for several svn-specific files and directories in the given
# directory.
def filecheck(ui, path, proto):
    for x in (b'locks', b'hooks', b'format', b'db'):
        if not os.path.exists(os.path.join(path, x)):
            return False
    return True


# Check to see if a given path is the root of an svn repo over http. We verify
# this by requesting a version-controlled URL we know can't exist and looking
# for the svn-specific "not found" XML.
def httpcheck(ui, path, proto):
    try:
        opener = urlreq.buildopener()
        rsp = opener.open(
            pycompat.strurl(b'%s://%s/!svn/ver/0/.svn' % (proto, path)), b'rb'
        )
        data = rsp.read()
    except urlerr.httperror as inst:
        if inst.code != 404:
            # Except for 404 we cannot know for sure this is not an svn repo
            ui.warn(
                _(
                    b'svn: cannot probe remote repository, assume it could '
                    b'be a subversion repository. Use --source-type if you '
                    b'know better.\n'
                )
            )
            return True
        data = inst.fp.read()
    except Exception:
        # Could be urlerr.urlerror if the URL is invalid or anything else.
        return False
    return b'<m:human-readable errcode="160013">' in data


protomap = {
    b'http': httpcheck,
    b'https': httpcheck,
    b'file': filecheck,
}


def issvnurl(ui, url):
    try:
        proto, path = url.split(b'://', 1)
        if proto == b'file':
            if (
                pycompat.iswindows
                and path[:1] == b'/'
                and path[1:2].isalpha()
                and path[2:6].lower() == b'%3a/'
            ):
                path = path[:2] + b':/' + path[6:]
            try:
                unicodepath = path.decode(fsencoding)
            except UnicodeDecodeError:
                ui.warn(
                    _(
                        b'Subversion requires that file URLs can be converted '
                        b'to Unicode using the current locale encoding (%s)\n'
                    )
                    % pycompat.sysbytes(fsencoding)
                )
                return False

            # Subversion paths are Unicode. Since it does percent-decoding on
            # UTF-8-encoded strings, percent-encoded bytes are interpreted as
            # UTF-8.
            # On Python 3, we have to pass unicode to urlreq.url2pathname().
            # Percent-decoded bytes get decoded using UTF-8 and the 'replace'
            # error handler.
            unicodepath = urlreq.url2pathname(unicodepath)
            if u'\N{REPLACEMENT CHARACTER}' in unicodepath:
                ui.warn(
                    _(
                        b'Subversion does not support non-UTF-8 '
                        b'percent-encoded bytes in file URLs\n'
                    )
                )
                return False

            # Below, we approximate how Subversion checks the path. On Unix, we
            # should therefore convert the path to bytes using `fsencoding`
            # (like Subversion does). On Windows, the right thing would
            # actually be to leave the path as unicode. For now, we restrict
            # the path to MBCS.
            path = unicodepath.encode(fsencoding)
    except ValueError:
        proto = b'file'
        path = util.abspath(url)
        try:
            path.decode(fsencoding)
        except UnicodeDecodeError:
            ui.warn(
                _(
                    b'Subversion requires that paths can be converted to '
                    b'Unicode using the current locale encoding (%s)\n'
                )
                % pycompat.sysbytes(fsencoding)
            )
            return False
    if proto == b'file':
        path = util.pconvert(path)
    elif proto in (b'http', 'https'):
        if not encoding.isasciistr(path):
            ui.warn(
                _(
                    b"Subversion sources don't support non-ASCII characters in "
                    b"HTTP(S) URLs. Please percent-encode them.\n"
                )
            )
            return False
    check = protomap.get(proto, lambda *args: False)
    while b'/' in path:
        if check(ui, path, proto):
            return True
        path = path.rsplit(b'/', 1)[0]
    return False


# SVN conversion code stolen from bzr-svn and tailor
#
# Subversion looks like a versioned filesystem, branches structures
# are defined by conventions and not enforced by the tool. First,
# we define the potential branches (modules) as "trunk" and "branches"
# children directories. Revisions are then identified by their
# module and revision number (and a repository identifier).
#
# The revision graph is really a tree (or a forest). By default, a
# revision parent is the previous revision in the same module. If the
# module directory is copied/moved from another module then the
# revision is the module root and its parent the source revision in
# the parent module. A revision has at most one parent.
#
class svn_source(converter_source):
    def __init__(self, ui, repotype, url, revs=None):
        super(svn_source, self).__init__(ui, repotype, url, revs=revs)

        init_fsencoding()
        if not (
            url.startswith(b'svn://')
            or url.startswith(b'svn+ssh://')
            or (
                os.path.exists(url)
                and os.path.exists(os.path.join(url, b'.svn'))
            )
            or issvnurl(ui, url)
        ):
            raise NoRepo(
                _(b"%s does not look like a Subversion repository") % url
            )
        if svn is None:
            raise MissingTool(_(b'could not load Subversion python bindings') +
                              _(b' (try installing the %s package)') % b'python3-subversion')

        try:
            version = svn.core.SVN_VER_MAJOR, svn.core.SVN_VER_MINOR
            if version < (1, 4):
                raise MissingTool(
                    _(
                        b'Subversion python bindings %d.%d found, '
                        b'1.4 or later required'
                    )
                    % version +
                    _(b' (try upgrading the %s package)') % b'python-subversion'
                )
        except AttributeError:
            raise MissingTool(
                _(
                    b'Subversion python bindings are too old, 1.4 '
                    b'or later required'
                ) +
                _(b' (try upgrading the %s package)') % b'python-subversion'
            )

        self.lastrevs = {}

        latest = None
        try:
            # Support file://path@rev syntax. Useful e.g. to convert
            # deleted branches.
            at = url.rfind(b'@')
            if at >= 0:
                latest = int(url[at + 1 :])
                url = url[:at]
        except ValueError:
            pass
        self.url = geturl(url)
        self.encoding = b'UTF-8'  # Subversion is always nominal UTF-8
        try:
            with util.with_lc_ctype():
                self.transport = transport.SvnRaTransport(url=self.url)
                self.ra = self.transport.ra
                self.ctx = self.transport.client
                self.baseurl = svn.ra.get_repos_root(self.ra)
                # Module is either empty or a repository path starting with
                # a slash and not ending with a slash.
                self.module = urlreq.unquote(self.url[len(self.baseurl) :])
                self.prevmodule = None
                self.rootmodule = self.module
                self.commits = {}
                self.paths = {}
                self.uuid = svn.ra.get_uuid(self.ra)
        except svn.core.SubversionException:
            ui.traceback()
            svnversion = b'%d.%d.%d' % (
                svn.core.SVN_VER_MAJOR,
                svn.core.SVN_VER_MINOR,
                svn.core.SVN_VER_MICRO,
            )
            raise NoRepo(
                _(
                    b"%s does not look like a Subversion repository "
                    b"to libsvn version %s"
                )
                % (self.url, svnversion)
            )

        if revs:
            if len(revs) > 1:
                raise error.Abort(
                    _(
                        b'subversion source does not support '
                        b'specifying multiple revisions'
                    )
                )
            try:
                latest = int(revs[0])
            except ValueError:
                raise error.Abort(
                    _(b'svn: revision %s is not an integer') % revs[0]
                )

        trunkcfg = self.ui.config(b'convert', b'svn.trunk')
        if trunkcfg is None:
            trunkcfg = b'trunk'
        self.trunkname = trunkcfg.strip(b'/')
        self.startrev = self.ui.config(b'convert', b'svn.startrev')
        try:
            self.startrev = int(self.startrev)
            if self.startrev < 0:
                self.startrev = 0
        except ValueError:
            raise error.Abort(
                _(b'svn: start revision %s is not an integer') % self.startrev
            )

        try:
            with util.with_lc_ctype():
                self.head = self.latest(self.module, latest)
        except SvnPathNotFound:
            self.head = None
        if not self.head:
            raise error.Abort(
                _(b'no revision found in module %s') % self.module
            )
        self.last_changed = self.revnum(self.head)

        self._changescache = (None, None)

        if os.path.exists(os.path.join(url, b'.svn/entries')):
            self.wc = url
        else:
            self.wc = None
        self.convertfp = None

    def before(self):
        self.with_lc_ctype = util.with_lc_ctype()
        self.with_lc_ctype.__enter__()

    def after(self):
        self.with_lc_ctype.__exit__(None, None, None)

    def setrevmap(self, revmap):
        lastrevs = {}
        for revid in revmap:
            uuid, module, revnum = revsplit(revid)
            lastrevnum = lastrevs.setdefault(module, revnum)
            if revnum > lastrevnum:
                lastrevs[module] = revnum
        self.lastrevs = lastrevs

    def exists(self, path, optrev):
        try:
            svn.client.ls(
                self.url.rstrip(b'/') + b'/' + quote(path),
                optrev,
                False,
                self.ctx,
            )
            return True
        except svn.core.SubversionException:
            return False

    def getheads(self):
        def isdir(path, revnum):
            kind = self._checkpath(path, revnum)
            return kind == svn.core.svn_node_dir

        def getcfgpath(name, rev):
            cfgpath = self.ui.config(b'convert', b'svn.' + name)
            if cfgpath is not None and cfgpath.strip() == b'':
                return None
            path = (cfgpath or name).strip(b'/')
            if not self.exists(path, rev):
                if self.module.endswith(path) and name == b'trunk':
                    # we are converting from inside this directory
                    return None
                if cfgpath:
                    raise error.Abort(
                        _(b'expected %s to be at %r, but not found')
                        % (name, path)
                    )
                return None
            self.ui.note(
                _(b'found %s at %r\n') % (name, pycompat.bytestr(path))
            )
            return path

        rev = optrev(self.last_changed)
        oldmodule = b''
        trunk = getcfgpath(b'trunk', rev)
        self.tags = getcfgpath(b'tags', rev)
        branches = getcfgpath(b'branches', rev)

        # If the project has a trunk or branches, we will extract heads
        # from them. We keep the project root otherwise.
        if trunk:
            oldmodule = self.module or b''
            self.module += b'/' + trunk
            self.head = self.latest(self.module, self.last_changed)
            if not self.head:
                raise error.Abort(
                    _(b'no revision found in module %s') % self.module
                )

        # First head in the list is the module's head
        self.heads = [self.head]
        if self.tags is not None:
            self.tags = b'%s/%s' % (oldmodule, (self.tags or b'tags'))

        # Check if branches bring a few more heads to the list
        if branches:
            rpath = self.url.strip(b'/')
            branchnames = svn.client.ls(
                rpath + b'/' + quote(branches), rev, False, self.ctx
            )
            for branch in sorted(branchnames):
                module = b'%s/%s/%s' % (oldmodule, branches, branch)
                if not isdir(module, self.last_changed):
                    continue
                brevid = self.latest(module, self.last_changed)
                if not brevid:
                    self.ui.note(_(b'ignoring empty branch %s\n') % branch)
                    continue
                self.ui.note(
                    _(b'found branch %s at %d\n')
                    % (branch, self.revnum(brevid))
                )
                self.heads.append(brevid)

        if self.startrev and self.heads:
