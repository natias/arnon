    @util.propertycache
    def rekwexp(self):
        '''Returns regex for expanded keywords.'''
        return re.compile(br'\$(%s): [^$\n\r]*? \$' % self.escape)

    def substitute(self, data, path, ctx, subfunc):
        '''Replaces keywords in data with expanded template.'''

        def kwsub(mobj):
            kw = mobj.group(1)
            ct = logcmdutil.maketemplater(
                self.ui, self.repo, self.templates[kw]
            )
            self.ui.pushbuffer()
            ct.show(ctx, root=self.repo.root, file=path)
            ekw = templatefilters.firstline(self.ui.popbuffer())
            return b'$%s: %s $' % (kw, ekw)

        return subfunc(kwsub, data)

    def linkctx(self, path, fileid):
        '''Similar to filelog.linkrev, but returns a changectx.'''
        return self.repo.filectx(path, fileid=fileid).changectx()

    def expand(self, path, node, data):
        '''Returns data with keywords expanded.'''
        if (
            not self.restrict
            and self.match(path)
            and not stringutil.binary(data)
        ):
            ctx = self.linkctx(path, node)
            return self.substitute(data, path, ctx, self.rekw.sub)
        return data

    def iskwfile(self, cand, ctx):
        """Returns subset of candidates which are configured for keyword
        expansion but are not symbolic links."""
        return [f for f in cand if self.match(f) and b'l' not in ctx.flags(f)]

    def overwrite(self, ctx, candidates, lookup, expand, rekw=False):
        '''Overwrites selected files expanding/shrinking keywords.'''
        if self.restrict or lookup or self.postcommit:  # exclude kw_copy
            candidates = self.iskwfile(candidates, ctx)
        if not candidates:
            return
        kwcmd = self.restrict and lookup  # kwexpand/kwshrink
        if self.restrict or expand and lookup:
            mf = ctx.manifest()
        if self.restrict or rekw:
            re_kw = self.rekw
        else:
            re_kw = self.rekwexp
        if expand:
            msg = _(b'overwriting %s expanding keywords\n')
        else:
            msg = _(b'overwriting %s shrinking keywords\n')
        wctx = self.repo[None]
        for f in candidates:
            if self.restrict:
                data = self.repo.file(f).read(mf[f])
            else:
                data = self.repo.wread(f)
            if stringutil.binary(data):
                continue
            if expand:
                parents = ctx.parents()
                if lookup:
                    ctx = self.linkctx(f, mf[f])
                elif self.restrict and len(parents) > 1:
                    # merge commit
                    # in case of conflict f is in modified state during
                    # merge, even if f does not differ from f in parent
                    for p in parents:
                        if f in p and not p[f].cmp(ctx[f]):
                            ctx = p[f].changectx()
                            break
                data, found = self.substitute(data, f, ctx, re_kw.subn)
            elif self.restrict:
                found = re_kw.search(data)
            else:
                data, found = _shrinktext(data, re_kw.subn)
            if found:
                self.ui.note(msg % f)
                fp = self.repo.wvfs(f, b"wb", atomictemp=True)
                fp.write(data)
                fp.close()
                if kwcmd:
                    s = wctx[f].lstat()
                    mode = s.st_mode
                    size = s.st_size
                    mtime = timestamp.mtime_of(s)
                    cache_data = (mode, size, mtime)
                    self.repo.dirstate.set_clean(f, cache_data)
                elif self.postcommit:
                    self.repo.dirstate.update_file_p1(f, p1_tracked=True)

    def shrink(self, fname, text):
        '''Returns text with all keyword substitutions removed.'''
        if self.match(fname) and not stringutil.binary(text):
            return _shrinktext(text, self.rekwexp.sub)
        return text

    def shrinklines(self, fname, lines):
        '''Returns lines with keyword substitutions removed.'''
        if self.match(fname):
            text = b''.join(lines)
            if not stringutil.binary(text):
                return _shrinktext(text, self.rekwexp.sub).splitlines(True)
        return lines

    def wread(self, fname, data):
        """If in restricted mode returns data read from wdir with
        keyword substitutions removed."""
        if self.restrict:
            return self.shrink(fname, data)
        return data


class kwfilelog(filelog.filelog):
    """
    Subclass of filelog to hook into its read, add, cmp methods.
    Keywords are "stored" unexpanded, and processed on reading.
    """

    def __init__(self, opener, kwt, path):
        super(kwfilelog, self).__init__(opener, path)
        self.kwt = kwt
        self.path = path

    def read(self, node):
        '''Expands keywords when reading filelog.'''
        data = super(kwfilelog, self).read(node)
        if self.renamed(node):
            return data
        return self.kwt.expand(self.path, node, data)

    def add(self, text, meta, tr, link, p1=None, p2=None):
        '''Removes keyword substitutions when adding to filelog.'''
        text = self.kwt.shrink(self.path, text)
        return super(kwfilelog, self).add(text, meta, tr, link, p1, p2)

    def cmp(self, node, text):
        '''Removes keyword substitutions for comparison.'''
        text = self.kwt.shrink(self.path, text)
        return super(kwfilelog, self).cmp(node, text)


def _status(ui, repo, wctx, kwt, *pats, **opts):
    """Bails out if [keyword] configuration is not active.
    Returns status of working directory."""
    if kwt:
        opts = pycompat.byteskwargs(opts)
        return repo.status(
            match=scmutil.match(wctx, pats, opts),
            clean=True,
            unknown=opts.get(b'unknown') or opts.get(b'all'),
        )
    if ui.configitems(b'keyword'):
        raise error.Abort(_(b'[keyword] patterns cannot match'))
    raise error.Abort(_(b'no [keyword] patterns configured'))


def _kwfwrite(ui, repo, expand, *pats, **opts):
    '''Selects files and passes them to kwtemplater.overwrite.'''
    wctx = repo[None]
    if len(wctx.parents()) > 1:
        raise error.Abort(_(b'outstanding uncommitted merge'))
    kwt = getattr(repo, '_keywordkwt', None)
    with repo.wlock():
        status = _status(ui, repo, wctx, kwt, *pats, **opts)
        if status.modified or status.added or status.removed or status.deleted:
            raise error.Abort(_(b'outstanding uncommitted changes'))
        kwt.overwrite(wctx, status.clean, True, expand)


@command(
    b'kwdemo',
    [
        (b'd', b'default', None, _(b'show default keyword template maps')),
        (b'f', b'rcfile', b'', _(b'read maps from rcfile'), _(b'FILE')),
    ],
    _(b'hg kwdemo [-d] [-f RCFILE] [TEMPLATEMAP]...'),
    optionalrepo=True,
)
def demo(ui, repo, *args, **opts):
    """print [keywordmaps] configuration and an expansion example

    Show current, custom, or default keyword template maps and their
    expansions.

    Extend the current configuration by specifying maps as arguments
    and using -f/--rcfile to source an external hgrc file.

    Use -d/--default to disable current configuration.

    See :hg:`help templates` for information on templates and filters.
    """

    def demoitems(section, items):
        ui.write(b'[%s]\n' % section)
        for k, v in sorted(items):
            if isinstance(v, bool):
                v = stringutil.pprint(v)
            ui.write(b'%s = %s\n' % (k, v))

    fn = b'demo.txt'
    tmpdir = pycompat.mkdtemp(b'', b'kwdemo.')
    ui.note(_(b'creating temporary repository at %s\n') % tmpdir)
    if repo is None:
        baseui = ui
    else:
        baseui = repo.baseui
    repo = localrepo.instance(baseui, tmpdir, create=True)
    ui.setconfig(b'keyword', fn, b'', b'keyword')
    svn = ui.configbool(b'keywordset', b'svn')
    # explicitly set keywordset for demo output
    ui.setconfig(b'keywordset', b'svn', svn, b'keyword')

    uikwmaps = ui.configitems(b'keywordmaps')
    if args or opts.get('rcfile'):
        ui.status(_(b'\n\tconfiguration using custom keyword template maps\n'))
        if uikwmaps:
            ui.status(_(b'\textending current template maps\n'))
        if opts.get('default') or not uikwmaps:
            if svn:
                ui.status(_(b'\toverriding default svn keywordset\n'))
            else:
                ui.status(_(b'\toverriding default cvs keywordset\n'))
        if opts.get('rcfile'):
            ui.readconfig(opts.get(b'rcfile'))
        if args:
            # simulate hgrc parsing
            rcmaps = b'[keywordmaps]\n%s\n' % b'\n'.join(args)
            repo.vfs.write(b'hgrc', rcmaps)
            ui.readconfig(repo.vfs.join(b'hgrc'))
        kwmaps = dict(ui.configitems(b'keywordmaps'))
    elif opts.get('default'):
        if svn:
            ui.status(_(b'\n\tconfiguration using default svn keywordset\n'))
        else:
            ui.status(_(b'\n\tconfiguration using default cvs keywordset\n'))
        kwmaps = _defaultkwmaps(ui)
        if uikwmaps:
            ui.status(_(b'\tdisabling current template maps\n'))
            for k, v in kwmaps.items():
                ui.setconfig(b'keywordmaps', k, v, b'keyword')
    else:
        ui.status(_(b'\n\tconfiguration using current keyword template maps\n'))
        if uikwmaps:
            kwmaps = dict(uikwmaps)
        else:
            kwmaps = _defaultkwmaps(ui)

    uisetup(ui)
    reposetup(ui, repo)
    ui.writenoi18n(b'[extensions]\nkeyword =\n')
    demoitems(b'keyword', ui.configitems(b'keyword'))
    demoitems(b'keywordset', ui.configitems(b'keywordset'))
    demoitems(b'keywordmaps', kwmaps.items())
    keywords = b'$' + b'$\n$'.join(sorted(kwmaps.keys())) + b'$\n'
    repo.wvfs.write(fn, keywords)
    repo[None].add([fn])
    ui.note(_(b'\nkeywords written to %s:\n') % fn)
    ui.note(keywords)
    with repo.wlock():
        repo.dirstate.setbranch(b'demobranch')
    for name, cmd in ui.configitems(b'hooks'):
        if name.split(b'.', 1)[0].find(b'commit') > -1:
            repo.ui.setconfig(b'hooks', name, b'', b'keyword')
    msg = _(b'hg keyword configuration and expansion example')
    ui.note((b"hg ci -m '%s'\n" % msg))
    repo.commit(text=msg)
    ui.status(_(b'\n\tkeywords expanded\n'))
    ui.write(repo.wread(fn))
    repo.wvfs.rmtree(repo.root)


@command(
    b'kwexpand',
    cmdutil.walkopts,
    _(b'hg kwexpand [OPTION]... [FILE]...'),
    inferrepo=True,
)
def expand(ui, repo, *pats, **opts):
    """expand keywords in the working directory

    Run after (re)enabling keyword expansion.

    kwexpand refuses to run if given files contain local changes.
    """
    # 3rd argument sets expansion to True
    _kwfwrite(ui, repo, True, *pats, **opts)


@command(
    b'kwfiles',
    [
        (b'A', b'all', None, _(b'show keyword status flags of all files')),
        (b'i', b'ignore', None, _(b'show files excluded from expansion')),
        (b'u', b'unknown', None, _(b'only show unknown (not tracked) files')),
    ]
    + cmdutil.walkopts,
    _(b'hg kwfiles [OPTION]... [FILE]...'),
    inferrepo=True,
)
def files(ui, repo, *pats, **opts):
    """show files configured for keyword expansion

    List which files in the working directory are matched by the
    [keyword] configuration patterns.

    Useful to prevent inadvertent keyword expansion and to speed up
    execution by including only files that are actual candidates for
    expansion.

    See :hg:`help keyword` on how to construct patterns both for
    inclusion and exclusion of files.

    With -A/--all and -v/--verbose the codes used to show the status
    of files are::

      K = keyword expansion candidate
      k = keyword expansion candidate (not tracked)
      I = ignored
      i = ignored (not tracked)
    """
    kwt = getattr(repo, '_keywordkwt', None)
    wctx = repo[None]
    status = _status(ui, repo, wctx, kwt, *pats, **opts)
    if pats:
        cwd = repo.getcwd()
    else:
        cwd = b''
    files = []
    opts = pycompat.byteskwargs(opts)
    if not opts.get(b'unknown') or opts.get(b'all'):
        files = sorted(status.modified + status.added + status.clean)
    kwfiles = kwt.iskwfile(files, wctx)
    kwdeleted = kwt.iskwfile(status.deleted, wctx)
    kwunknown = kwt.iskwfile(status.unknown, wctx)
    if not opts.get(b'ignore') or opts.get(b'all'):
        showfiles = kwfiles, kwdeleted, kwunknown
    else:
        showfiles = [], [], []
    if opts.get(b'all') or opts.get(b'ignore'):
        showfiles += (
            [f for f in files if f not in kwfiles],
            [f for f in status.unknown if f not in kwunknown],
        )
    kwlabels = b'enabled deleted enabledunknown ignored ignoredunknown'.split()
    kwstates = zip(kwlabels, pycompat.bytestr(b'K!kIi'), showfiles)
    fm = ui.formatter(b'kwfiles', opts)
    fmt = b'%.0s%s\n'
    if opts.get(b'all') or ui.verbose:
        fmt = b'%s %s\n'
    for kwstate, char, filenames in kwstates:
        label = b'kwfiles.' + kwstate
        for f in filenames:
            fm.startitem()
            fm.data(kwstatus=char, path=f)
            fm.plain(fmt % (char, repo.pathto(f, cwd)), label=label)
    fm.end()


@command(
    b'kwshrink',
    cmdutil.walkopts,
    _(b'hg kwshrink [OPTION]... [FILE]...'),
    inferrepo=True,
)
def shrink(ui, repo, *pats, **opts):
    """revert expanded keywords in the working directory

    Must be run before changing/disabling active keywords.

    kwshrink refuses to run if given files contain local changes.
    """
    # 3rd argument sets expansion to False
    _kwfwrite(ui, repo, False, *pats, **opts)


# monkeypatches


def kwpatchfile_init(orig, self, ui, gp, backend, store, eolmode=None):
    """Monkeypatch/wrap patch.patchfile.__init__ to avoid
    rejects or conflicts due to expanded keywords in working dir."""
    orig(self, ui, gp, backend, store, eolmode)
    kwt = getattr(getattr(backend, 'repo', None), '_keywordkwt', None)
    if kwt:
        # shrink keywords read from working dir
        self.lines = kwt.shrinklines(self.fname, self.lines)


def kwdiff(orig, repo, *args, **kwargs):
    '''Monkeypatch patch.diff to avoid expansion.'''
    kwt = getattr(repo, '_keywordkwt', None)
    if kwt:
        restrict = kwt.restrict
        kwt.restrict = True
    try:
        for chunk in orig(repo, *args, **kwargs):
            yield chunk
    finally:
        if kwt:
            kwt.restrict = restrict


def kwweb_skip(orig, web):
    '''Wraps webcommands.x turning off keyword expansion.'''
    kwt = getattr(web.repo, '_keywordkwt', None)
    if kwt:
        origmatch = kwt.match
        kwt.match = util.never
    try:
        for chunk in orig(web):
            yield chunk
    finally:
        if kwt:
            kwt.match = origmatch


def kw_amend(orig, ui, repo, old, extra, pats, opts):
    '''Wraps cmdutil.amend expanding keywords after amend.'''
    kwt = getattr(repo, '_keywordkwt', None)
    if kwt is None:
        return orig(ui, repo, old, extra, pats, opts)
    with repo.wlock(), repo.dirstate.parentchange():
        kwt.postcommit = True
        newid = orig(ui, repo, old, extra, pats, opts)
        if newid != old.node():
            ctx = repo[newid]
            kwt.restrict = True
            kwt.overwrite(ctx, ctx.files(), False, True)
            kwt.restrict = False
        return newid


def kw_copy(orig, ui, repo, pats, opts, rename=False):
    """Wraps cmdutil.copy so that copy/rename destinations do not
    contain expanded keywords.
    Note that the source of a regular file destination may also be a
    symlink:
    hg cp sym x                -> x is symlink
    cp sym x; hg cp -A sym x   -> x is file (maybe expanded keywords)
    For the latter we have to follow the symlink to find out whether its
    target is configured for expansion and we therefore must unexpand the
    keywords in the destination."""
    kwt = getattr(repo, '_keywordkwt', None)
    if kwt is None:
        return orig(ui, repo, pats, opts, rename)
    with repo.wlock():
        orig(ui, repo, pats, opts, rename)
        if opts.get(b'dry_run'):
            return
        wctx = repo[None]
        cwd = repo.getcwd()

        def haskwsource(dest):
            """Returns true if dest is a regular file and configured for
            expansion or a symlink which points to a file configured for
            expansion."""
            source = repo.dirstate.copied(dest)
            if b'l' in wctx.flags(source):
                source = pathutil.canonpath(
                    repo.root, cwd, os.path.realpath(source)
                )
            return kwt.match(source)

        candidates = [
            f
            for f in repo.dirstate.copies()
            if b'l' not in wctx.flags(f) and haskwsource(f)
        ]
        kwt.overwrite(wctx, candidates, False, False)


def kw_dorecord(orig, ui, repo, commitfunc, *pats, **opts):
    '''Wraps record.dorecord expanding keywords after recording.'''
    kwt = getattr(repo, '_keywordkwt', None)
    if kwt is None:
        return orig(ui, repo, commitfunc, *pats, **opts)
    with repo.wlock():
        # record returns 0 even when nothing has changed
        # therefore compare nodes before and after
        kwt.postcommit = True
        ctx = repo[b'.']
        wstatus = ctx.status()
        ret = orig(ui, repo, commitfunc, *pats, **opts)
        recctx = repo[b'.']
        if ctx != recctx:
            modified, added = _preselect(wstatus, recctx.files())
            kwt.restrict = False
            with repo.dirstate.parentchange():
                kwt.overwrite(recctx, modified, False, True)
                kwt.overwrite(recctx, added, False, True, True)
            kwt.restrict = True
        return ret


def kwfilectx_cmp(orig, self, fctx):
    if fctx._customcmp:
        return fctx.cmp(self)
    kwt = getattr(self._repo, '_keywordkwt', None)
    if kwt is None:
        return orig(self, fctx)
    # keyword affects data size, comparing wdir and filelog size does
    # not make sense
    if (
        fctx._filenode is None
        and (
            self._repo._encodefilterpats
            or kwt.match(fctx.path())
            and b'l' not in fctx.flags()
            or self.size() - 4 == fctx.size()
        )
        or self.size() == fctx.size()
    ):
        return self._filelog.cmp(self._filenode, fctx.data())
    return True


def uisetup(ui):
    """Monkeypatches dispatch._parse to retrieve user command.
    Overrides file method to return kwfilelog instead of filelog
    if file matches user configuration.
    Wraps commit to overwrite configured files with updated
    keyword substitutions.
    Monkeypatches patch and webcommands."""

    def kwdispatch_parse(orig, ui, args):
        '''Monkeypatch dispatch._parse to obtain running hg command.'''
        cmd, func, args, options, cmdoptions = orig(ui, args)
        kwtools[b'hgcmd'] = cmd
        return cmd, func, args, options, cmdoptions

    extensions.wrapfunction(dispatch, b'_parse', kwdispatch_parse)

    extensions.wrapfunction(context.filectx, b'cmp', kwfilectx_cmp)
    extensions.wrapfunction(patch.patchfile, b'__init__', kwpatchfile_init)
    extensions.wrapfunction(patch, b'diff', kwdiff)
    extensions.wrapfunction(cmdutil, b'amend', kw_amend)
    extensions.wrapfunction(cmdutil, b'copy', kw_copy)
    extensions.wrapfunction(cmdutil, b'dorecord', kw_dorecord)
    for c in nokwwebcommands.split():
        extensions.wrapfunction(webcommands, c, kwweb_skip)


def reposetup(ui, repo):
    '''Sets up repo as kwrepo for keyword substitution.'''

    try:
        if (
            not repo.local()
            or kwtools[b'hgcmd'] in nokwcommands.split()
            or b'.hg' in util.splitpath(repo.root)
            or repo._url.startswith(b'bundle:')
        ):
            return
    except AttributeError:
        pass

    inc, exc = [], [b'.hg*']
    for pat, opt in ui.configitems(b'keyword'):
        if opt != b'ignore':
            inc.append(pat)
        else:
            exc.append(pat)
    if not inc:
        return

    kwt = kwtemplater(ui, repo, inc, exc)

    class kwrepo(repo.__class__):
        def file(self, f):
            if f[0] == b'/':
                f = f[1:]
            return kwfilelog(self.svfs, kwt, f)

        def wread(self, filename):
            data = super(kwrepo, self).wread(filename)
            return kwt.wread(filename, data)

        def commit(self, *args, **opts):
            # use custom commitctx for user commands
            # other extensions can still wrap repo.commitctx directly
            self.commitctx = self.kwcommitctx
            try:
                return super(kwrepo, self).commit(*args, **opts)
            finally:
                del self.commitctx

        def kwcommitctx(self, ctx, error=False, origctx=None):
            n = super(kwrepo, self).commitctx(ctx, error, origctx)
            # no lock needed, only called from repo.commit() which already locks
            if not kwt.postcommit:
                restrict = kwt.restrict
                kwt.restrict = True
                kwt.overwrite(
                    self[n], sorted(ctx.added() + ctx.modified()), False, True
                )
                kwt.restrict = restrict
            return n

        def rollback(self, dryrun=False, force=False):
            with self.wlock():
                origrestrict = kwt.restrict
                try:
                    if not dryrun:
                        changed = self[b'.'].files()
                    ret = super(kwrepo, self).rollback(dryrun, force)
                    if not dryrun:
                        ctx = self[b'.']
                        modified, added = _preselect(ctx.status(), changed)
                        kwt.restrict = False
                        kwt.overwrite(ctx, modified, True, True)
                        kwt.overwrite(ctx, added, True, False)
                    return ret
                finally:
                    kwt.restrict = origrestrict

    repo.__class__ = kwrepo
    repo._keywordkwt = kwt
                                                                                                                                                                                                         usr/lib/python3/dist-packages/hgext/largefiles/                                                     0000755 0000000 0000000 00000000000 14714551121 020203  5                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        usr/lib/python3/dist-packages/hgext/largefiles/__init__.py                                          0000644 0000000 0000000 00000015346 14355257011 022327  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # Copyright 2009-2010 Gregory P. Ward
# Copyright 2009-2010 Intelerad Medical Systems Incorporated
# Copyright 2010-2011 Fog Creek Software
# Copyright 2010-2011 Unity Technologies
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.

'''track large binary files

Large binary files tend to be not very compressible, not very
diffable, and not at all mergeable. Such files are not handled
efficiently by Mercurial's storage format (revlog), which is based on
compressed binary deltas; storing large binary files as regular
Mercurial files wastes bandwidth and disk space and increases
Mercurial's memory usage. The largefiles extension addresses these
problems by adding a centralized client-server layer on top of
Mercurial: largefiles live in a *central store* out on the network
somewhere, and you only fetch the revisions that you need when you
need them.

largefiles works by maintaining a "standin file" in .hglf/ for each
largefile. The standins are small (41 bytes: an SHA-1 hash plus
newline) and are tracked by Mercurial. Largefile revisions are
identified by the SHA-1 hash of their contents, which is written to
the standin. largefiles uses that revision ID to get/put largefile
revisions from/to the central store. This saves both disk space and
bandwidth, since you don't need to retrieve all historical revisions
of large files when you clone or pull.

To start a new repository or add new large binary files, just add
--large to your :hg:`add` command. For example::

  $ dd if=/dev/urandom of=randomdata count=2000
  $ hg add --large randomdata
  $ hg commit -m "add randomdata as a largefile"

When you push a changeset that adds/modifies largefiles to a remote
repository, its largefile revisions will be uploaded along with it.
Note that the remote Mercurial must also have the largefiles extension
enabled for this to work.

When you pull a changeset that affects largefiles from a remote
repository, the largefiles for the changeset will by default not be
pulled down. However, when you update to such a revision, any
largefiles needed by that revision are downloaded and cached (if
they have never been downloaded before). One way to pull largefiles
when pulling is thus to use --update, which will update your working
copy to the latest pulled revision (and thereby downloading any new
largefiles).

If you want to pull largefiles you don't need for update yet, then
you can use pull with the `--lfrev` option or the :hg:`lfpull` command.

If you know you are pulling from a non-default location and want to
download all the largefiles that correspond to the new changesets at
the same time, then you can pull with `--lfrev "pulled()"`.

If you just want to ensure that you will have the largefiles needed to
merge or rebase with new heads that you are pulling, then you can pull
with `--lfrev "head(pulled())"` flag to pre-emptively download any largefiles
that are new in the heads you are pulling.

Keep in mind that network access may now be required to update to
changesets that you have not previously updated to. The nature of the
largefiles extension means that updating is no longer guaranteed to
be a local-only operation.

If you already have large files tracked by Mercurial without the
largefiles extension, you will need to convert your repository in
order to benefit from largefiles. This is done with the
:hg:`lfconvert` command::

  $ hg lfconvert --size 10 oldrepo newrepo

In repositories that already have largefiles in them, any new file
over 10MB will automatically be added as a largefile. To change this
threshold, set ``largefiles.minsize`` in your Mercurial config file
to the minimum size in megabytes to track as a largefile, or use the
--lfsize option to the add command (also in megabytes)::

  [largefiles]
  minsize = 2

  $ hg add --lfsize 2

The ``largefiles.patterns`` config option allows you to specify a list
of filename patterns (see :hg:`help patterns`) that should always be
tracked as largefiles::

  [largefiles]
  patterns =
    *.jpg
    re:.*\\.(png|bmp)$
    library.zip
    content/audio/*

Files that match one of these patterns will be added as largefiles
regardless of their size.

The ``largefiles.minsize`` and ``largefiles.patterns`` config options
will be ignored for any repositories not already containing a
largefile. To add the first largefile to a repository, you must
explicitly do so with the --large flag passed to the :hg:`add`
command.
'''

from mercurial import (
    cmdutil,
    extensions,
    exthelper,
    hg,
    localrepo,
    wireprotov1server,
)

from . import (
    lfcommands,
    overrides,
    proto,
    reposetup,
)

# Note for extension authors: ONLY specify testedwith = 'ships-with-hg-core' for
# extensions which SHIP WITH MERCURIAL. Non-mainline extensions should
# be specifying the version(s) of Mercurial they are tested with, or
# leave the attribute unspecified.
testedwith = b'ships-with-hg-core'

eh = exthelper.exthelper()
eh.merge(lfcommands.eh)
eh.merge(overrides.eh)
eh.merge(proto.eh)

eh.configitem(
    b'largefiles',
    b'minsize',
    default=eh.configitem.dynamicdefault,
)
eh.configitem(
    b'largefiles',
    b'patterns',
    default=list,
)
eh.configitem(
    b'largefiles',
    b'usercache',
    default=None,
)

cmdtable = eh.cmdtable
configtable = eh.configtable
extsetup = eh.finalextsetup
reposetup = reposetup.reposetup
uisetup = eh.finaluisetup


def featuresetup(ui, supported):
    # don't die on seeing a repo with the largefiles requirement
    supported |= {b'largefiles'}


@eh.uisetup
def _uisetup(ui):
    localrepo.featuresetupfuncs.add(featuresetup)
    hg.wirepeersetupfuncs.append(proto.wirereposetup)

    cmdutil.outgoinghooks.add(b'largefiles', overrides.outgoinghook)
    cmdutil.summaryremotehooks.add(b'largefiles', overrides.summaryremotehook)

    # create the new wireproto commands ...
    wireprotov1server.wireprotocommand(b'putlfile', b'sha', permission=b'push')(
        proto.putlfile
    )
    wireprotov1server.wireprotocommand(b'getlfile', b'sha', permission=b'pull')(
        proto.getlfile
    )
    wireprotov1server.wireprotocommand(
        b'statlfile', b'sha', permission=b'pull'
    )(proto.statlfile)
    wireprotov1server.wireprotocommand(b'lheads', b'', permission=b'pull')(
        wireprotov1server.heads
    )

    extensions.wrapfunction(
        wireprotov1server.commands[b'heads'], b'func', proto.heads
    )
    # TODO also wrap wireproto.commandsv2 once heads is implemented there.

    # override some extensions' stuff as well
    for name, module in extensions.extensions():
        if name == b'rebase':
            # TODO: teach exthelper to handle this
            extensions.wrapfunction(
                module, b'rebase', overrides.overriderebasecmd
            )


revsetpredicate = eh.revsetpredicate
                                                                                                                                                                                                                                                                                          usr/lib/python3/dist-packages/hgext/largefiles/__pycache__/                                         0000755 0000000 0000000 00000000000 14714551121 022413  5                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        usr/lib/python3/dist-packages/hgext/largefiles/__pycache__/__init__.cpython-311.pyc                 0000644 0000000 0000000 00000017044 14714551121 026662  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        §
    	^µcæ  ã                   ó  — d Z ddlmZmZmZmZmZmZ ddlm	Z	m
Z
mZmZ dZ ej        ¦   «         Ze                     e	j        ¦  «         e                     e
j        ¦  «         e                     ej        ¦  «         e                     ddej        j        ¬¦  «         e                     dd	e¬¦  «         e                     dd
d¬¦  «         ej        Zej        Zej        Zej        Zej        Zd„ Zej        d„ ¦   «         Zej        ZdS )aZ  track large binary files

Large binary files tend to be not very compressible, not very
diffable, and not at all mergeable. Such files are not handled
efficiently by Mercurial's storage format (revlog), which is based on
compressed binary deltas; storing large binary files as regular
Mercurial files wastes bandwidth and disk space and increases
Mercurial's memory usage. The largefiles extension addresses these
problems by adding a centralized client-server layer on top of
Mercurial: largefiles live in a *central store* out on the network
somewhere, and you only fetch the revisions that you need when you
need them.

largefiles works by maintaining a "standin file" in .hglf/ for each
largefile. The standins are small (41 bytes: an SHA-1 hash plus
newline) and are tracked by Mercurial. Largefile revisions are
identified by the SHA-1 hash of their contents, which is written to
the standin. largefiles uses that revision ID to get/put largefile
revisions from/to the central store. This saves both disk space and
bandwidth, since you don't need to retrieve all historical revisions
of large files when you clone or pull.

To start a new repository or add new large binary files, just add
--large to your :hg:`add` command. For example::

  $ dd if=/dev/urandom of=randomdata count=2000
  $ hg add --large randomdata
  $ hg commit -m "add randomdata as a largefile"

When you push a changeset that adds/modifies largefiles to a remote
repository, its largefile revisions will be uploaded along with it.
Note that the remote Mercurial must also have the largefiles extension
enabled for this to work.

When you pull a changeset that affects largefiles from a remote
repository, the largefiles for the changeset will by default not be
pulled down. However, when you update to such a revision, any
largefiles needed by that revision are downloaded and cached (if
they have never been downloaded before). One way to pull largefiles
when pulling is thus to use --update, which will update your working
copy to the latest pulled revision (and thereby downloading any new
largefiles).

If you want to pull largefiles you don't need for update yet, then
you can use pull with the `--lfrev` option or the :hg:`lfpull` command.

If you know you are pulling from a non-default location and want to
download all the largefiles that correspond to the new changesets at
the same time, then you can pull with `--lfrev "pulled()"`.

If you just want to ensure that you will have the largefiles needed to
merge or rebase with new heads that you are pulling, then you can pull
with `--lfrev "head(pulled())"` flag to pre-emptively download any largefiles
that are new in the heads you are pulling.

Keep in mind that network access may now be required to update to
changesets that you have not previously updated to. The nature of the
largefiles extension means that updating is no longer guaranteed to
be a local-only operation.

If you already have large files tracked by Mercurial without the
largefiles extension, you will need to convert your repository in
order to benefit from largefiles. This is done with the
:hg:`lfconvert` command::

  $ hg lfconvert --size 10 oldrepo newrepo

In repositories that already have largefiles in them, any new file
over 10MB will automatically be added as a largefile. To change this
threshold, set ``largefiles.minsize`` in your Mercurial config file
to the minimum size in megabytes to track as a largefile, or use the
--lfsize option to the add command (also in megabytes)::

  [largefiles]
  minsize = 2

  $ hg add --lfsize 2

The ``largefiles.patterns`` config option allows you to specify a list
of filename patterns (see :hg:`help patterns`) that should always be
tracked as largefiles::

  [largefiles]
  patterns =
    *.jpg
    re:.*\.(png|bmp)$
    library.zip
    content/audio/*

Files that match one of these patterns will be added as largefiles
regardless of their size.

The ``largefiles.minsize`` and ``largefiles.patterns`` config options
will be ignored for any repositories not already containing a
largefile. To add the first largefile to a repository, you must
explicitly do so with the --large flag passed to the :hg:`add`
command.
é    )ÚcmdutilÚ
extensionsÚ	exthelperÚhgÚ	localrepoÚwireprotov1serveré   )Ú
lfcommandsÚ	overridesÚprotoÚ	reposetups   ships-with-hg-coreó
   largefiless   minsize)Údefaults   patternss	   usercacheNc                 ó   — |dhz  }d S )Nr   © )ÚuiÚ	supporteds     ú;/usr/lib/python3/dist-packages/hgext/largefiles/__init__.pyÚfeaturesetupr      s   € à-Ñ €I€I€Ió    c                 óv  — t           j                             t          ¦  «         t          j                             t          j        ¦  «         t          j
                             dt          j        ¦  «         t          j                             dt          j        ¦  «          t          j        ddd¬¦  «        t          j        ¦  «          t          j        ddd¬¦  «        t          j        ¦  «          t          j        ddd¬¦  «        t          j        ¦  «          t          j        d	d
d¬¦  «        t          j        ¦  «         t+          j        t          j        d         dt          j        ¦  «         t+          j        ¦   «         D ]+\  }}|dk    r t+          j        |dt          j        ¦  «         Œ,d S )Nr   s   putlfiles   shas   push)Ú
permissions   getlfiles   pulls	   statlfiles   lheadsr   s   headss   funcs   rebase)r   ÚfeaturesetupfuncsÚaddr   r   ÚwirepeersetupfuncsÚappendr   Úwirereposetupr   Úoutgoinghooksr   ÚoutgoinghookÚsummaryremotehooksÚsummaryremotehookr   ÚwireprotocommandÚputlfileÚgetlfileÚ	statlfileÚheadsr   ÚwrapfunctionÚcommandsÚoverriderebasecmd)r   ÚnameÚmodules      r   Ú_uisetupr,   £   s©  € åÔ×#Ò#¥LÑ1Ô1Ğ1İÔ× Ò ¥Ô!4Ñ5Ô5Ğ5åÔ×Ò˜m­YÔ-CÑDÔDĞDİÔ×"Ò" =µ)Ô2MÑNÔNĞNğ PÕÔ& {°FÀwĞOÑOÔOİŒñô ğ ğ PÕÔ& {°FÀwĞOÑOÔOİŒñô ğ ğÕÔ&Øf¨ğñ ô å„oñô ğ ğ KÕÔ& y°#À'ĞJÑJÔJİÔñô ğ õ ÔİÔ" 8Ô,¨gµu´{ñô ğ õ #Ô-Ñ/Ô/ğ ğ ‰ˆˆfØ9ÒĞåÔ#Ø˜	¥9Ô#>ñô ğ øğğ r   )Ú__doc__Ú	mercurialr   r   r   r   r   r   Ú r
   r   r   r   Ú
testedwithÚehÚmergeÚ
configitemÚdynamicdefaultÚlistÚcmdtableÚconfigtableÚfinalextsetupÚextsetupÚfinaluisetupÚuisetupr   r,   Úrevsetpredicater   r   r   ú<module>r=      sÈ  ğğağ ağFğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ #€
à€YÔÑÔ€Ø ‡‚ˆŒÑ Ô Ğ Ø ‡‚ˆŒÑ Ô Ğ Ø ‡‚ˆŒÑ Ô Ğ à ‡‚ØØØŒMÔ(ğ ñ ô ğ ğ
 ‡‚ØØØğ ñ ô ğ ğ
 ‡‚ØØØğ ñ ô ğ ğ Œ;€ØŒn€ØÔ€ØÔ€	Ø
Œ/€ğ!ğ !ğ !ğ
 „ğ ğ  ñ „ğ ğF Ô$€€€r                                                                                                                                                                                                                                                                                                                                                                                                                                                                                               usr/lib/python3/dist-packages/hgext/largefiles/__pycache__/basestore.cpython-311.pyc                0000644 0000000 0000000 00000023611 14714551121 027107  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        §
    	^µcÔ  ã                   ó|   — d Z ddlmZ ddlmZ ddlmZ ddlmZ ddl	m
Z
  G d„ d	e¦  «        Z G d
„ d¦  «        ZdS )zCbase class for store implementations and store-related utility codeé    )Ú_)Úshort)Úutil)Úurlutilé   )Úlfutilc                   ó$   — e Zd ZdZd„ Zd„ Zd„ ZdS )Ú
StoreErrorzZRaised when there is a problem getting files from or putting
    files to a central store.c                 ó>   — || _         || _        || _        || _        d S ©N)ÚfilenameÚhashÚurlÚdetail)Úselfr   r   r   r   s        ú</usr/lib/python3/dist-packages/hgext/largefiles/basestore.pyÚ__init__zStoreError.__init__   s"   € Ø ˆŒØˆŒ	ØˆŒØˆŒˆˆó    c                 óz   — t          d¦  «        | j        t          j        | j        ¦  «        | j        | j        fz  S )Ns0   error getting id %s from url %s for file %s: %s
)r   r   r   Úhidepasswordr   r   r   ©r   s    r   ÚlongmessagezStoreError.longmessage    s=   € İĞEÑFÔFØŒIİÔ  ¤Ñ*Ô*ØŒMØŒKğ	J
ñ 
ğ 	
r   c                 óH   — dt          j        | j        ¦  «        | j        fz  S )Ns   %s: %s)r   r   r   r   r   s    r   Ú__str__zStoreError.__str__(   s!   € ØGÔ0°´Ñ:Ô:¸D¼KĞHÑHĞHr   N)Ú__name__Ú
__module__Ú__qualname__Ú__doc__r   r   r   © r   r   r
   r
      sP   € € € € € ğ!ğ !ğğ ğ ğ
ğ 
ğ 
ğIğ Iğ Iğ Iğ Ir   r
   c                   ó@   — e Zd Zd„ Zd„ Zd„ Zd„ Zd„ Zdd„Zd„ Z	d	„ Z
d
S )Ú	basestorec                 ó0   — || _         || _        || _        d S r   )ÚuiÚrepor   )r   r#   r$   r   s       r   r   zbasestore.__init__-   s   € ØˆŒØˆŒ	ØˆŒˆˆr   c                 ó    — t          d¦  «        ‚)z>Put source file into the store so it can be retrieved by hash.ó   abstract method©ÚNotImplementedError)r   Úsourcer   s      r   Úputzbasestore.put2   s   € å!Ğ"4Ñ5Ô5Ğ5r   c                 ó    — t          d¦  «        ‚)z€Check to see if the store contains the given hashes. Given an
        iterable of hashes it returns a mapping from hash to bool.r&   r'   )r   Úhashess     r   Úexistszbasestore.exists6   s   € õ "Ğ"4Ñ5Ô5Ğ5r   c           
      óş  — g }g }| j         }d}|                      d„ |D ¦   «         ¦  «        }|                     t          d¦  «        t          d¦  «        t	          |¦  «        ¬¦  «        5 }|D ]ó\  }}	|                     |¦  «         |dz  }|                     t          d¦  «        ||	fz  ¦  «         |                     |	¦  «        sU|                     t          d¦  «        ||	t          j
        | j        ¦  «        fz  ¦  «         |                     |¦  «         Œ°|                      ||	¦  «        r|                     ||	f¦  «         ŒŞ|                     |¦  «         Œô	 d	d	d	¦  «         n# 1 swxY w Y   ||fS )
aú  Get the specified largefiles from the store and write to local
        files under repo.root.  files is a list of (filename, hash)
        tuples.  Return (success, missing), lists of files successfully
        downloaded and those not found in the store.  success is a list
        of (filename, hash) tuples; missing is a list of filenames that
        we could not get.  (The detailed error message will already have
        been presented to the user, so missing is just supplied as a
        summary.)r   c                 ó   — h | ]\  }}|’ŒS r   r   )Ú.0Ú	_filenamer   s      r   ú	<setcomp>z basestore.get.<locals>.<setcomp>I   s   € Ğ EĞ EĞ EÑ*;¨9°d Ğ EĞ EĞ Er   s   getting largefiless   files)ÚunitÚtotalr   s   getting %s:%s
s'   %s: largefile %s not available from %s
N)r#   r-   Úmakeprogressr   ÚlenÚupdateÚnoteÚgetÚwarnr   r   r   ÚappendÚ_gethash)
r   ÚfilesÚsuccessÚmissingr#   ÚatÚ	availableÚprogressr   r   s
             r   r9   zbasestore.get;   sÖ  € ğ ˆØˆØŒWˆàˆØ—K’KĞ EĞ E¸uĞ EÑ EÔ EÑFÔFˆ	Ø_Š_İĞ#Ñ$Ô$­1¨X©;¬;½cÀ%¹j¼jğ ñ 
ô 
ğ 	-àØ"'ğ -ğ -‘˜$Ø—’ Ñ#Ô#Ğ#Øa‘Ø—’Ğ,Ñ-Ô-°¸4Ğ0@Ñ@ÑAÔAĞAà —}’} TÑ*Ô*ğ Ø—G’GİĞEÑFÔFØ# T­7Ô+?ÀÄÑ+IÔ+IĞJñKñô ğ ğ —N’N 8Ñ,Ô,Ğ,Øà—=’= ¨4Ñ0Ô0ğ -Ø—N’N H¨dĞ#3Ñ4Ô4Ğ4Ğ4à—N’N 8Ñ,Ô,Ğ,Ğ,ğ!-ğ	-ğ 	-ğ 	-ñ 	-ô 	-ğ 	-ğ 	-ğ 	-ğ 	-ğ 	-ğ 	-øøøğ 	-ğ 	-ğ 	-ğ 	-ğ* ˜Ğ!Ğ!s   Á,C7E0Å0E4Å7E4c                 óÎ  — t          j        t          j        | j        d¦  «        ¦  «         t          j        | j        |¦  «        }|dz   }t          j        || j        j        j        ¬¦  «        5 }	 |                      |||¦  «        }nE# t          $ r8}| j
                             |                     ¦   «         ¦  «         d}Y d}~nd}~ww xY wddd¦  «         n# 1 swxY w Y   ||k    rI|dk    r-| j
                             t          d¦  «        |||fz  ¦  «         t          j        |¦  «         dS t          j        ||¦  «         t          j        | j        |¦  «         dS )z¢Get file with the provided hash and store it in the local repo's
        store and in the usercache.
        filename is for informational messages only.
        r   s   .tmp)Ú
createmodeNs*   %s: data corruption (expected %s, got %s)
FT)r   Úmakedirsr   Ú	storepathr$   ÚatomictempfileÚstorerD   Ú_getfiler
   r#   r:   r   r   ÚunlinkÚrenameÚlinktousercache)r   r   r   ÚstorefilenameÚtmpnameÚtmpfileÚgothashÚerrs           r   r<   zbasestore._gethasha   sª  € õ
 	Œ•fÔ& t¤y°#Ñ6Ô6Ñ7Ô7Ğ7İÔ(¨¬°DÑ9Ô9ˆà 'Ñ)ˆİÔ Ø ¤	¤Ô :ğ
ñ 
ô 
ğ 	àğØŸ-š-¨°¸4Ñ@Ô@øİğ ğ ğ Ø”—’˜SŸ_š_Ñ.Ô.Ñ/Ô/Ğ/Øøøøøğøøøğ	ğ 	ğ 	ñ 	ô 	ğ 	ğ 	ğ 	ğ 	ğ 	ğ 	øøøğ 	ğ 	ğ 	ğ 	ğ dŠ?ˆ?Ø˜#Š~ˆ~Ø”—’İĞDÑEÔEØ  wĞ/ñ0ñô ğ õ ŒK˜Ñ Ô Ğ Ø5åŒG˜]Ñ+Ô+Ğ+İÔ˜tœy¨$Ñ/Ô/Ğ/Øˆts<   Á1CÁ3BÂ
CÂ
CÂ.CÃCÃCÃCÃC Ã#C Fc                 óp  — | j                              t          d¦  «        t          |¦  «        z  ¦  «         t	          ¦   «         }g }|D ]Å}| j        |         }d|                     ¦   «         t          |                     ¦   «         ¦  «        fz  }|D ]{}t          j
        |¦  «        }	|	rc||         }
|	|
                     ¦   «         f}||vrA|                     |¦  «         t          j        |
¦  «        }|                     ||	|f¦  «         Œ|ŒÆ|                      ||¦  «        }t          |¦  «        }t          d„ |D ¦   «         ¦  «        }|r-| j                              t          d¦  «        ||fz  ¦  «         n,| j                              t          d¦  «        ||fz  ¦  «         t!          |¦  «        S )z³Verify the existence (and, optionally, contents) of every big
        file revision referenced by every changeset in revs.
        Return 0 if all is well, non-zero on any errors.s'   searching %d changesets for largefiles
s   %d:%sc                 ó   — h | ]\  }}|’ŒS r   r   )r0   ÚfnameÚfnodes      r   r2   z#basestore.verify.<locals>.<setcomp>›   s   € Ğ>Ğ>Ğ>¡> E¨5˜Ğ>Ğ>Ğ>r   s3   verified contents of %d revisions of %d largefiles
s4   verified existence of %d revisions of %d largefiles
)r#   Ústatusr   r6   Úsetr$   Úrevr   Únoder   ÚsplitstandinÚfilenodeÚaddÚreadasstandinr;   Ú_verifyfilesÚint)r   ÚrevsÚcontentsÚverifiedÚfilestocheckrX   ÚcctxÚcsetÚstandinr   ÚfctxÚkeyÚexpectedhashÚfailedÚnumrevsÚ	numlfiless                   r   Úverifyzbasestore.verify€   s×  € ğ
 	ŒŠİĞ9Ñ:Ô:½SÀ¹Y¼YÑFñ	
