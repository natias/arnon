        storedsize=False,
    ):
        d = {}

        if exclusivefiles:
            d[b'exclusivefiles'] = []

        if sharedfiles:
            # TODO list sqlite file(s) here.
            d[b'sharedfiles'] = []

        if revisionscount:
            d[b'revisionscount'] = len(self)

        if trackedsize:
            d[b'trackedsize'] = sum(
                len(self.revision(node)) for node in self._nodetorev
            )

        if storedsize:
            # TODO implement this?
            d[b'storedsize'] = None

        return d

    def verifyintegrity(self, state):
        state[b'skipread'] = set()

        for rev in self:
            node = self.node(rev)

            try:
                self.revision(node)
            except Exception as e:
                yield sqliteproblem(
                    error=_(b'unpacking %s: %s') % (short(node), e), node=node
                )

                state[b'skipread'].add(node)

    # End of ifilestorage interface.

    def _checkhash(self, fulltext, node, p1=None, p2=None):
        if p1 is None and p2 is None:
            p1, p2 = self.parents(node)

        if node == storageutil.hashrevisionsha1(fulltext, p1, p2):
            return

        try:
            del self._revisioncache[node]
        except KeyError:
            pass

        if storageutil.iscensoredtext(fulltext):
            raise error.CensoredNodeError(self._path, node, fulltext)

        raise SQLiteStoreError(_(b'integrity check failed on %s') % self._path)

    def _addrawrevision(
        self,
        node,
        revisiondata,
        transaction,
        linkrev,
        p1,
        p2,
        storedelta=None,
        flags=0,
    ):
        if self._pathid is None:
            res = self._db.execute(
                'INSERT INTO filepath (path) VALUES (?)', (self._path,)
            )
            self._pathid = res.lastrowid

        # For simplicity, always store a delta against p1.
        # TODO we need a lot more logic here to make behavior reasonable.

        if storedelta:
            deltabase, delta = storedelta

            if isinstance(deltabase, int):
                deltabase = self.node(deltabase)

        else:
            assert revisiondata is not None
            deltabase = p1

            if deltabase == sha1nodeconstants.nullid:
                delta = revisiondata
            else:
                delta = mdiff.textdiff(
                    self.revision(self.rev(deltabase)), revisiondata
                )

        # File index stores a pointer to its delta and the parent delta.
        # The parent delta is stored via a pointer to the fileindex PK.
        if deltabase == sha1nodeconstants.nullid:
            baseid = None
        else:
            baseid = self._revisions[deltabase].rid

        # Deltas are stored with a hash of their content. This allows
        # us to de-duplicate. The table is configured to ignore conflicts
        # and it is faster to just insert and silently noop than to look
        # first.
        deltahash = hashutil.sha1(delta).digest()

        if self._compengine == b'zstd':
            deltablob = self._cctx.compress(delta)
            compression = COMPRESSION_ZSTD
        elif self._compengine == b'zlib':
            deltablob = zlib.compress(delta)
            compression = COMPRESSION_ZLIB
        elif self._compengine == b'none':
            deltablob = delta
            compression = COMPRESSION_NONE
        else:
            raise error.ProgrammingError(
                b'unhandled compression engine: %s' % self._compengine
            )

        # Don't store compressed data if it isn't practical.
        if len(deltablob) >= len(delta):
            deltablob = delta
            compression = COMPRESSION_NONE

        deltaid = insertdelta(self._db, compression, deltahash, deltablob)

        rev = len(self)

        if p1 == sha1nodeconstants.nullid:
            p1rev = nullrev
        else:
            p1rev = self._nodetorev[p1]

        if p2 == sha1nodeconstants.nullid:
            p2rev = nullrev
        else:
            p2rev = self._nodetorev[p2]

        rid = self._db.execute(
            'INSERT INTO fileindex ('
            '    pathid, revnum, node, p1rev, p2rev, linkrev, flags, '
            '    deltaid, deltabaseid) '
            '    VALUES (?, ?, ?, ?, ?, ?, ?, ?, ?)',
            (
                self._pathid,
                rev,
                node,
                p1rev,
                p2rev,
                linkrev,
                flags,
                deltaid,
                baseid,
            ),
        ).lastrowid

        entry = revisionentry(
            rid=rid,
            rev=rev,
            node=node,
            p1rev=p1rev,
            p2rev=p2rev,
            p1node=p1,
            p2node=p2,
            linkrev=linkrev,
            flags=flags,
        )

        self._nodetorev[node] = rev
        self._revtonode[rev] = node
        self._revisions[node] = entry

        return rev


class sqliterepository(localrepo.localrepository):
    def cancopy(self):
        return False

    def transaction(self, *args, **kwargs):
        current = self.currenttransaction()

        tr = super(sqliterepository, self).transaction(*args, **kwargs)

        if current:
            return tr

        self._dbconn.execute('BEGIN TRANSACTION')

        def committransaction(_):
            self._dbconn.commit()

        tr.addfinalize(b'sqlitestore', committransaction)

        return tr

    @property
    def _dbconn(self):
        # SQLite connections can only be used on the thread that created
        # them. In most cases, this "just works." However, hgweb uses
        # multiple threads.
        tid = threading.current_thread().ident

        if self._db:
            if self._db[0] == tid:
                return self._db[1]

        db = makedb(self.svfs.join(b'db.sqlite'))
        self._db = (tid, db)

        return db


def makedb(path):
    """Construct a database handle for a database at path."""

    db = sqlite3.connect(encoding.strfromlocal(path))
    db.text_factory = bytes

    res = db.execute('PRAGMA user_version').fetchone()[0]

    # New database.
    if res == 0:
        for statement in CREATE_SCHEMA:
            db.execute(statement)

        db.commit()

    elif res == CURRENT_SCHEMA_VERSION:
        pass

    else:
        raise error.Abort(_(b'sqlite database has unrecognized version'))

    db.execute('PRAGMA journal_mode=WAL')

    return db


def featuresetup(ui, supported):
    supported.add(REQUIREMENT)

    if zstd:
        supported.add(REQUIREMENT_ZSTD)

    supported.add(REQUIREMENT_ZLIB)
    supported.add(REQUIREMENT_NONE)
    supported.add(REQUIREMENT_SHALLOW_FILES)
    supported.add(requirements.NARROW_REQUIREMENT)


def newreporequirements(orig, ui, createopts):
    if createopts[b'backend'] != b'sqlite':
        return orig(ui, createopts)

    # This restriction can be lifted once we have more confidence.
    if b'sharedrepo' in createopts:
        raise error.Abort(
            _(b'shared repositories not supported with SQLite store')
        )

    # This filtering is out of an abundance of caution: we want to ensure
    # we honor creation options and we do that by annotating exactly the
    # creation options we recognize.
    known = {
        b'narrowfiles',
        b'backend',
        b'shallowfilestore',
    }

    unsupported = set(createopts) - known
    if unsupported:
        raise error.Abort(
            _(b'SQLite store does not support repo creation option: %s')
            % b', '.join(sorted(unsupported))
        )

    # Since we're a hybrid store that still relies on revlogs, we fall back
    # to using the revlogv1 backend's storage requirements then adding our
    # own requirement.
    createopts[b'backend'] = b'revlogv1'
    requirements = orig(ui, createopts)
    requirements.add(REQUIREMENT)

    compression = ui.config(b'storage', b'sqlite.compression')

    if compression == b'zstd' and not zstd:
        raise error.Abort(
            _(
                b'storage.sqlite.compression set to "zstd" but '
                b'zstandard compression not available to this '
                b'Mercurial install'
            )
        )

    if compression == b'zstd':
        requirements.add(REQUIREMENT_ZSTD)
    elif compression == b'zlib':
        requirements.add(REQUIREMENT_ZLIB)
    elif compression == b'none':
        requirements.add(REQUIREMENT_NONE)
    else:
        raise error.Abort(
            _(
                b'unknown compression engine defined in '
                b'storage.sqlite.compression: %s'
            )
            % compression
        )

    if createopts.get(b'shallowfilestore'):
        requirements.add(REQUIREMENT_SHALLOW_FILES)

    return requirements


@interfaceutil.implementer(repository.ilocalrepositoryfilestorage)
class sqlitefilestorage:
    """Repository file storage backed by SQLite."""

    def file(self, path):
        if path[0] == b'/':
            path = path[1:]

        if REQUIREMENT_ZSTD in self.requirements:
            compression = b'zstd'
        elif REQUIREMENT_ZLIB in self.requirements:
            compression = b'zlib'
        elif REQUIREMENT_NONE in self.requirements:
            compression = b'none'
        else:
            raise error.Abort(
                _(
                    b'unable to determine what compression engine '
                    b'to use for SQLite storage'
                )
            )

        return sqlitefilestore(self._dbconn, path, compression)


def makefilestorage(orig, requirements, features, **kwargs):
    """Produce a type conforming to ``ilocalrepositoryfilestorage``."""
    if REQUIREMENT in requirements:
        if REQUIREMENT_SHALLOW_FILES in requirements:
            features.add(repository.REPO_FEATURE_SHALLOW_FILE_STORAGE)

        return sqlitefilestorage
    else:
        return orig(requirements=requirements, features=features, **kwargs)


def makemain(orig, ui, requirements, **kwargs):
    if REQUIREMENT in requirements:
        if REQUIREMENT_ZSTD in requirements and not zstd:
            raise error.Abort(
                _(
                    b'repository uses zstandard compression, which '
                    b'is not available to this Mercurial install'
                )
            )

        return sqliterepository

    return orig(requirements=requirements, **kwargs)


def verifierinit(orig, self, *args, **kwargs):
    orig(self, *args, **kwargs)

    # We don't care that files in the store don't align with what is
    # advertised. So suppress these warnings.
    self.warnorphanstorefiles = False


def extsetup(ui):
    localrepo.featuresetupfuncs.add(featuresetup)
    extensions.wrapfunction(
        localrepo, b'newreporequirements', newreporequirements
    )
    extensions.wrapfunction(localrepo, b'makefilestorage', makefilestorage)
    extensions.wrapfunction(localrepo, b'makemain', makemain)
    extensions.wrapfunction(verify.verifier, b'__init__', verifierinit)


def reposetup(ui, repo):
    if isinstance(repo, sqliterepository):
        repo._db = None

    # TODO check for bundlerepository?
                                                                                                                                                                                                                                                                                                                                                       usr/lib/python3/dist-packages/hgext/strip.py                                                        0000644 0000000 0000000 00000001622 14355257011 017604  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        """strip changesets and their descendants from history (DEPRECATED)

The functionality of this extension has been included in core Mercurial
since version 5.7. Please use :hg:`debugstrip ...` instead.

This extension allows you to strip changesets and all their descendants from the
repository. See the command help for details.
"""

from mercurial import commands

# Note for extension authors: ONLY specify testedwith = 'ships-with-hg-core' for
# extensions which SHIP WITH MERCURIAL. Non-mainline extensions should
# be specifying the version(s) of Mercurial they are tested with, or
# leave the attribute unspecified.
testedwith = b'ships-with-hg-core'

# This is a bit ugly, but a uisetup function that defines strip as an
# alias for debugstrip would override any user alias for strip,
# including aliases like "strip = strip --no-backup".
commands.command.rename(old=b'debugstrip', new=b'debugstrip|strip')
                                                                                                              usr/lib/python3/dist-packages/hgext/transplant.py                                                   0000644 0000000 0000000 00000074014 14355257011 020636  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # Patch transplanting extension for Mercurial
#
# Copyright 2006, 2007 Brendan Cully <brendan@kublai.com>
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.

'''command to transplant changesets from another branch

This extension allows you to transplant changes to another parent revision,
possibly in another repository. The transplant is done using 'diff' patches.

Transplanted patches are recorded in .hg/transplant/transplants, as a
map from a changeset hash to its hash in the source repository.
'''

import os

from mercurial.i18n import _
from mercurial.pycompat import open
from mercurial.node import (
    bin,
    hex,
    short,
)
from mercurial import (
    bundlerepo,
    cmdutil,
    error,
    exchange,
    hg,
    logcmdutil,
    match,
    merge,
    patch,
    pycompat,
    registrar,
    revset,
    smartset,
    state as statemod,
    util,
    vfs as vfsmod,
)
from mercurial.utils import (
    procutil,
    stringutil,
    urlutil,
)


class TransplantError(error.Abort):
    pass


cmdtable = {}
command = registrar.command(cmdtable)
# Note for extension authors: ONLY specify testedwith = 'ships-with-hg-core' for
# extensions which SHIP WITH MERCURIAL. Non-mainline extensions should
# be specifying the version(s) of Mercurial they are tested with, or
# leave the attribute unspecified.
testedwith = b'ships-with-hg-core'

configtable = {}
configitem = registrar.configitem(configtable)

configitem(
    b'transplant',
    b'filter',
    default=None,
)
configitem(
    b'transplant',
    b'log',
    default=None,
)


class transplantentry:
    def __init__(self, lnode, rnode):
        self.lnode = lnode
        self.rnode = rnode


class transplants:
    def __init__(self, path=None, transplantfile=None, opener=None):
        self.path = path
        self.transplantfile = transplantfile
        self.opener = opener

        if not opener:
            self.opener = vfsmod.vfs(self.path)
        self.transplants = {}
        self.dirty = False
        self.read()

    def read(self):
        abspath = os.path.join(self.path, self.transplantfile)
        if self.transplantfile and os.path.exists(abspath):
            for line in self.opener.read(self.transplantfile).splitlines():
                lnode, rnode = map(bin, line.split(b':'))
                list = self.transplants.setdefault(rnode, [])
                list.append(transplantentry(lnode, rnode))

    def write(self):
        if self.dirty and self.transplantfile:
            if not os.path.isdir(self.path):
                os.mkdir(self.path)
            fp = self.opener(self.transplantfile, b'w')
            for list in self.transplants.values():
                for t in list:
                    l, r = map(hex, (t.lnode, t.rnode))
                    fp.write(l + b':' + r + b'\n')
            fp.close()
        self.dirty = False

    def get(self, rnode):
        return self.transplants.get(rnode) or []

    def set(self, lnode, rnode):
        list = self.transplants.setdefault(rnode, [])
        list.append(transplantentry(lnode, rnode))
        self.dirty = True

    def remove(self, transplant):
        list = self.transplants.get(transplant.rnode)
        if list:
            del list[list.index(transplant)]
            self.dirty = True


class transplanter:
    def __init__(self, ui, repo, opts):
        self.ui = ui
        self.repo = repo
        self.path = repo.vfs.join(b'transplant')
        self.opener = vfsmod.vfs(self.path)
        self.transplants = transplants(
            self.path, b'transplants', opener=self.opener
        )

        def getcommiteditor():
            editform = cmdutil.mergeeditform(repo[None], b'transplant')
            return cmdutil.getcommiteditor(
                editform=editform, **pycompat.strkwargs(opts)
            )

        self.getcommiteditor = getcommiteditor

    def applied(self, repo, node, parent):
        """returns True if a node is already an ancestor of parent
        or is parent or has already been transplanted"""
        if hasnode(repo, parent):
            parentrev = repo.changelog.rev(parent)
        if hasnode(repo, node):
            rev = repo.changelog.rev(node)
            reachable = repo.changelog.ancestors(
                [parentrev], rev, inclusive=True
            )
            if rev in reachable:
                return True
        for t in self.transplants.get(node):
            # it might have been stripped
            if not hasnode(repo, t.lnode):
                self.transplants.remove(t)
                return False
            lnoderev = repo.changelog.rev(t.lnode)
            if lnoderev in repo.changelog.ancestors(
                [parentrev], lnoderev, inclusive=True
            ):
                return True
        return False

    def apply(self, repo, source, revmap, merges, opts=None):
        '''apply the revisions in revmap one by one in revision order'''
        if opts is None:
            opts = {}
        revs = sorted(revmap)
        p1 = repo.dirstate.p1()
        pulls = []
        diffopts = patch.difffeatureopts(self.ui, opts)
        diffopts.git = True

        lock = tr = None
        try:
            lock = repo.lock()
            tr = repo.transaction(b'transplant')
            for rev in revs:
                node = revmap[rev]
                revstr = b'%d:%s' % (rev, short(node))

                if self.applied(repo, node, p1):
                    self.ui.warn(
                        _(b'skipping already applied revision %s\n') % revstr
                    )
                    continue

                parents = source.changelog.parents(node)
                if not (opts.get(b'filter') or opts.get(b'log')):
                    # If the changeset parent is the same as the
                    # wdir's parent, just pull it.
                    if parents[0] == p1:
                        pulls.append(node)
                        p1 = node
                        continue
                    if pulls:
                        if source != repo:
                            exchange.pull(repo, source.peer(), heads=pulls)
                        merge.update(repo[pulls[-1]])
                        p1 = repo.dirstate.p1()
                        pulls = []

                domerge = False
                if node in merges:
                    # pulling all the merge revs at once would mean we
                    # couldn't transplant after the latest even if
                    # transplants before them fail.
                    domerge = True
                    if not hasnode(repo, node):
                        exchange.pull(repo, source.peer(), heads=[node])

                skipmerge = False
                if parents[1] != repo.nullid:
                    if not opts.get(b'parent'):
                        self.ui.note(
                            _(b'skipping merge changeset %d:%s\n')
                            % (rev, short(node))
                        )
                        skipmerge = True
                    else:
                        parent = source.lookup(opts[b'parent'])
                        if parent not in parents:
                            raise error.Abort(
                                _(b'%s is not a parent of %s')
                                % (short(parent), short(node))
                            )
                else:
                    parent = parents[0]

                if skipmerge:
                    patchfile = None
                else:
                    fd, patchfile = pycompat.mkstemp(prefix=b'hg-transplant-')
                    fp = os.fdopen(fd, 'wb')
                    gen = patch.diff(source, parent, node, opts=diffopts)
                    for chunk in gen:
                        fp.write(chunk)
                    fp.close()

                del revmap[rev]
                if patchfile or domerge:
                    try:
                        try:
                            n = self.applyone(
                                repo,
                                node,
                                source.changelog.read(node),
                                patchfile,
                                merge=domerge,
                                log=opts.get(b'log'),
                                filter=opts.get(b'filter'),
                            )
                        except TransplantError:
                            # Do not rollback, it is up to the user to
                            # fix the merge or cancel everything
                            tr.close()
                            raise
                        if n and domerge:
                            self.ui.status(
                                _(b'%s merged at %s\n') % (revstr, short(n))
                            )
                        elif n:
                            self.ui.status(
                                _(b'%s transplanted to %s\n')
                                % (short(node), short(n))
                            )
                    finally:
                        if patchfile:
                            os.unlink(patchfile)
            tr.close()
            if pulls:
                exchange.pull(repo, source.peer(), heads=pulls)
                merge.update(repo[pulls[-1]])
        finally:
            self.saveseries(revmap, merges)
            self.transplants.write()
            if tr:
                tr.release()
            if lock:
                lock.release()

    def filter(self, filter, node, changelog, patchfile):
        '''arbitrarily rewrite changeset before applying it'''

        self.ui.status(_(b'filtering %s\n') % patchfile)
        user, date, msg = (changelog[1], changelog[2], changelog[4])
        fd, headerfile = pycompat.mkstemp(prefix=b'hg-transplant-')
        fp = os.fdopen(fd, 'wb')
        fp.write(b"# HG changeset patch\n")
        fp.write(b"# User %s\n" % user)
        fp.write(b"# Date %d %d\n" % date)
        fp.write(msg + b'\n')
        fp.close()

        try:
            self.ui.system(
                b'%s %s %s'
                % (
                    filter,
                    procutil.shellquote(headerfile),
                    procutil.shellquote(patchfile),
                ),
                environ={
                    b'HGUSER': changelog[1],
                    b'HGREVISION': hex(node),
                },
                onerr=error.Abort,
                errprefix=_(b'filter failed'),
                blockedtag=b'transplant_filter',
            )
            user, date, msg = self.parselog(open(headerfile, b'rb'))[1:4]
        finally:
            os.unlink(headerfile)

        return (user, date, msg)

    def applyone(
        self, repo, node, cl, patchfile, merge=False, log=False, filter=None
    ):
        '''apply the patch in patchfile to the repository as a transplant'''
        (manifest, user, (time, timezone), files, message) = cl[:5]
        date = b"%d %d" % (time, timezone)
        extra = {b'transplant_source': node}
        if filter:
            (user, date, message) = self.filter(filter, node, cl, patchfile)

        if log:
            # we don't translate messages inserted into commits
            message += b'\n(transplanted from %s)' % hex(node)

        self.ui.status(_(b'applying %s\n') % short(node))
        self.ui.note(b'%s %s\n%s\n' % (user, date, message))

        if not patchfile and not merge:
            raise error.Abort(_(b'can only omit patchfile if merging'))
        if patchfile:
            try:
                files = set()
                patch.patch(self.ui, repo, patchfile, files=files, eolmode=None)
                files = list(files)
            except Exception as inst:
                seriespath = os.path.join(self.path, b'series')
                if os.path.exists(seriespath):
                    os.unlink(seriespath)
                p1 = repo.dirstate.p1()
                p2 = node
                self.log(user, date, message, p1, p2, merge=merge)
                self.ui.write(stringutil.forcebytestr(inst) + b'\n')
                raise TransplantError(
                    _(
                        b'fix up the working directory and run '
                        b'hg transplant --continue'
                    )
                )
        else:
            files = None
        if merge:
            p1 = repo.dirstate.p1()
            repo.setparents(p1, node)
            m = match.always()
        else:
            m = match.exact(files)

        n = repo.commit(
            message,
            user,
            date,
            extra=extra,
            match=m,
            editor=self.getcommiteditor(),
        )
        if not n:
            self.ui.warn(_(b'skipping emptied changeset %s\n') % short(node))
            return None
        if not merge:
            self.transplants.set(n, node)

        return n

    def canresume(self):
        return os.path.exists(os.path.join(self.path, b'journal'))

    def resume(self, repo, source, opts):
        '''recover last transaction and apply remaining changesets'''
        if os.path.exists(os.path.join(self.path, b'journal')):
            n, node = self.recover(repo, source, opts)
            if n:
                self.ui.status(
                    _(b'%s transplanted as %s\n') % (short(node), short(n))
                )
            else:
                self.ui.status(
                    _(b'%s skipped due to empty diff\n') % (short(node),)
                )
        seriespath = os.path.join(self.path, b'series')
        if not os.path.exists(seriespath):
            self.transplants.write()
            return
        nodes, merges = self.readseries()
        revmap = {}
        for n in nodes:
            revmap[source.changelog.rev(n)] = n
        os.unlink(seriespath)

        self.apply(repo, source, revmap, merges, opts)

    def recover(self, repo, source, opts):
        '''commit working directory using journal metadata'''
        node, user, date, message, parents = self.readlog()
        merge = False

        if not user or not date or not message or not parents[0]:
            raise error.Abort(_(b'transplant log file is corrupt'))

        parent = parents[0]
        if len(parents) > 1:
            if opts.get(b'parent'):
                parent = source.lookup(opts[b'parent'])
                if parent not in parents:
                    raise error.Abort(
                        _(b'%s is not a parent of %s')
                        % (short(parent), short(node))
                    )
            else:
                merge = True

        extra = {b'transplant_source': node}
        try:
            p1 = repo.dirstate.p1()
            if p1 != parent:
                raise error.Abort(
                    _(b'working directory not at transplant parent %s')
                    % hex(parent)
                )
            if merge:
                repo.setparents(p1, parents[1])
            st = repo.status()
            modified, added, removed, deleted = (
                st.modified,
                st.added,
                st.removed,
                st.deleted,
            )
            if merge or modified or added or removed or deleted:
                n = repo.commit(
                    message,
                    user,
                    date,
                    extra=extra,
                    editor=self.getcommiteditor(),
                )
                if not n:
                    raise error.Abort(_(b'commit failed'))
                if not merge:
                    self.transplants.set(n, node)
            else:
                n = None
            self.unlog()

            return n, node
        finally:
            # TODO: get rid of this meaningless try/finally enclosing.
            # this is kept only to reduce changes in a patch.
            pass

    def stop(self, ui, repo):
        """logic to stop an interrupted transplant"""
        if self.canresume():
            startctx = repo[b'.']
            merge.clean_update(startctx)
            ui.status(_(b"stopped the interrupted transplant\n"))
            ui.status(
                _(b"working directory is now at %s\n") % startctx.hex()[:12]
            )
            self.unlog()
            return 0

    def readseries(self):
        nodes = []
        merges = []
        cur = nodes
        for line in self.opener.read(b'series').splitlines():
            if line.startswith(b'# Merges'):
                cur = merges
                continue
            cur.append(bin(line))

        return (nodes, merges)

    def saveseries(self, revmap, merges):
        if not revmap:
            return

        if not os.path.isdir(self.path):
            os.mkdir(self.path)
        series = self.opener(b'series', b'w')
        for rev in sorted(revmap):
            series.write(hex(revmap[rev]) + b'\n')
        if merges:
            series.write(b'# Merges\n')
            for m in merges:
                series.write(hex(m) + b'\n')
        series.close()

    def parselog(self, fp):
        parents = []
        message = []
        node = self.repo.nullid
        inmsg = False
        user = None
        date = None
        for line in fp.read().splitlines():
            if inmsg:
                message.append(line)
            elif line.startswith(b'# User '):
                user = line[7:]
            elif line.startswith(b'# Date '):
                date = line[7:]
            elif line.startswith(b'# Node ID '):
                node = bin(line[10:])
            elif line.startswith(b'# Parent '):
                parents.append(bin(line[9:]))
            elif not line.startswith(b'# '):
                inmsg = True
                message.append(line)
        if None in (user, date):
            raise error.Abort(
                _(b"filter corrupted changeset (no user or date)")
            )
        return (node, user, date, b'\n'.join(message), parents)

    def log(self, user, date, message, p1, p2, merge=False):
        '''journal changelog metadata for later recover'''

        if not os.path.isdir(self.path):
            os.mkdir(self.path)
        fp = self.opener(b'journal', b'w')
        fp.write(b'# User %s\n' % user)
        fp.write(b'# Date %s\n' % date)
        fp.write(b'# Node ID %s\n' % hex(p2))
        fp.write(b'# Parent ' + hex(p1) + b'\n')
        if merge:
            fp.write(b'# Parent ' + hex(p2) + b'\n')
        fp.write(message.rstrip() + b'\n')
        fp.close()

    def readlog(self):
        return self.parselog(self.opener(b'journal'))

    def unlog(self):
        '''remove changelog journal'''
        absdst = os.path.join(self.path, b'journal')
        if os.path.exists(absdst):
            os.unlink(absdst)

    def transplantfilter(self, repo, source, root):
        def matchfn(node):
            if self.applied(repo, node, root):
                return False
            if source.changelog.parents(node)[1] != repo.nullid:
                return False
            extra = source.changelog.read(node)[5]
            cnode = extra.get(b'transplant_source')
            if cnode and self.applied(repo, cnode, root):
                return False
            return True

        return matchfn


def hasnode(repo, node):
    try:
        return repo.changelog.rev(node) is not None
    except error.StorageError:
        return False

