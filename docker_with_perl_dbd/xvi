    b'ext4',
    b'hfs',
    b'jfs',
    b'NTFS',
    b'reiserfs',
    b'tmpfs',
    b'ufs',
    b'xfs',
    b'zfs',
}


def copyfile(
    src,
    dest,
    hardlink=False,
    copystat=False,
    checkambig=False,
    nb_bytes=None,
    no_hardlink_cb=None,
    check_fs_hardlink=True,
):
    """copy a file, preserving mode and optionally other stat info like
    atime/mtime

    checkambig argument is used with filestat, and is useful only if
    destination file is guarded by any lock (e.g. repo.lock or
    repo.wlock).

    copystat and checkambig should be exclusive.

    nb_bytes: if set only copy the first `nb_bytes` of the source file.
    """
    assert not (copystat and checkambig)
    oldstat = None
    if os.path.lexists(dest):
        if checkambig:
            oldstat = checkambig and filestat.frompath(dest)
        unlink(dest)
    if hardlink and check_fs_hardlink:
        # Hardlinks are problematic on CIFS (issue4546), do not allow hardlinks
        # unless we are confident that dest is on a whitelisted filesystem.
        try:
            fstype = getfstype(os.path.dirname(dest))
        except OSError:
            fstype = None
        if fstype not in _hardlinkfswhitelist:
            if no_hardlink_cb is not None:
                no_hardlink_cb()
            hardlink = False
    if hardlink:
        try:
            oslink(src, dest)
            if nb_bytes is not None:
                m = "the `nb_bytes` argument is incompatible with `hardlink`"
                raise error.ProgrammingError(m)
            return
        except (IOError, OSError) as exc:
            if exc.errno != errno.EEXIST and no_hardlink_cb is not None:
                no_hardlink_cb()
            # fall back to normal copy
    if os.path.islink(src):
        os.symlink(os.readlink(src), dest)
        # copytime is ignored for symlinks, but in general copytime isn't needed
        # for them anyway
        if nb_bytes is not None:
            m = "cannot use `nb_bytes` on a symlink"
            raise error.ProgrammingError(m)
    else:
        try:
            shutil.copyfile(src, dest)
            if copystat:
                # copystat also copies mode
                shutil.copystat(src, dest)
            else:
                shutil.copymode(src, dest)
                if oldstat and oldstat.stat:
                    newstat = filestat.frompath(dest)
                    if newstat.isambig(oldstat):
                        # stat of copied file is ambiguous to original one
                        advanced = (
                            oldstat.stat[stat.ST_MTIME] + 1
                        ) & 0x7FFFFFFF
                        os.utime(dest, (advanced, advanced))
            # We could do something smarter using `copy_file_range` call or similar
            if nb_bytes is not None:
                with open(dest, mode='r+') as f:
                    f.truncate(nb_bytes)
        except shutil.Error as inst:
            raise error.Abort(stringutil.forcebytestr(inst))


def copyfiles(src, dst, hardlink=None, progress=None):
    """Copy a directory tree using hardlinks if possible."""
    num = 0

    def settopic():
        if progress:
            progress.topic = _(b'linking') if hardlink else _(b'copying')

    if os.path.isdir(src):
        if hardlink is None:
            hardlink = (
                os.stat(src).st_dev == os.stat(os.path.dirname(dst)).st_dev
            )
        settopic()
        os.mkdir(dst)
        for name, kind in listdir(src):
            srcname = os.path.join(src, name)
            dstname = os.path.join(dst, name)
            hardlink, n = copyfiles(srcname, dstname, hardlink, progress)
            num += n
    else:
        if hardlink is None:
            hardlink = (
                os.stat(os.path.dirname(src)).st_dev
                == os.stat(os.path.dirname(dst)).st_dev
            )
        settopic()

        if hardlink:
            try:
                oslink(src, dst)
            except (IOError, OSError) as exc:
                if exc.errno != errno.EEXIST:
                    hardlink = False
                # XXX maybe try to relink if the file exist ?
                shutil.copy(src, dst)
        else:
            shutil.copy(src, dst)
        num += 1
        if progress:
            progress.increment()

    return hardlink, num


_winreservednames = {
    b'con',
    b'prn',
    b'aux',
    b'nul',
    b'com1',
    b'com2',
    b'com3',
    b'com4',
    b'com5',
    b'com6',
    b'com7',
    b'com8',
    b'com9',
    b'lpt1',
    b'lpt2',
    b'lpt3',
    b'lpt4',
    b'lpt5',
    b'lpt6',
    b'lpt7',
    b'lpt8',
    b'lpt9',
}
_winreservedchars = b':*?"<>|'


def checkwinfilename(path):
    # type: (bytes) -> Optional[bytes]
    r"""Check that the base-relative path is a valid filename on Windows.
    Returns None if the path is ok, or a UI string describing the problem.

    >>> checkwinfilename(b"just/a/normal/path")
    >>> checkwinfilename(b"foo/bar/con.xml")
    "filename contains 'con', which is reserved on Windows"
    >>> checkwinfilename(b"foo/con.xml/bar")
    "filename contains 'con', which is reserved on Windows"
    >>> checkwinfilename(b"foo/bar/xml.con")
    >>> checkwinfilename(b"foo/bar/AUX/bla.txt")
    "filename contains 'AUX', which is reserved on Windows"
    >>> checkwinfilename(b"foo/bar/bla:.txt")
    "filename contains ':', which is reserved on Windows"
    >>> checkwinfilename(b"foo/bar/b\07la.txt")
    "filename contains '\\x07', which is invalid on Windows"
    >>> checkwinfilename(b"foo/bar/bla ")
    "filename ends with ' ', which is not allowed on Windows"
    >>> checkwinfilename(b"../bar")
    >>> checkwinfilename(b"foo\\")
    "filename ends with '\\', which is invalid on Windows"
    >>> checkwinfilename(b"foo\\/bar")
    "directory name ends with '\\', which is invalid on Windows"
    """
    if path.endswith(b'\\'):
        return _(b"filename ends with '\\', which is invalid on Windows")
    if b'\\/' in path:
        return _(b"directory name ends with '\\', which is invalid on Windows")
    for n in path.replace(b'\\', b'/').split(b'/'):
        if not n:
            continue
        for c in _filenamebytestr(n):
            if c in _winreservedchars:
                return (
                    _(
                        b"filename contains '%s', which is reserved "
                        b"on Windows"
                    )
                    % c
                )
            if ord(c) <= 31:
                return _(
                    b"filename contains '%s', which is invalid on Windows"
                ) % stringutil.escapestr(c)
        base = n.split(b'.')[0]
        if base and base.lower() in _winreservednames:
            return (
                _(b"filename contains '%s', which is reserved on Windows")
                % base
            )
        t = n[-1:]
        if t in b'. ' and n not in b'..':
            return (
                _(
                    b"filename ends with '%s', which is not allowed "
                    b"on Windows"
                )
                % t
            )


timer = getattr(time, "perf_counter", None)

if pycompat.iswindows:
    checkosfilename = checkwinfilename
    if not timer:
        timer = time.clock
else:
    # mercurial.windows doesn't have platform.checkosfilename
    checkosfilename = platform.checkosfilename  # pytype: disable=module-attr
    if not timer:
        timer = time.time


def makelock(info, pathname):
    """Create a lock file atomically if possible

    This may leave a stale lock file if symlink isn't supported and signal
    interrupt is enabled.
    """
    try:
        return os.symlink(info, pathname)
    except OSError as why:
        if why.errno == errno.EEXIST:
            raise
    except AttributeError:  # no symlink in os
        pass

    flags = os.O_CREAT | os.O_WRONLY | os.O_EXCL | getattr(os, 'O_BINARY', 0)
    ld = os.open(pathname, flags)
    os.write(ld, info)
    os.close(ld)


def readlock(pathname):
    # type: (bytes) -> bytes
    try:
        return readlink(pathname)
    except OSError as why:
        if why.errno not in (errno.EINVAL, errno.ENOSYS):
            raise
    except AttributeError:  # no symlink in os
        pass
    with posixfile(pathname, b'rb') as fp:
        return fp.read()


def fstat(fp):
    '''stat file object that may not have fileno method.'''
    try:
        return os.fstat(fp.fileno())
    except AttributeError:
        return os.stat(fp.name)


# File system features


def fscasesensitive(path):
    # type: (bytes) -> bool
    """
    Return true if the given path is on a case-sensitive filesystem

    Requires a path (like /foo/.hg) ending with a foldable final
    directory component.
    """
    s1 = os.lstat(path)
    d, b = os.path.split(path)
    b2 = b.upper()
    if b == b2:
        b2 = b.lower()
        if b == b2:
            return True  # no evidence against case sensitivity
    p2 = os.path.join(d, b2)
    try:
        s2 = os.lstat(p2)
        if s2 == s1:
            return False
        return True
    except OSError:
        return True


_re2_input = lambda x: x
try:
    import re2  # pytype: disable=import-error

    _re2 = None
except ImportError:
    _re2 = False


class _re:
    def _checkre2(self):
        global _re2
        global _re2_input

        check_pattern = br'\[([^\[]+)\]'
        check_input = b'[ui]'
        try:
            # check if match works, see issue3964
            _re2 = bool(re2.match(check_pattern, check_input))
        except ImportError:
            _re2 = False
        except TypeError:
            # the `pyre-2` project provides a re2 module that accept bytes
            # the `fb-re2` project provides a re2 module that acccept sysstr
            check_pattern = pycompat.sysstr(check_pattern)
            check_input = pycompat.sysstr(check_input)
            _re2 = bool(re2.match(check_pattern, check_input))
            _re2_input = pycompat.sysstr

    def compile(self, pat, flags=0):
        """Compile a regular expression, using re2 if possible

        For best performance, use only re2-compatible regexp features. The
        only flags from the re module that are re2-compatible are
        IGNORECASE and MULTILINE."""
        if _re2 is None:
            self._checkre2()
        if _re2 and (flags & ~(remod.IGNORECASE | remod.MULTILINE)) == 0:
            if flags & remod.IGNORECASE:
                pat = b'(?i)' + pat
            if flags & remod.MULTILINE:
                pat = b'(?m)' + pat
            try:
                return re2.compile(_re2_input(pat))
            except re2.error:
                pass
        return remod.compile(pat, flags)

    @propertycache
    def escape(self):
        """Return the version of escape corresponding to self.compile.

        This is imperfect because whether re2 or re is used for a particular
        function depends on the flags, etc, but it's the best we can do.
        """
        global _re2
        if _re2 is None:
            self._checkre2()
        if _re2:
            return re2.escape
        else:
            return remod.escape


re = _re()

_fspathcache = {}


def fspath(name, root):
    # type: (bytes, bytes) -> bytes
    """Get name in the case stored in the filesystem

    The name should be relative to root, and be normcase-ed for efficiency.

    Note that this function is unnecessary, and should not be
    called, for case-sensitive filesystems (simply because it's expensive).

    The root should be normcase-ed, too.
    """

    def _makefspathcacheentry(dir):
        return {normcase(n): n for n in os.listdir(dir)}

    seps = pycompat.ossep
    if pycompat.osaltsep:
        seps = seps + pycompat.osaltsep
    # Protect backslashes. This gets silly very quickly.
    seps.replace(b'\\', b'\\\\')
    pattern = remod.compile(br'([^%s]+)|([%s]+)' % (seps, seps))
    dir = os.path.normpath(root)
    result = []
    for part, sep in pattern.findall(name):
        if sep:
            result.append(sep)
            continue

        if dir not in _fspathcache:
            _fspathcache[dir] = _makefspathcacheentry(dir)
        contents = _fspathcache[dir]

        found = contents.get(part)
        if not found:
            # retry "once per directory" per "dirstate.walk" which
            # may take place for each patches of "hg qpush", for example
            _fspathcache[dir] = contents = _makefspathcacheentry(dir)
            found = contents.get(part)

        result.append(found or part)
        dir = os.path.join(dir, part)

    return b''.join(result)


def checknlink(testfile):
    # type: (bytes) -> bool
    '''check whether hardlink count reporting works properly'''

    # testfile may be open, so we need a separate file for checking to
    # work around issue2543 (or testfile may get lost on Samba shares)
    f1, f2, fp = None, None, None
    try:
        fd, f1 = pycompat.mkstemp(
            prefix=b'.%s-' % os.path.basename(testfile),
            suffix=b'1~',
            dir=os.path.dirname(testfile),
        )
        os.close(fd)
        f2 = b'%s2~' % f1[:-2]

        oslink(f1, f2)
        # nlinks() may behave differently for files on Windows shares if
        # the file is open.
        fp = posixfile(f2)
        return nlinks(f2) > 1
    except OSError:
        return False
    finally:
        if fp is not None:
            fp.close()
        for f in (f1, f2):
            try:
                if f is not None:
                    os.unlink(f)
            except OSError:
                pass


def endswithsep(path):
    # type: (bytes) -> bool
    '''Check path ends with os.sep or os.altsep.'''
    return bool(  # help pytype
        path.endswith(pycompat.ossep)
        or pycompat.osaltsep
        and path.endswith(pycompat.osaltsep)
    )


def splitpath(path):
    # type: (bytes) -> List[bytes]
    """Split path by os.sep.
    Note that this function does not use os.altsep because this is
    an alternative of simple "xxx.split(os.sep)".
    It is recommended to use os.path.normpath() before using this
    function if need."""
    return path.split(pycompat.ossep)


def mktempcopy(name, emptyok=False, createmode=None, enforcewritable=False):
    """Create a temporary file with the same contents from name

    The permission bits are copied from the original file.

    If the temporary file is going to be truncated immediately, you
    can use emptyok=True as an optimization.

    Returns the name of the temporary file.
    """
    d, fn = os.path.split(name)
    fd, temp = pycompat.mkstemp(prefix=b'.%s-' % fn, suffix=b'~', dir=d)
    os.close(fd)
    # Temporary files are created with mode 0600, which is usually not
    # what we want.  If the original file already exists, just copy
    # its mode.  Otherwise, manually obey umask.
    copymode(name, temp, createmode, enforcewritable)

    if emptyok:
        return temp
    try:
        try:
            ifp = posixfile(name, b"rb")
        except IOError as inst:
            if inst.errno == errno.ENOENT:
                return temp
            if not getattr(inst, 'filename', None):
                inst.filename = name
            raise
        ofp = posixfile(temp, b"wb")
        for chunk in filechunkiter(ifp):
            ofp.write(chunk)
        ifp.close()
        ofp.close()
    except:  # re-raises
        try:
            os.unlink(temp)
        except OSError:
            pass
        raise
    return temp


class filestat:
    """help to exactly detect change of a file

    'stat' attribute is result of 'os.stat()' if specified 'path'
    exists. Otherwise, it is None. This can avoid preparative
    'exists()' examination on client side of this class.
    """

    def __init__(self, stat):
        self.stat = stat

    @classmethod
    def frompath(cls, path):
        try:
            stat = os.stat(path)
        except FileNotFoundError:
            stat = None
        return cls(stat)

    @classmethod
    def fromfp(cls, fp):
        stat = os.fstat(fp.fileno())
        return cls(stat)

    __hash__ = object.__hash__

    def __eq__(self, old):
        try:
            # if ambiguity between stat of new and old file is
            # avoided, comparison of size, ctime and mtime is enough
            # to exactly detect change of a file regardless of platform
            return (
                self.stat.st_size == old.stat.st_size
                and self.stat[stat.ST_CTIME] == old.stat[stat.ST_CTIME]
                and self.stat[stat.ST_MTIME] == old.stat[stat.ST_MTIME]
            )
        except AttributeError:
            pass
        try:
            return self.stat is None and old.stat is None
        except AttributeError:
            return False

    def isambig(self, old):
        """Examine whether new (= self) stat is ambiguous against old one

        "S[N]" below means stat of a file at N-th change:

        - S[n-1].ctime  < S[n].ctime: can detect change of a file
        - S[n-1].ctime == S[n].ctime
          - S[n-1].ctime  < S[n].mtime: means natural advancing (*1)
          - S[n-1].ctime == S[n].mtime: is ambiguous (*2)
          - S[n-1].ctime  > S[n].mtime: never occurs naturally (don't care)
        - S[n-1].ctime  > S[n].ctime: never occurs naturally (don't care)

        Case (*2) above means that a file was changed twice or more at
        same time in sec (= S[n-1].ctime), and comparison of timestamp
        is ambiguous.

        Base idea to avoid such ambiguity is "advance mtime 1 sec, if
        timestamp is ambiguous".

        But advancing mtime only in case (*2) doesn't work as
        expected, because naturally advanced S[n].mtime in case (*1)
        might be equal to manually advanced S[n-1 or earlier].mtime.

        Therefore, all "S[n-1].ctime == S[n].ctime" cases should be
        treated as ambiguous regardless of mtime, to avoid overlooking
        by confliction between such mtime.

        Advancing mtime "if isambig(oldstat)" ensures "S[n-1].mtime !=
        S[n].mtime", even if size of a file isn't changed.
        """
        try:
            return self.stat[stat.ST_CTIME] == old.stat[stat.ST_CTIME]
        except AttributeError:
            return False

    def avoidambig(self, path, old):
        """Change file stat of specified path to avoid ambiguity

        'old' should be previous filestat of 'path'.

        This skips avoiding ambiguity, if a process doesn't have
        appropriate privileges for 'path'. This returns False in this
        case.

        Otherwise, this returns True, as "ambiguity is avoided".
        """
        advanced = (old.stat[stat.ST_MTIME] + 1) & 0x7FFFFFFF
        try:
            os.utime(path, (advanced, advanced))
        except PermissionError:
            # utime() on the file created by another user causes EPERM,
            # if a process doesn't have appropriate privileges
            return False
        return True

    def __ne__(self, other):
        return not self == other


class atomictempfile:
    """writable file object that atomically updates a file

    All writes will go to a temporary copy of the original file. Call
    close() when you are done writing, and atomictempfile will rename
    the temporary copy to the original name, making the changes
    visible. If the object is destroyed without being closed, all your
    writes are discarded.

    checkambig argument of constructor is used with filestat, and is
    useful only if target file is guarded by any lock (e.g. repo.lock
    or repo.wlock).
    """

    def __init__(self, name, mode=b'w+b', createmode=None, checkambig=False):
        self.__name = name  # permanent name
        self._tempname = mktempcopy(
            name,
            emptyok=(b'w' in mode),
            createmode=createmode,
            enforcewritable=(b'w' in mode),
        )

        self._fp = posixfile(self._tempname, mode)
        self._checkambig = checkambig

        # delegated methods
        self.read = self._fp.read
        self.write = self._fp.write
        self.seek = self._fp.seek
        self.tell = self._fp.tell
        self.fileno = self._fp.fileno

    def close(self):
        if not self._fp.closed:
            self._fp.close()
            filename = localpath(self.__name)
            oldstat = self._checkambig and filestat.frompath(filename)
            if oldstat and oldstat.stat:
                rename(self._tempname, filename)
                newstat = filestat.frompath(filename)
                if newstat.isambig(oldstat):
                    # stat of changed file is ambiguous to original one
                    advanced = (oldstat.stat[stat.ST_MTIME] + 1) & 0x7FFFFFFF
                    os.utime(filename, (advanced, advanced))
            else:
                rename(self._tempname, filename)

    def discard(self):
        if not self._fp.closed:
            try:
                os.unlink(self._tempname)
            except OSError:
                pass
            self._fp.close()

    def __del__(self):
        if safehasattr(self, '_fp'):  # constructor actually did something
            self.discard()

    def __enter__(self):
        return self

    def __exit__(self, exctype, excvalue, traceback):
        if exctype is not None:
            self.discard()
        else:
            self.close()


def tryrmdir(f):
    try:
        removedirs(f)
    except OSError as e:
        if e.errno != errno.ENOENT and e.errno != errno.ENOTEMPTY:
            raise


def unlinkpath(f, ignoremissing=False, rmdir=True):
    # type: (bytes, bool, bool) -> None
    """unlink and remove the directory if it is empty"""
    if ignoremissing:
        tryunlink(f)
    else:
        unlink(f)
    if rmdir:
        # try removing directories that might now be empty
        try:
            removedirs(os.path.dirname(f))
        except OSError:
            pass


def tryunlink(f):
    # type: (bytes) -> None
    """Attempt to remove a file, ignoring FileNotFoundError."""
    try:
        unlink(f)
    except FileNotFoundError:
        pass


def makedirs(name, mode=None, notindexed=False):
    # type: (bytes, Optional[int], bool) -> None
    """recursive directory creation with parent mode inheritance

    Newly created directories are marked as "not to be indexed by
    the content indexing service", if ``notindexed`` is specified
    for "write" mode access.
    """
    try:
        makedir(name, notindexed)
    except OSError as err:
        if err.errno == errno.EEXIST:
            return
        if err.errno != errno.ENOENT or not name:
            raise
        parent = os.path.dirname(abspath(name))
        if parent == name:
            raise
        makedirs(parent, mode, notindexed)
        try:
            makedir(name, notindexed)
        except OSError as err:
            # Catch EEXIST to handle races
            if err.errno == errno.EEXIST:
                return
            raise
    if mode is not None:
        os.chmod(name, mode)


def readfile(path):
    # type: (bytes) -> bytes
    with open(path, b'rb') as fp:
        return fp.read()


def writefile(path, text):
    # type: (bytes, bytes) -> None
    with open(path, b'wb') as fp:
        fp.write(text)


def appendfile(path, text):
    # type: (bytes, bytes) -> None
    with open(path, b'ab') as fp:
        fp.write(text)


class chunkbuffer:
    """Allow arbitrary sized chunks of data to be efficiently read from an
    iterator over chunks of arbitrary size."""

    def __init__(self, in_iter):
        """in_iter is the iterator that's iterating over the input chunks."""

        def splitbig(chunks):
            for chunk in chunks:
                if len(chunk) > 2 ** 20:
                    pos = 0
                    while pos < len(chunk):
                        end = pos + 2 ** 18
                        yield chunk[pos:end]
                        pos = end
                else:
                    yield chunk

        self.iter = splitbig(in_iter)
        self._queue = collections.deque()
        self._chunkoffset = 0

    def read(self, l=None):
        """Read L bytes of data from the iterator of chunks of data.
        Returns less than L bytes if the iterator runs dry.

        If size parameter is omitted, read everything"""
        if l is None:
            return b''.join(self.iter)

        left = l
        buf = []
        queue = self._queue
        while left > 0:
            # refill the queue
            if not queue:
                target = 2 ** 18
                for chunk in self.iter:
                    queue.append(chunk)
                    target -= len(chunk)
                    if target <= 0:
                        break
                if not queue:
                    break

            # The easy way to do this would be to queue.popleft(), modify the
            # chunk (if necessary), then queue.appendleft(). However, for cases
            # where we read partial chunk content, this incurs 2 dequeue
            # mutations and creates a new str for the remaining chunk in the
            # queue. Our code below avoids this overhead.

            chunk = queue[0]
            chunkl = len(chunk)
            offset = self._chunkoffset

            # Use full chunk.
            if offset == 0 and left >= chunkl:
                left -= chunkl
                queue.popleft()
                buf.append(chunk)
                # self._chunkoffset remains at 0.
                continue

            chunkremaining = chunkl - offset

            # Use all of unconsumed part of chunk.
            if left >= chunkremaining:
                left -= chunkremaining
                queue.popleft()
                # offset == 0 is enabled by block above, so this won't merely
                # copy via ``chunk[0:]``.
                buf.append(chunk[offset:])
                self._chunkoffset = 0

            # Partial chunk needed.
            else:
                buf.append(chunk[offset : offset + left])
                self._chunkoffset += left
                left -= chunkremaining

        return b''.join(buf)


def filechunkiter(f, size=131072, limit=None):
    """Create a generator that produces the data in the file size
    (default 131072) bytes at a time, up to optional limit (default is
    to read all data).  Chunks may be less than size bytes if the
    chunk is the last chunk in the file, or the file is a socket or
    some other type of file that sometimes reads less data than is
    requested."""
    assert size >= 0
    assert limit is None or limit >= 0
    while True:
        if limit is None:
            nbytes = size
        else:
            nbytes = min(limit, size)
        s = nbytes and f.read(nbytes)
        if not s:
            break
        if limit:
            limit -= len(s)
        yield s


class cappedreader:
    """A file object proxy that allows reading up to N bytes.

    Given a source file object, instances of this type allow reading up to
    N bytes from that source file object. Attempts to read past the allowed
    limit are treated as EOF.

    It is assumed that I/O is not performed on the original file object
    in addition to I/O that is performed by this instance. If there is,
    state tracking will get out of sync and unexpected results will ensue.
    """

    def __init__(self, fh, limit):
        """Allow reading up to <limit> bytes from <fh>."""
        self._fh = fh
        self._left = limit

    def read(self, n=-1):
        if not self._left:
            return b''

        if n < 0:
            n = self._left

        data = self._fh.read(min(n, self._left))
        self._left -= len(data)
        assert self._left >= 0

        return data

    def readinto(self, b):
        res = self.read(len(b))
        if res is None:
            return None

        b[0 : len(res)] = res
        return len(res)


def unitcountfn(*unittable):
    '''return a function that renders a readable count of some quantity'''

    def go(count):
        for multiplier, divisor, format in unittable:
            if abs(count) >= divisor * multiplier:
                return format % (count / float(divisor))
        return unittable[-1][2] % count

    return go


def processlinerange(fromline, toline):
    # type: (int, int) -> Tuple[int, int]
    """Check that linerange <fromline>:<toline> makes sense and return a
    0-based range.

    >>> processlinerange(10, 20)
    (9, 20)
    >>> processlinerange(2, 1)
    Traceback (most recent call last):
        ...
    ParseError: line range must be positive
    >>> processlinerange(0, 5)
    Traceback (most recent call last):
        ...
    ParseError: fromline must be strictly positive
    """
    if toline - fromline < 0:
        raise error.ParseError(_(b"line range must be positive"))
    if fromline < 1:
        raise error.ParseError(_(b"fromline must be strictly positive"))
    return fromline - 1, toline


bytecount = unitcountfn(
    (100, 1 << 30, _(b'%.0f GB')),
    (10, 1 << 30, _(b'%.1f GB')),
    (1, 1 << 30, _(b'%.2f GB')),
    (100, 1 << 20, _(b'%.0f MB')),
    (10, 1 << 20, _(b'%.1f MB')),
    (1, 1 << 20, _(b'%.2f MB')),
    (100, 1 << 10, _(b'%.0f KB')),
    (10, 1 << 10, _(b'%.1f KB')),
    (1, 1 << 10, _(b'%.2f KB')),
    (1, 1, _(b'%.0f bytes')),
)


class transformingwriter:
    """Writable file wrapper to transform data by function"""

    def __init__(self, fp, encode):
        self._fp = fp
        self._encode = encode

    def close(self):
        self._fp.close()

    def flush(self):
        self._fp.flush()

    def write(self, data):
        return self._fp.write(self._encode(data))


# Matches a single EOL which can either be a CRLF where repeated CR
# are removed or a LF. We do not care about old Macintosh files, so a
# stray CR is an error.
_eolre = remod.compile(br'\r*\n')


def tolf(s):
    # type: (bytes) -> bytes
    return _eolre.sub(b'\n', s)


def tocrlf(s):
    # type: (bytes) -> bytes
    return _eolre.sub(b'\r\n', s)


def _crlfwriter(fp):
    return transformingwriter(fp, tocrlf)

