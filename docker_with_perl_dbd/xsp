        # type: (localrepo.localrepository) -> Set[bytes]
        """returns the roots of all non-public phases

        The roots are not minimized, so if the secret revisions are
        descendants of draft revisions, their roots will still be present.
        """
        repo = repo.unfiltered()
        cl = repo.changelog
        if len(cl) >= self._loadedrevslen:
            self.invalidate()
            self.loadphaserevs(repo)
        return set().union(
            *[
                revs
                for phase, revs in self.phaseroots.items()
                if phase != public
            ]
        )

    def getrevset(self, repo, phases, subset=None):
        # type: (localrepo.localrepository, Iterable[int], Optional[Any]) -> Any
        # TODO: finish typing this
        """return a smartset for the given phases"""
        self.loadphaserevs(repo)  # ensure phase's sets are loaded
        phases = set(phases)
        publicphase = public in phases

        if publicphase:
            # In this case, phases keeps all the *other* phases.
            phases = set(allphases).difference(phases)
            if not phases:
                return smartset.fullreposet(repo)

        # fast path: _phasesets contains the interesting sets,
        # might only need a union and post-filtering.
        revsneedscopy = False
        if len(phases) == 1:
            [p] = phases
            revs = self._phasesets[p]
            revsneedscopy = True  # Don't modify _phasesets
        else:
            # revs has the revisions in all *other* phases.
            revs = set.union(*[self._phasesets[p] for p in phases])

        def _addwdir(wdirsubset, wdirrevs):
            if wdirrev in wdirsubset and repo[None].phase() in phases:
                if revsneedscopy:
                    wdirrevs = wdirrevs.copy()
                # The working dir would never be in the # cache, but it was in
                # the subset being filtered for its phase (or filtered out,
                # depending on publicphase), so add it to the output to be
                # included (or filtered out).
                wdirrevs.add(wdirrev)
            return wdirrevs

        if not publicphase:
            if repo.changelog.filteredrevs:
                revs = revs - repo.changelog.filteredrevs

            if subset is None:
                return smartset.baseset(revs)
            else:
                revs = _addwdir(subset, revs)
                return subset & smartset.baseset(revs)
        else:
            if subset is None:
                subset = smartset.fullreposet(repo)

            revs = _addwdir(subset, revs)

            if not revs:
                return subset
            return subset.filter(lambda r: r not in revs)

    def copy(self):
        # Shallow copy meant to ensure isolation in
        # advance/retractboundary(), nothing more.
        ph = self.__class__(None, None, _load=False)
        ph.phaseroots = self.phaseroots.copy()
        ph.dirty = self.dirty
        ph.opener = self.opener
        ph._loadedrevslen = self._loadedrevslen
        ph._phasesets = self._phasesets
        return ph

    def replace(self, phcache):
        """replace all values in 'self' with content of phcache"""
        for a in (
            b'phaseroots',
            b'dirty',
            b'opener',
            b'_loadedrevslen',
            b'_phasesets',
        ):
            setattr(self, a, getattr(phcache, a))

    def _getphaserevsnative(self, repo):
        repo = repo.unfiltered()
        return repo.changelog.computephases(self.phaseroots)

    def _computephaserevspure(self, repo):
        repo = repo.unfiltered()
        cl = repo.changelog
        self._phasesets = {phase: set() for phase in allphases}
        lowerroots = set()
        for phase in reversed(trackedphases):
            roots = pycompat.maplist(cl.rev, self.phaseroots[phase])
            if roots:
                ps = set(cl.descendants(roots))
                for root in roots:
                    ps.add(root)
                ps.difference_update(lowerroots)
                lowerroots.update(ps)
                self._phasesets[phase] = ps
        self._loadedrevslen = len(cl)

    def loadphaserevs(self, repo):
        # type: (localrepo.localrepository) -> None
        """ensure phase information is loaded in the object"""
        if self._phasesets is None:
            try:
                res = self._getphaserevsnative(repo)
                self._loadedrevslen, self._phasesets = res
            except AttributeError:
                self._computephaserevspure(repo)

    def invalidate(self):
        self._loadedrevslen = 0
        self._phasesets = None

    def phase(self, repo, rev):
        # type: (localrepo.localrepository, int) -> int
        # We need a repo argument here to be able to build _phasesets
        # if necessary. The repository instance is not stored in
        # phasecache to avoid reference cycles. The changelog instance
        # is not stored because it is a filecache() property and can
        # be replaced without us being notified.
        if rev == nullrev:
            return public
        if rev < nullrev:
            raise ValueError(_(b'cannot lookup negative revision'))
        if rev >= self._loadedrevslen:
            self.invalidate()
            self.loadphaserevs(repo)
        for phase in trackedphases:
            if rev in self._phasesets[phase]:
                return phase
        return public

    def write(self):
        if not self.dirty:
            return
        f = self.opener(b'phaseroots', b'w', atomictemp=True, checkambig=True)
        try:
            self._write(f)
        finally:
            f.close()

    def _write(self, fp):
        for phase, roots in self.phaseroots.items():
            for h in sorted(roots):
                fp.write(b'%i %s\n' % (phase, hex(h)))
        self.dirty = False

    def _updateroots(self, phase, newroots, tr):
        self.phaseroots[phase] = newroots
        self.invalidate()
        self.dirty = True

        tr.addfilegenerator(b'phase', (b'phaseroots',), self._write)
        tr.hookargs[b'phases_moved'] = b'1'

    def registernew(self, repo, tr, targetphase, revs):
        repo = repo.unfiltered()
        self._retractboundary(repo, tr, targetphase, [], revs=revs)
        if tr is not None and b'phases' in tr.changes:
            phasetracking = tr.changes[b'phases']
            phase = self.phase
            for rev in sorted(revs):
                revphase = phase(repo, rev)
                _trackphasechange(phasetracking, rev, None, revphase)
        repo.invalidatevolatilesets()

    def advanceboundary(
        self, repo, tr, targetphase, nodes, revs=None, dryrun=None
    ):
        """Set all 'nodes' to phase 'targetphase'

        Nodes with a phase lower than 'targetphase' are not affected.

        If dryrun is True, no actions will be performed

        Returns a set of revs whose phase is changed or should be changed
        """
        # Be careful to preserve shallow-copied values: do not update
        # phaseroots values, replace them.
        if revs is None:
            revs = []
        if tr is None:
            phasetracking = None
        else:
            phasetracking = tr.changes.get(b'phases')

        repo = repo.unfiltered()
        revs = [repo[n].rev() for n in nodes] + [r for r in revs]

        changes = set()  # set of revisions to be changed
        delroots = []  # set of root deleted by this path
        for phase in (phase for phase in allphases if phase > targetphase):
            # filter nodes that are not in a compatible phase already
            revs = [rev for rev in revs if self.phase(repo, rev) >= phase]
            if not revs:
                break  # no roots to move anymore

            olds = self.phaseroots[phase]

            affected = repo.revs(b'%ln::%ld', olds, revs)
            changes.update(affected)
            if dryrun:
                continue
            for r in affected:
                _trackphasechange(
                    phasetracking, r, self.phase(repo, r), targetphase
                )

            roots = {
                ctx.node()
                for ctx in repo.set(b'roots((%ln::) - %ld)', olds, affected)
            }
            if olds != roots:
                self._updateroots(phase, roots, tr)
                # some roots may need to be declared for lower phases
                delroots.extend(olds - roots)
        if not dryrun:
            # declare deleted root in the target phase
            if targetphase != 0:
                self._retractboundary(repo, tr, targetphase, delroots)
            repo.invalidatevolatilesets()
        return changes

    def retractboundary(self, repo, tr, targetphase, nodes):
        oldroots = {
            phase: revs
            for phase, revs in self.phaseroots.items()
            if phase <= targetphase
        }
        if tr is None:
            phasetracking = None
        else:
            phasetracking = tr.changes.get(b'phases')
        repo = repo.unfiltered()
        if (
            self._retractboundary(repo, tr, targetphase, nodes)
            and phasetracking is not None
        ):

            # find the affected revisions
            new = self.phaseroots[targetphase]
            old = oldroots[targetphase]
            affected = set(repo.revs(b'(%ln::) - (%ln::)', new, old))

            # find the phase of the affected revision
            for phase in range(targetphase, -1, -1):
                if phase:
                    roots = oldroots.get(phase, [])
                    revs = set(repo.revs(b'%ln::%ld', roots, affected))
                    affected -= revs
                else:  # public phase
                    revs = affected
                for r in sorted(revs):
                    _trackphasechange(phasetracking, r, phase, targetphase)
        repo.invalidatevolatilesets()

    def _retractboundary(self, repo, tr, targetphase, nodes, revs=None):
        # Be careful to preserve shallow-copied values: do not update
        # phaseroots values, replace them.
        if revs is None:
            revs = []
        if (
            targetphase == internal
            and not supportinternal(repo)
            or targetphase == archived
            and not supportarchived(repo)
        ):
            name = phasenames[targetphase]
            msg = b'this repository does not support the %s phase' % name
            raise error.ProgrammingError(msg)

        repo = repo.unfiltered()
        torev = repo.changelog.rev
        tonode = repo.changelog.node
        currentroots = {torev(node) for node in self.phaseroots[targetphase]}
        finalroots = oldroots = set(currentroots)
        newroots = [torev(node) for node in nodes] + [r for r in revs]
        newroots = [
            rev for rev in newroots if self.phase(repo, rev) < targetphase
        ]

        if newroots:
            if nullrev in newroots:
                raise error.Abort(_(b'cannot change null revision phase'))
            currentroots.update(newroots)

            # Only compute new roots for revs above the roots that are being
            # retracted.
            minnewroot = min(newroots)
            aboveroots = [rev for rev in currentroots if rev >= minnewroot]
            updatedroots = repo.revs(b'roots(%ld::)', aboveroots)

            finalroots = {rev for rev in currentroots if rev < minnewroot}
            finalroots.update(updatedroots)
        if finalroots != oldroots:
            self._updateroots(
                targetphase, {tonode(rev) for rev in finalroots}, tr
            )
            return True
        return False

    def filterunknown(self, repo):
        # type: (localrepo.localrepository) -> None
        """remove unknown nodes from the phase boundary

        Nothing is lost as unknown nodes only hold data for their descendants.
        """
        filtered = False
        has_node = repo.changelog.index.has_node  # to filter unknown nodes
        for phase, nodes in self.phaseroots.items():
            missing = sorted(node for node in nodes if not has_node(node))
            if missing:
                for mnode in missing:
                    repo.ui.debug(
                        b'removing unknown node %s from %i-phase boundary\n'
                        % (short(mnode), phase)
                    )
                nodes.symmetric_difference_update(missing)
                filtered = True
        if filtered:
            self.dirty = True
        # filterunknown is called by repo.destroyed, we may have no changes in
        # root but _phasesets contents is certainly invalid (or at least we
        # have not proper way to check that). related to issue 3858.
        #
        # The other caller is __init__ that have no _phasesets initialized
        # anyway. If this change we should consider adding a dedicated
        # "destroyed" function to phasecache or a proper cache key mechanism
        # (see branchmap one)
        self.invalidate()


def advanceboundary(repo, tr, targetphase, nodes, revs=None, dryrun=None):
    """Add nodes to a phase changing other nodes phases if necessary.

    This function move boundary *forward* this means that all nodes
    are set in the target phase or kept in a *lower* phase.

    Simplify boundary to contains phase roots only.

    If dryrun is True, no actions will be performed

    Returns a set of revs whose phase is changed or should be changed
    """
    if revs is None:
        revs = []
    phcache = repo._phasecache.copy()
    changes = phcache.advanceboundary(
        repo, tr, targetphase, nodes, revs=revs, dryrun=dryrun
    )
    if not dryrun:
        repo._phasecache.replace(phcache)
    return changes


def retractboundary(repo, tr, targetphase, nodes):
    """Set nodes back to a phase changing other nodes phases if
    necessary.

    This function move boundary *backward* this means that all nodes
    are set in the target phase or kept in a *higher* phase.

    Simplify boundary to contains phase roots only."""
    phcache = repo._phasecache.copy()
    phcache.retractboundary(repo, tr, targetphase, nodes)
    repo._phasecache.replace(phcache)


def registernew(repo, tr, targetphase, revs):
    """register a new revision and its phase

    Code adding revisions to the repository should use this function to
    set new changeset in their target phase (or higher).
    """
    phcache = repo._phasecache.copy()
    phcache.registernew(repo, tr, targetphase, revs)
    repo._phasecache.replace(phcache)


def listphases(repo):
    # type: (localrepo.localrepository) -> Dict[bytes, bytes]
    """List phases root for serialization over pushkey"""
    # Use ordered dictionary so behavior is deterministic.
    keys = util.sortdict()
    value = b'%i' % draft
    cl = repo.unfiltered().changelog
    for root in repo._phasecache.phaseroots[draft]:
        if repo._phasecache.phase(repo, cl.rev(root)) <= draft:
            keys[hex(root)] = value

    if repo.publishing():
        # Add an extra data to let remote know we are a publishing
        # repo. Publishing repo can't just pretend they are old repo.
        # When pushing to a publishing repo, the client still need to
        # push phase boundary
        #
        # Push do not only push changeset. It also push phase data.
        # New phase data may apply to common changeset which won't be
        # push (as they are common). Here is a very simple example:
        #
        # 1) repo A push changeset X as draft to repo B
        # 2) repo B make changeset X public
        # 3) repo B push to repo A. X is not pushed but the data that
        #    X as now public should
        #
        # The server can't handle it on it's own as it has no idea of
        # client phase data.
        keys[b'publishing'] = b'True'
    return keys


def pushphase(repo, nhex, oldphasestr, newphasestr):
    # type: (localrepo.localrepository, bytes, bytes, bytes) -> bool
    """List phases root for serialization over pushkey"""
    repo = repo.unfiltered()
    with repo.lock():
        currentphase = repo[nhex].phase()
        newphase = abs(int(newphasestr))  # let's avoid negative index surprise
        oldphase = abs(int(oldphasestr))  # let's avoid negative index surprise
        if currentphase == oldphase and newphase < oldphase:
            with repo.transaction(b'pushkey-phase') as tr:
                advanceboundary(repo, tr, newphase, [bin(nhex)])
            return True
        elif currentphase == newphase:
            # raced, but got correct result
            return True
        else:
            return False


def subsetphaseheads(repo, subset):
    """Finds the phase heads for a subset of a history

    Returns a list indexed by phase number where each item is a list of phase
    head nodes.
    """
    cl = repo.changelog

    headsbyphase = {i: [] for i in allphases}
    # No need to keep track of secret phase; any heads in the subset that
    # are not mentioned are implicitly secret.
    for phase in allphases[:secret]:
        revset = b"heads(%%ln & %s())" % phasenames[phase]
        headsbyphase[phase] = [cl.node(r) for r in repo.revs(revset, subset)]
    return headsbyphase


def updatephases(repo, trgetter, headsbyphase):
    """Updates the repo with the given phase heads"""
    # Now advance phase boundaries of all phases
    #
    # run the update (and fetch transaction) only if there are actually things
    # to update. This avoid creating empty transaction during no-op operation.

    for phase in allphases:
        revset = b'%ln - _phase(%s)'
        heads = [c.node() for c in repo.set(revset, headsbyphase[phase], phase)]
        if heads:
            advanceboundary(repo, trgetter(), phase, heads)


def analyzeremotephases(repo, subset, roots):
    """Compute phases heads and root in a subset of node from root dict

    * subset is heads of the subset
    * roots is {<nodeid> => phase} mapping. key and value are string.

    Accept unknown element input
    """
    repo = repo.unfiltered()
    # build list from dictionary
    draftroots = []
    has_node = repo.changelog.index.has_node  # to filter unknown nodes
    for nhex, phase in roots.items():
        if nhex == b'publishing':  # ignore data related to publish option
            continue
        node = bin(nhex)
        phase = int(phase)
        if phase == public:
            if node != repo.nullid:
                repo.ui.warn(
                    _(
                        b'ignoring inconsistent public root'
                        b' from remote: %s\n'
                    )
                    % nhex
                )
        elif phase == draft:
            if has_node(node):
                draftroots.append(node)
        else:
            repo.ui.warn(
                _(b'ignoring unexpected root from remote: %i %s\n')
                % (phase, nhex)
            )
    # compute heads
    publicheads = newheads(repo, subset, draftroots)
    return publicheads, draftroots


class remotephasessummary:
    """summarize phase information on the remote side

    :publishing: True is the remote is publishing
    :publicheads: list of remote public phase heads (nodes)
    :draftheads: list of remote draft phase heads (nodes)
    :draftroots: list of remote draft phase root (nodes)
    """

    def __init__(self, repo, remotesubset, remoteroots):
        unfi = repo.unfiltered()
        self._allremoteroots = remoteroots

        self.publishing = remoteroots.get(b'publishing', False)

        ana = analyzeremotephases(repo, remotesubset, remoteroots)
        self.publicheads, self.draftroots = ana
        # Get the list of all "heads" revs draft on remote
        dheads = unfi.set(b'heads(%ln::%ln)', self.draftroots, remotesubset)
        self.draftheads = [c.node() for c in dheads]


def newheads(repo, heads, roots):
    """compute new head of a subset minus another

    * `heads`: define the first subset
    * `roots`: define the second we subtract from the first"""
    # prevent an import cycle
    # phases > dagop > patch > copies > scmutil > obsolete > obsutil > phases
    from . import dagop

    repo = repo.unfiltered()
    cl = repo.changelog
    rev = cl.index.get_rev
    if not roots:
        return heads
    if not heads or heads == [repo.nullid]:
        return []
    # The logic operated on revisions, convert arguments early for convenience
    new_heads = {rev(n) for n in heads if n != repo.nullid}
    roots = [rev(n) for n in roots]
    # compute the area we need to remove
    affected_zone = repo.revs(b"(%ld::%ld)", roots, new_heads)
    # heads in the area are no longer heads
    new_heads.difference_update(affected_zone)
    # revisions in the area have children outside of it,
    # They might be new heads
    candidates = repo.revs(
        b"parents(%ld + (%ld and merge())) and not null", roots, affected_zone
    )
    candidates -= affected_zone
    if new_heads or candidates:
        # remove candidate that are ancestors of other heads
        new_heads.update(candidates)
        prunestart = repo.revs(b"parents(%ld) and not null", new_heads)
        pruned = dagop.reachableroots(repo, candidates, prunestart)
        new_heads.difference_update(pruned)

    return pycompat.maplist(cl.node, sorted(new_heads))


def newcommitphase(ui):
    # type: (uimod.ui) -> int
    """helper to get the target phase of new commit

    Handle all possible values for the phases.new-commit options.

    """
    v = ui.config(b'phases', b'new-commit')
    try:
        return phasenumber2[v]
    except KeyError:
        raise error.ConfigError(
            _(b"phases.new-commit: not a valid phase name ('%s')") % v
        )


def hassecret(repo):
    # type: (localrepo.localrepository) -> bool
    """utility function that check if a repo have any secret changeset."""
    return bool(repo._phasecache.phaseroots[secret])


def preparehookargs(node, old, new):
    # type: (bytes, Optional[int], Optional[int]) -> Dict[bytes, bytes]
    if old is None:
        old = b''
    else:
        old = phasenames[old]
    return {b'node': node, b'oldphase': old, b'phase': phasenames[new]}
        usr/lib/python3/dist-packages/mercurial/policy.py                                                   0000644 0000000 0000000 00000011154 14355257011 020607  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # policy.py - module policy logic for Mercurial.
#
# Copyright 2015 Gregory Szorc <gregory.szorc@gmail.com>
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


import os
import sys

from .pycompat import getattr

# Rules for how modules can be loaded. Values are:
#
#    c - require C extensions
#    rust+c - require Rust and C extensions
#    rust+c-allow - allow Rust and C extensions with fallback to pure Python
#                   for each
#    allow - allow pure Python implementation when C loading fails
#    cffi - required cffi versions (implemented within pure module)
#    cffi-allow - allow pure Python implementation if cffi version is missing
#    py - only load pure Python modules
#
# By default, fall back to the pure modules so the in-place build can
# run without recompiling the C extensions. This will be overridden by
# __modulepolicy__ generated by setup.py.
policy = b'allow'
_packageprefs = {
    # policy: (versioned package, pure package)
    b'c': ('cext', None),
    b'allow': ('cext', 'pure'),
    b'cffi': ('cffi', None),
    b'cffi-allow': ('cffi', 'pure'),
    b'py': (None, 'pure'),
    # For now, rust policies impact importrust only
    b'rust+c': ('cext', None),
    b'rust+c-allow': ('cext', 'pure'),
}

try:
    from . import __modulepolicy__

    policy = __modulepolicy__.modulepolicy
except ImportError:
    pass

# PyPy doesn't load C extensions.
#
# The canonical way to do this is to test platform.python_implementation().
# But we don't import platform and don't bloat for it here.
if '__pypy__' in sys.builtin_module_names:
    policy = b'cffi'

# Environment variable can always force settings.
if 'HGMODULEPOLICY' in os.environ:
    policy = os.environ['HGMODULEPOLICY'].encode('utf-8')


def _importfrom(pkgname, modname):
    # from .<pkgname> import <modname> (where . is looked through this module)
    fakelocals = {}
    pkg = __import__(pkgname, globals(), fakelocals, [modname], level=1)
    try:
        fakelocals[modname] = mod = getattr(pkg, modname)
    except AttributeError:
        raise ImportError('cannot import name %s' % modname)
    # force import; fakelocals[modname] may be replaced with the real module
    getattr(mod, '__doc__', None)
    return fakelocals[modname]


# keep in sync with "version" in C modules
_cextversions = {
    ('cext', 'base85'): 1,
    ('cext', 'bdiff'): 3,
    ('cext', 'mpatch'): 1,
    ('cext', 'osutil'): 4,
    ('cext', 'parsers'): 20,
}

# map import request to other package or module
_modredirects = {
    ('cext', 'charencode'): ('cext', 'parsers'),
    ('cffi', 'base85'): ('pure', 'base85'),
    ('cffi', 'charencode'): ('pure', 'charencode'),
    ('cffi', 'parsers'): ('pure', 'parsers'),
}


def _checkmod(pkgname, modname, mod):
    expected = _cextversions.get((pkgname, modname))
    actual = getattr(mod, 'version', None)
    if actual != expected:
        raise ImportError(
            'cannot import module %s.%s '
            '(expected version: %d, actual: %r)'
            % (pkgname, modname, expected, actual)
        )


def importmod(modname):
    """Import module according to policy and check API version"""
    try:
        verpkg, purepkg = _packageprefs[policy]
    except KeyError:
        raise ImportError('invalid HGMODULEPOLICY %r' % policy)
    assert verpkg or purepkg
    if verpkg:
        pn, mn = _modredirects.get((verpkg, modname), (verpkg, modname))
        try:
            mod = _importfrom(pn, mn)
            if pn == verpkg:
                _checkmod(pn, mn, mod)
            return mod
        except ImportError:
            if not purepkg:
                raise
    pn, mn = _modredirects.get((purepkg, modname), (purepkg, modname))
    return _importfrom(pn, mn)


def _isrustpermissive():
    """Assuming the policy is a Rust one, tell if it's permissive."""
    return policy.endswith(b'-allow')


def importrust(modname, member=None, default=None):
    """Import Rust module according to policy and availability.

    If policy isn't a Rust one, this returns `default`.

    If either the module or its member is not available, this returns `default`
    if policy is permissive and raises `ImportError` if not.
    """
    if not policy.startswith(b'rust'):
        return default

    try:
        mod = _importfrom('rustext', modname)
    except ImportError:
        if _isrustpermissive():
            return default
        raise
    if member is None:
        return mod

    try:
        return getattr(mod, member)
    except AttributeError:
        if _isrustpermissive():
            return default
        raise ImportError("Cannot import name %s" % member)
                                                                                                                                                                                                                                                                                                                                                                                                                    usr/lib/python3/dist-packages/mercurial/posix.py                                                    0000644 0000000 0000000 00000053455 14355257011 020464  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # posix.py - Posix utility function implementations for Mercurial
#
#  Copyright 2005-2009 Olivia Mackall <olivia@selenic.com> and others
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


import errno
import fcntl
import getpass
import grp
import os
import pwd
import re
import select
import stat
import sys
import tempfile
import unicodedata

from .i18n import _
from .pycompat import (
    getattr,
    open,
)
from . import (
    encoding,
    error,
    policy,
    pycompat,
)

osutil = policy.importmod('osutil')

normpath = os.path.normpath
samestat = os.path.samestat
abspath = os.path.abspath  # re-exports

try:
    oslink = os.link
except AttributeError:
    # Some platforms build Python without os.link on systems that are
    # vaguely unix-like but don't have hardlink support. For those
    # poor souls, just say we tried and that it failed so we fall back
    # to copies.
    def oslink(src, dst):
        raise OSError(
            errno.EINVAL, b'hardlinks not supported: %s to %s' % (src, dst)
        )


readlink = os.readlink
unlink = os.unlink
rename = os.rename
removedirs = os.removedirs
expandglobs = False

umask = os.umask(0)
os.umask(umask)

posixfile = open


def split(p):
    """Same as posixpath.split, but faster

    >>> import posixpath
    >>> for f in [b'/absolute/path/to/file',
    ...           b'relative/path/to/file',
    ...           b'file_alone',
    ...           b'path/to/directory/',
    ...           b'/multiple/path//separators',
    ...           b'/file_at_root',
    ...           b'///multiple_leading_separators_at_root',
    ...           b'']:
    ...     assert split(f) == posixpath.split(f), f
    """
    ht = p.rsplit(b'/', 1)
    if len(ht) == 1:
        return b'', p
    nh = ht[0].rstrip(b'/')
    if nh:
        return nh, ht[1]
    return ht[0] + b'/', ht[1]


def openhardlinks():
    '''return true if it is safe to hold open file handles to hardlinks'''
    return True


def nlinks(name):
    '''return number of hardlinks for the given file'''
    return os.lstat(name).st_nlink


def parsepatchoutput(output_line):
    """parses the output produced by patch and returns the filename"""
    pf = output_line[14:]
    if pycompat.sysplatform == b'OpenVMS':
        if pf[0] == b'`':
            pf = pf[1:-1]  # Remove the quotes
    else:
        if pf.startswith(b"'") and pf.endswith(b"'") and b" " in pf:
            pf = pf[1:-1]  # Remove the quotes
    return pf


def sshargs(sshcmd, host, user, port):
    '''Build argument list for ssh'''
    args = user and (b"%s@%s" % (user, host)) or host
    if b'-' in args[:1]:
        raise error.Abort(
            _(b'illegal ssh hostname or username starting with -: %s') % args
        )
    args = shellquote(args)
    if port:
        args = b'-p %s %s' % (shellquote(port), args)
    return args


def isexec(f):
    """check whether a file is executable"""
    return os.lstat(f).st_mode & 0o100 != 0


def setflags(f, l, x):
    st = os.lstat(f)
    s = st.st_mode
    if l:
        if not stat.S_ISLNK(s):
            # switch file to link
            with open(f, b'rb') as fp:
                data = fp.read()
            unlink(f)
            try:
                os.symlink(data, f)
            except OSError:
                # failed to make a link, rewrite file
                with open(f, b"wb") as fp:
                    fp.write(data)

        # no chmod needed at this point
        return
    if stat.S_ISLNK(s):
        # switch link to file
        data = os.readlink(f)
        unlink(f)
        with open(f, b"wb") as fp:
            fp.write(data)
        s = 0o666 & ~umask  # avoid restatting for chmod

    sx = s & 0o100
    if st.st_nlink > 1 and bool(x) != bool(sx):
        # the file is a hardlink, break it
        with open(f, b"rb") as fp:
            data = fp.read()
        unlink(f)
        with open(f, b"wb") as fp:
            fp.write(data)

    if x and not sx:
        # Turn on +x for every +r bit when making a file executable
        # and obey umask.
        os.chmod(f, s | (s & 0o444) >> 2 & ~umask)
    elif not x and sx:
        # Turn off all +x bits
        os.chmod(f, s & 0o666)


def copymode(src, dst, mode=None, enforcewritable=False):
    """Copy the file mode from the file at path src to dst.
    If src doesn't exist, we're using mode instead. If mode is None, we're
    using umask."""
    try:
        st_mode = os.lstat(src).st_mode & 0o777
    except FileNotFoundError:
        st_mode = mode
        if st_mode is None:
            st_mode = ~umask
        st_mode &= 0o666

    new_mode = st_mode

    if enforcewritable:
        new_mode |= stat.S_IWUSR

    os.chmod(dst, new_mode)


def checkexec(path):
    """
    Check whether the given path is on a filesystem with UNIX-like exec flags

    Requires a directory (like /foo/.hg)
    """

    # VFAT on some Linux versions can flip mode but it doesn't persist
    # a FS remount. Frequently we can detect it if files are created
    # with exec bit on.

    try:
        EXECFLAGS = stat.S_IXUSR | stat.S_IXGRP | stat.S_IXOTH
        basedir = os.path.join(path, b'.hg')
        cachedir = os.path.join(basedir, b'wcache')
        storedir = os.path.join(basedir, b'store')
        if not os.path.exists(cachedir):
            try:
                # we want to create the 'cache' directory, not the '.hg' one.
                # Automatically creating '.hg' directory could silently spawn
                # invalid Mercurial repositories. That seems like a bad idea.
                os.mkdir(cachedir)
                if os.path.exists(storedir):
                    copymode(storedir, cachedir)
                else:
                    copymode(basedir, cachedir)
            except (IOError, OSError):
                # we other fallback logic triggers
                pass
        if os.path.isdir(cachedir):
            checkisexec = os.path.join(cachedir, b'checkisexec')
            checknoexec = os.path.join(cachedir, b'checknoexec')

            try:
                m = os.stat(checkisexec).st_mode
            except FileNotFoundError:
                # checkisexec does not exist - fall through ...
                pass
            else:
                # checkisexec exists, check if it actually is exec
                if m & EXECFLAGS != 0:
                    # ensure checkisexec exists, check it isn't exec
                    try:
                        m = os.stat(checknoexec).st_mode
                    except FileNotFoundError:
                        open(checknoexec, b'w').close()  # might fail
                        m = os.stat(checknoexec).st_mode
                    if m & EXECFLAGS == 0:
                        # check-exec is exec and check-no-exec is not exec
