            if tok_type == INDENT:
                indents.append(token)
                continue
            elif tok_type == DEDENT:
                indents.pop()
                self.prev_row, self.prev_col = end
                continue
            elif tok_type in (NEWLINE, NL):
                startline = True
            elif startline and indents:
                indent = indents[-1]
                if start[1] >= len(indent):
                    self.tokens.append(indent)
                    self.prev_col = len(indent)
                startline = False
            self.add_whitespace(start)
            self.tokens.append(token)
            self.prev_row, self.prev_col = end
            if tok_type in (NEWLINE, NL):
                self.prev_row += 1
                self.prev_col = 0
        return "".join(self.tokens)

    def compat(self, token, iterable):
        indents = []
        toks_append = self.tokens.append
        startline = token[0] in (NEWLINE, NL)
        prevstring = False

        for tok in _itertools.chain([token], iterable):
            toknum, tokval = tok[:2]
            if toknum == ENCODING:
                self.encoding = tokval
                continue

            if toknum in (NAME, NUMBER):
                tokval += ' '

            # Insert a space between two consecutive strings
            if toknum == STRING:
                if prevstring:
                    tokval = ' ' + tokval
                prevstring = True
            else:
                prevstring = False

            if toknum == INDENT:
                indents.append(tokval)
                continue
            elif toknum == DEDENT:
                indents.pop()
                continue
            elif toknum in (NEWLINE, NL):
                startline = True
            elif startline and indents:
                toks_append(indents[-1])
                startline = False
            toks_append(tokval)


def untokenize(iterable):
    """Transform tokens back into Python source code.
    It returns a bytes object, encoded using the ENCODING
    token, which is the first token sequence output by tokenize.

    Each element returned by the iterable must be a token sequence
    with at least two elements, a token number and token value.  If
    only two tokens are passed, the resulting output is poor.

    Round-trip invariant for full input:
        Untokenized source will match input source exactly

    Round-trip invariant for limited input:
        # Output bytes will tokenize back to the input
        t1 = [tok[:2] for tok in tokenize(f.readline)]
        newcode = untokenize(t1)
        readline = BytesIO(newcode).readline
        t2 = [tok[:2] for tok in tokenize(readline)]
        assert t1 == t2
    """
    ut = Untokenizer()
    out = ut.untokenize(iterable)
    if ut.encoding is not None:
        out = out.encode(ut.encoding)
    return out


def _get_normal_name(orig_enc):
    """Imitates get_normal_name in tokenizer.c."""
    # Only care about the first 12 characters.
    enc = orig_enc[:12].lower().replace("_", "-")
    if enc == "utf-8" or enc.startswith("utf-8-"):
        return "utf-8"
    if enc in ("latin-1", "iso-8859-1", "iso-latin-1") or \
       enc.startswith(("latin-1-", "iso-8859-1-", "iso-latin-1-")):
        return "iso-8859-1"
    return orig_enc

def detect_encoding(readline):
    """
    The detect_encoding() function is used to detect the encoding that should
    be used to decode a Python source file.  It requires one argument, readline,
    in the same way as the tokenize() generator.

    It will call readline a maximum of twice, and return the encoding used
    (as a string) and a list of any lines (left as bytes) it has read in.

    It detects the encoding from the presence of a utf-8 bom or an encoding
    cookie as specified in pep-0263.  If both a bom and a cookie are present,
    but disagree, a SyntaxError will be raised.  If the encoding cookie is an
    invalid charset, raise a SyntaxError.  Note that if a utf-8 bom is found,
    'utf-8-sig' is returned.

    If no encoding is specified, then the default of 'utf-8' will be returned.
    """
    try:
        filename = readline.__self__.name
    except AttributeError:
        filename = None
    bom_found = False
    encoding = None
    default = 'utf-8'
    def read_or_stop():
        try:
            return readline()
        except StopIteration:
            return b''

    def find_cookie(line):
        try:
            # Decode as UTF-8. Either the line is an encoding declaration,
            # in which case it should be pure ASCII, or it must be UTF-8
            # per default encoding.
            line_string = line.decode('utf-8')
        except UnicodeDecodeError:
            msg = "invalid or missing encoding declaration"
            if filename is not None:
                msg = '{} for {!r}'.format(msg, filename)
            raise SyntaxError(msg)

        match = cookie_re.match(line_string)
        if not match:
            return None
        encoding = _get_normal_name(match.group(1))
        try:
            codec = lookup(encoding)
        except LookupError:
            # This behaviour mimics the Python interpreter
            if filename is None:
                msg = "unknown encoding: " + encoding
            else:
                msg = "unknown encoding for {!r}: {}".format(filename,
                        encoding)
            raise SyntaxError(msg)

        if bom_found:
            if encoding != 'utf-8':
                # This behaviour mimics the Python interpreter
                if filename is None:
                    msg = 'encoding problem: utf-8'
                else:
                    msg = 'encoding problem for {!r}: utf-8'.format(filename)
                raise SyntaxError(msg)
            encoding += '-sig'
        return encoding

    first = read_or_stop()
    if first.startswith(BOM_UTF8):
        bom_found = True
        first = first[3:]
        default = 'utf-8-sig'
    if not first:
        return default, []

    encoding = find_cookie(first)
    if encoding:
        return encoding, [first]
    if not blank_re.match(first):
        return default, [first]

    second = read_or_stop()
    if not second:
        return default, [first]

    encoding = find_cookie(second)
    if encoding:
        return encoding, [first, second]

    return default, [first, second]


def open(filename):
    """Open a file in read only mode using the encoding detected by
    detect_encoding().
    """
    buffer = _builtin_open(filename, 'rb')
    try:
        encoding, lines = detect_encoding(buffer.readline)
        buffer.seek(0)
        text = TextIOWrapper(buffer, encoding, line_buffering=True)
        text.mode = 'r'
        return text
    except:
        buffer.close()
        raise


def tokenize(readline):
    """
    The tokenize() generator requires one argument, readline, which
    must be a callable object which provides the same interface as the
    readline() method of built-in file objects.  Each call to the function
    should return one line of input as bytes.  Alternatively, readline
    can be a callable function terminating with StopIteration:
        readline = open(myfile, 'rb').__next__  # Example of alternate readline

    The generator produces 5-tuples with these members: the token type; the
    token string; a 2-tuple (srow, scol) of ints specifying the row and
    column where the token begins in the source; a 2-tuple (erow, ecol) of
    ints specifying the row and column where the token ends in the source;
    and the line on which the token was found.  The line passed is the
    physical line.

    The first token sequence will always be an ENCODING token
    which tells you which encoding was used to decode the bytes stream.
    """
    encoding, consumed = detect_encoding(readline)
    empty = _itertools.repeat(b"")
    rl_gen = _itertools.chain(consumed, iter(readline, b""), empty)
    return _tokenize(rl_gen.__next__, encoding)


def _tokenize(readline, encoding):
    lnum = parenlev = continued = 0
    numchars = '0123456789'
    contstr, needcont = '', 0
    contline = None
    indents = [0]

    if encoding is not None:
        if encoding == "utf-8-sig":
            # BOM will already have been stripped.
            encoding = "utf-8"
        yield TokenInfo(ENCODING, encoding, (0, 0), (0, 0), '')
    last_line = b''
    line = b''
    while True:                                # loop over lines in stream
        try:
            # We capture the value of the line variable here because
            # readline uses the empty string '' to signal end of input,
            # hence `line` itself will always be overwritten at the end
            # of this loop.
            last_line = line
            line = readline()
        except StopIteration:
            line = b''

        if encoding is not None:
            line = line.decode(encoding)
        lnum += 1
        pos, max = 0, len(line)

        if contstr:                            # continued string
            if not line:
                raise TokenError("EOF in multi-line string", strstart)
            endmatch = endprog.match(line)
            if endmatch:
                pos = end = endmatch.end(0)
                yield TokenInfo(STRING, contstr + line[:end],
                       strstart, (lnum, end), contline + line)
                contstr, needcont = '', 0
                contline = None
            elif needcont and line[-2:] != '\\\n' and line[-3:] != '\\\r\n':
                yield TokenInfo(ERRORTOKEN, contstr + line,
                           strstart, (lnum, len(line)), contline)
                contstr = ''
                contline = None
                continue
            else:
                contstr = contstr + line
                contline = contline + line
                continue

        elif parenlev == 0 and not continued:  # new statement
            if not line: break
            column = 0
            while pos < max:                   # measure leading whitespace
                if line[pos] == ' ':
                    column += 1
                elif line[pos] == '\t':
                    column = (column//tabsize + 1)*tabsize
                elif line[pos] == '\f':
                    column = 0
                else:
                    break
                pos += 1
            if pos == max:
                break

            if line[pos] in '#\r\n':           # skip comments or blank lines
                if line[pos] == '#':
                    comment_token = line[pos:].rstrip('\r\n')
                    yield TokenInfo(COMMENT, comment_token,
                           (lnum, pos), (lnum, pos + len(comment_token)), line)
                    pos += len(comment_token)

                yield TokenInfo(NL, line[pos:],
                           (lnum, pos), (lnum, len(line)), line)
                continue

            if column > indents[-1]:           # count indents or dedents
                indents.append(column)
                yield TokenInfo(INDENT, line[:pos], (lnum, 0), (lnum, pos), line)
            while column < indents[-1]:
                if column not in indents:
                    raise IndentationError(
                        "unindent does not match any outer indentation level",
                        ("<tokenize>", lnum, pos, line))
                indents = indents[:-1]

                yield TokenInfo(DEDENT, '', (lnum, pos), (lnum, pos), line)

        else:                                  # continued statement
            if not line:
                raise TokenError("EOF in multi-line statement", (lnum, 0))
            continued = 0

        while pos < max:
            pseudomatch = _compile(PseudoToken).match(line, pos)
            if pseudomatch:                                # scan for tokens
                start, end = pseudomatch.span(1)
                spos, epos, pos = (lnum, start), (lnum, end), end
                if start == end:
                    continue
                token, initial = line[start:end], line[start]

                if (initial in numchars or                 # ordinary number
                    (initial == '.' and token != '.' and token != '...')):
                    yield TokenInfo(NUMBER, token, spos, epos, line)
                elif initial in '\r\n':
                    if parenlev > 0:
                        yield TokenInfo(NL, token, spos, epos, line)
                    else:
                        yield TokenInfo(NEWLINE, token, spos, epos, line)

                elif initial == '#':
                    assert not token.endswith("\n")
                    yield TokenInfo(COMMENT, token, spos, epos, line)

                elif token in triple_quoted:
                    endprog = _compile(endpats[token])
                    endmatch = endprog.match(line, pos)
                    if endmatch:                           # all on one line
                        pos = endmatch.end(0)
                        token = line[start:pos]
                        yield TokenInfo(STRING, token, spos, (lnum, pos), line)
                    else:
                        strstart = (lnum, start)           # multiple lines
                        contstr = line[start:]
                        contline = line
                        break

                # Check up to the first 3 chars of the token to see if
                #  they're in the single_quoted set. If so, they start
                #  a string.
                # We're using the first 3, because we're looking for
                #  "rb'" (for example) at the start of the token. If
                #  we switch to longer prefixes, this needs to be
                #  adjusted.
                # Note that initial == token[:1].
                # Also note that single quote checking must come after
                #  triple quote checking (above).
                elif (initial in single_quoted or
                      token[:2] in single_quoted or
                      token[:3] in single_quoted):
                    if token[-1] == '\n':                  # continued string
                        strstart = (lnum, start)
                        # Again, using the first 3 chars of the
                        #  token. This is looking for the matching end
                        #  regex for the correct type of quote
                        #  character. So it's really looking for
                        #  endpats["'"] or endpats['"'], by trying to
                        #  skip string prefix characters, if any.
                        endprog = _compile(endpats.get(initial) or
                                           endpats.get(token[1]) or
                                           endpats.get(token[2]))
                        contstr, needcont = line[start:], 1
                        contline = line
                        break
                    else:                                  # ordinary string
                        yield TokenInfo(STRING, token, spos, epos, line)

                elif initial.isidentifier():               # ordinary name
                    yield TokenInfo(NAME, token, spos, epos, line)
                elif initial == '\\':                      # continued stmt
                    continued = 1
                else:
                    if initial in '([{':
                        parenlev += 1
                    elif initial in ')]}':
                        parenlev -= 1
                    yield TokenInfo(OP, token, spos, epos, line)
            else:
                yield TokenInfo(ERRORTOKEN, line[pos],
                           (lnum, pos), (lnum, pos+1), line)
                pos += 1

    # Add an implicit NEWLINE if the input doesn't end in one
    if last_line and last_line[-1] not in '\r\n' and not last_line.strip().startswith("#"):
        yield TokenInfo(NEWLINE, '', (lnum - 1, len(last_line)), (lnum - 1, len(last_line) + 1), '')
    for indent in indents[1:]:                 # pop remaining indent levels
        yield TokenInfo(DEDENT, '', (lnum, 0), (lnum, 0), '')
    yield TokenInfo(ENDMARKER, '', (lnum, 0), (lnum, 0), '')


def generate_tokens(readline):
    """Tokenize a source reading Python code as unicode strings.

    This has the same API as tokenize(), except that it expects the *readline*
    callable to return str objects instead of bytes.
    """
    return _tokenize(readline, None)

def main():
    import argparse

    # Helper error handling routines
    def perror(message):
        sys.stderr.write(message)
        sys.stderr.write('\n')

    def error(message, filename=None, location=None):
        if location:
            args = (filename,) + location + (message,)
            perror("%s:%d:%d: error: %s" % args)
        elif filename:
            perror("%s: error: %s" % (filename, message))
        else:
            perror("error: %s" % message)
        sys.exit(1)

    # Parse the arguments and options
    parser = argparse.ArgumentParser(prog='python -m tokenize')
    parser.add_argument(dest='filename', nargs='?',
                        metavar='filename.py',
                        help='the file to tokenize; defaults to stdin')
    parser.add_argument('-e', '--exact', dest='exact', action='store_true',
                        help='display token names using the exact type')
    args = parser.parse_args()

    try:
        # Tokenize the input
        if args.filename:
            filename = args.filename
            with _builtin_open(filename, 'rb') as f:
                tokens = list(tokenize(f.readline))
        else:
            filename = "<stdin>"
            tokens = _tokenize(sys.stdin.readline, None)

        # Output the tokenization
        for token in tokens:
            token_type = token.type
            if args.exact:
                token_type = token.exact_type
            token_range = "%d,%d-%d,%d:" % (token.start + token.end)
            print("%-20s%-15s%-15r" %
                  (token_range, tok_name[token_type], token.string))
    except IndentationError as err:
        line, column = err.args[1][1:3]
        error(err.args[0], filename, (line, column))
    except TokenError as err:
        line, column = err.args[1]
        error(err.args[0], filename, (line, column))
    except SyntaxError as err:
        error(err, filename)
    except OSError as err:
        error(err)
    except KeyboardInterrupt:
        print("interrupted\n")
    except Exception as err:
        perror("unexpected error: %s" % err)
        raise

def _generate_tokens_from_c_tokenizer(source):
    """Tokenize a source reading Python code as unicode strings using the internal C tokenizer"""
    import _tokenize as c_tokenizer
    for info in c_tokenizer.TokenizerIter(source):
        tok, type, lineno, end_lineno, col_off, end_col_off, line = info
        yield TokenInfo(type, tok, (lineno, col_off), (end_lineno, end_col_off), line)


if __name__ == "__main__":
    main()
                                                                                                                                                                                                                                                                                                usr/lib/python3.11/tomllib/                                                                         0000755 0000000 0000000 00000000000 14714551121 014112  5                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        usr/lib/python3.11/tomllib/__init__.py                                                              0000644 0000000 0000000 00000000464 14671176116 016240  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # SPDX-License-Identifier: MIT
# SPDX-FileCopyrightText: 2021 Taneli Hukkinen
# Licensed to PSF under a Contributor Agreement.

__all__ = ("loads", "load", "TOMLDecodeError")

from ._parser import TOMLDecodeError, load, loads

# Pretend this exception was created here.
TOMLDecodeError.__module__ = __name__
                                                                                                                                                                                                            usr/lib/python3.11/tomllib/__pycache__/                                                             0000755 0000000 0000000 00000000000 14714551121 016322  5                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        usr/lib/python3.11/tomllib/__pycache__/__init__.cpython-311.pyc                                     0000644 0000000 0000000 00000000517 14714551121 022566  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        §
    Nüäf4  ã                   ó,   — d Z ddlmZmZmZ ee_        dS ))ÚloadsÚloadÚTOMLDecodeErroré   )r   r   r   N)Ú__all__Ú_parserr   r   r   Ú__name__Ú
__module__© ó    ú'/usr/lib/python3.11/tomllib/__init__.pyú<module>r      s:   ğğ
 /€à 1Ğ 1Ğ 1Ğ 1Ğ 1Ğ 1Ğ 1Ğ 1Ğ 1Ğ 1ğ &€Ô Ğ Ğ r                                                                                                                                                                                    usr/lib/python3.11/tomllib/__pycache__/_parser.cpython-311.pyc                                      0000644 0000000 0000000 00000074121 14714551121 022464  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        §
    NüäfgX  ã            
      ó4  — d dl mZ d dlmZ d dlZd dlmZ d dlmZm	Z	m
Z
 ddlmZmZmZmZmZmZ ddlmZmZmZ  ed	„  ed
¦  «        D ¦   «         ¦  «         e ed¦  «        ¦  «        z  Ze ed¦  «        z
  Ze ed¦  «        z
  ZeZeZeZ ed¦  «        Ze ed¦  «        z  Z  eej!        ej"        z   dz   ¦  «        Z#e# ed¦  «        z  Z$ eej%        ¦  «        Z& eddddddddœ¦  «        Z' G d„ de(¦  «        Z)e*dœd]d!„Z+e*dœd^d$„Z, G d%„ d&¦  «        Z- G d'„ d(¦  «        Z. G d)„ d*e
¦  «        Z/d_d0„Z0d`d6„Z1dad7„Z2dad8„Z3dbd;„Z4dbd<„Z5dcd?„Z6dddA„Z7dedB„Z8dfdD„Z9dfdE„Z:dgdG„Z;dhdI„Z<dJdKœdidM„Z=dfdN„Z>djdQ„Z?dfdR„Z@dkdT„ZAdidU„ZBdldW„ZCdmdY„ZDdnd[„ZEdod\„ZFdS )pé    )Úannotations)ÚIterableN)ÚMappingProxyType)ÚAnyÚBinaryIOÚ
NamedTupleé   )ÚRE_DATETIMEÚRE_LOCALTIMEÚ	RE_NUMBERÚmatch_to_datetimeÚmatch_to_localtimeÚmatch_to_number)ÚKeyÚ
ParseFloatÚPosc              #  ó4   K  — | ]}t          |¦  «        V — Œd S ©N)Úchr)Ú.0Úis     ú&/usr/lib/python3.11/tomllib/_parser.pyú	<genexpr>r      s(   è è € Ğ1Ğ1 !•s˜1‘v”vĞ1Ğ1Ğ1Ğ1Ğ1Ğ1ó    é    é   ú	z	
z 	ú
z-_z"'úúúú"ú\)z\bz\tz\nz\fz\rz\"z\\c                  ó   — e Zd ZdZdS )ÚTOMLDecodeErrorz0An error raised if a document is not valid TOML.N)Ú__name__Ú
__module__Ú__qualname__Ú__doc__© r   r   r%   r%   5   s   € € € € € Ø:Ğ:Ğ:Ğ:r   r%   ©Úparse_floatÚfpr   r,   r   Úreturnúdict[str, Any]c              ó´   — |                       ¦   «         }	 |                     ¦   «         }n# t          $ r t          d¦  «        d‚w xY wt	          ||¬¦  «        S )z%Parse TOML from a binary file object.zEFile must be opened in binary mode, e.g. use `open('foo.toml', 'rb')`Nr+   )ÚreadÚdecodeÚAttributeErrorÚ	TypeErrorÚloads)r-   r,   ÚbÚss       r   Úloadr8   9   sk   € à
Š‰	Œ	€AğØHŠH‰JŒJˆˆøİğ ğ ğ İØSñ
ô 
àğ	ğøøøõ  Ğ,Ñ,Ô,Ğ,s	   –+ «Ar7   Ústrc              ód  — |                       dd¦  «        }d}t          t          ¦   «         t          ¦   «         ¦  «        }d}t	          |¦  «        }	 t          ||t          ¦  «        }	 ||         }n# t          $ r Y n&w xY w|dk    r|dz  }Œ>|t          v r*t          |||||¦  «        }t          ||t          ¦  «        }n›|dk    r~	 ||dz            }n# t          $ r d}Y nw xY w|j
                             ¦   «          |dk    rt          |||¦  «        \  }}nt          |||¦  «        \  }}t          ||t          ¦  «        }n|d	k    rt          ||d
¦  «        ‚t          ||¦  «        }	 ||         }n# t          $ r Y n"w xY w|dk    rt          ||d¦  «        ‚|dz  }ŒS|j        j        S )zParse TOML from a string.z
r   r   r*   Tr	   ú[Nú#zInvalid statementz5Expected newline or end of document after a statement)ÚreplaceÚOutputÚ
NestedDictÚFlagsÚmake_safe_parse_floatÚ
skip_charsÚTOML_WSÚ
IndexErrorÚKEY_INITIAL_CHARSÚkey_value_ruleÚflagsÚfinalize_pendingÚcreate_list_ruleÚcreate_dict_ruleÚsuffixed_errÚskip_commentÚdataÚdict)r7   r,   ÚsrcÚposÚoutÚheaderÚcharÚsecond_chars           r   r5   r5   E   s  € ğ
 )Š)F˜DÑ
!Ô
!€CØ
€Cİ
•‘”u™wœwÑ
'Ô
'€CØ€Fİ'¨Ñ4Ô4€Kğ0å˜˜c¥7Ñ+Ô+ˆğ	Øs”8ˆDˆDøİğ 	ğ 	ğ 	Ø‰Eğ	øøøà4Š<ˆ<Ø1‰HˆCØØÕ$Ğ$Ğ$İ   c¨3°¸ÑDÔDˆCİ˜S #¥wÑ/Ô/ˆCˆCØSŠ[ˆ[ğ#Ø*-¨c°A©g¬,øİğ #ğ #ğ #Ø"ğ#øøøàŒI×&Ò&Ñ(Ô(Ğ(Ø˜cÒ!Ğ!İ.¨s°C¸Ñ=Ô=‘VVå.¨s°C¸Ñ=Ô=‘Vİ˜S #¥wÑ/Ô/ˆCˆCØSŠ[ˆ[İ˜s CĞ)<Ñ=Ô=Ğ=õ ˜3 Ñ$Ô$ˆğ	Øs”8ˆDˆDøİğ 	ğ 	ğ 	ØˆEğ	øøøà4Š<ˆ<İØSĞQñô ğ ğ 	ˆq‰ˆña0ğd Œ8Œ=Ğs6   Á*A3 Á3
BÂ BÃ
C ÃC%Ã$C%Å/E8 Å8
FÆFc                  óJ   — e Zd ZdZdZdZdd„Zdd„Zdd„Zdd„Z	dd„Z
dd„ZdS )r@   z)Flags that map to parsed keys/namespaces.r   r	   r.   ÚNonec                ó:   — i | _         t          ¦   «         | _        d S r   )Ú_flagsÚsetÚ_pending_flags©Úselfs    r   Ú__init__zFlags.__init__   s   € Ø')ˆŒİ47±E´EˆÔĞĞr   Úkeyr   ÚflagÚintc                ó>   — | j                              ||f¦  «         d S r   )rZ   Úadd©r\   r^   r_   s      r   Úadd_pendingzFlags.add_pending”   s#   € ØÔ×Ò  d Ñ,Ô,Ğ,Ğ,Ğ,r   c                ó‚   — | j         D ]\  }}|                      ||d¬¦  «         Œ| j                              ¦   «          d S )NF©Ú	recursive)rZ   rY   Úclearrc   s      r   rH   zFlags.finalize_pending—   sN   € ØÔ,ğ 	1ğ 	1‰IˆCØHŠHS˜$¨%ˆHÑ0Ô0Ğ0Ğ0ØÔ×!Ò!Ñ#Ô#Ğ#Ğ#Ğ#r   c                ó   — | j         }|d d…         D ]}||vr d S ||         d         }Œ|                     |d         d ¦  «         d S )NéÿÿÿÿÚnested)rX   Úpop)r\   r^   ÚcontÚks       r   Ú	unset_allzFlags.unset_allœ   s^   € ØŒ{ˆØSbS”ğ 	%ğ 	%ˆAØ˜ˆ}ˆ}ØØ˜”7˜8Ô$ˆDˆDØŠR”˜$ÑÔĞĞĞr   rg   Úboolc               ó<  — | j         }|d d…         |d         }}|D ]5}||vr!t          ¦   «         t          ¦   «         i dœ||<   ||         d         }Œ6||vr!t          ¦   «         t          ¦   «         i dœ||<   ||         |rdnd                              |¦  «         d S )Nrj   )rG   Úrecursive_flagsrk   rk   rr   rG   )rX   rY   rb   )r\   r^   r_   rg   rm   Ú
key_parentÚkey_stemrn   s           r   rY   z	Flags.set¤   s¶   € ØŒ{ˆØ" 3 B 3œx¨¨R¬Hˆ
Øğ 	%ğ 	%ˆAØ˜ˆ}ˆ}İ$'¡E¤E½c¹e¼eÈrĞRĞRQ‘Ø˜”7˜8Ô$ˆDˆDØ˜4ĞĞİ'*¡u¤uÅÁÄĞRTĞUĞUˆD‰NØˆXŒ¨IĞBĞ(Ğ(¸7ÔC×GÒGÈÑMÔMĞMĞMĞMr   c                óÎ   — |sdS | j         }|d d…         D ]&}||vr dS ||         }||d         v r dS |d         }Œ'|d         }||v r||         }||d         v p	||d         v S dS )NFrj   rr   Trk   rG   )rX   )r\   r^   r_   rm   rn   Ú
inner_contrt   s          r   Úis_z	Flags.is_¯   s«   € Øğ 	Ø5ØŒ{ˆØSbS”ğ 	(ğ 	(ˆAØ˜ˆ}ˆ}ØuuØ˜aœˆJØzĞ"3Ô4Ğ4Ğ4ØttØ˜hÔ'ˆDˆDØr”7ˆØtĞĞØ˜”>ˆDØ˜4 œ=Ğ(ĞK¨D°DĞ9JÔ4KĞ,KĞKØˆur   N©r.   rV   )r^   r   r_   r`   r.   rV   ©r^   r   r.   rV   )r^   r   r_   r`   rg   rp   r.   rV   )r^   r   r_   r`   r.   rp   )r&   r'   r(   r)   ÚFROZENÚEXPLICIT_NESTr]   rd   rH   ro   rY   rw   r*   r   r   r@   r@   ‡   s¤   € € € € € Ø3Ğ3ğ €Fğ €Mğ:ğ :ğ :ğ :ğ-ğ -ğ -ğ -ğ$ğ $ğ $ğ $ğ
 ğ  ğ  ğ  ğ	Nğ 	Nğ 	Nğ 	Nğğ ğ ğ ğ ğ r   r@   c                  ó,   — e Zd Zdd„Zddœdd„Zdd„ZdS )r?   r.   rV   c                ó   — i | _         d S r   )rN   r[   s    r   r]   zNestedDict.__init__Â   s   € à$&ˆŒ	ˆ	ˆ	r   T©Úaccess_listsr^   r   r   rp   rN   c               óÆ   — | j         }|D ]V}||vri ||<   ||         }|rt          |t          ¦  «        r|d         }t          |t           ¦  «        st          d¦  «        ‚ŒW|S )Nrj   z There is no nest behind this key)rN   Ú
isinstanceÚlistÚKeyError)r\   r^   r   rm   rn   s        r   Úget_or_create_nestzNestedDict.get_or_create_nestÆ   s†   € ğ ”IˆØğ 	Cğ 	CˆAØ˜ˆ}ˆ}ØQ‘Ø˜”7ˆDØğ  ¥
¨4µÑ 6Ô 6ğ  Ø˜B”xİ˜d¥DÑ)Ô)ğ CİĞAÑBÔBĞBğCàˆr   c                óê   — |                       |d d…         ¦  «        }|d         }||v rC||         }t          |t          ¦  «        st          d¦  «        ‚|                     i ¦  «         d S i g||<   d S )Nrj   z/An object other than list found behind this key)r„   r   r‚   rƒ   Úappend)r\   r^   rm   Úlast_keyÚlist_s        r   Úappend_nest_to_listzNestedDict.append_nest_to_list×   sƒ   € Ø×&Ò& s¨3¨B¨3¤xÑ0Ô0ˆØr”7ˆØtĞĞØ˜”NˆEİ˜e¥TÑ*Ô*ğ RİĞPÑQÔQĞQØLŠL˜ÑÔĞĞĞà ˜TˆD‰NˆNˆNr   Nrx   )r^   r   r   rp   r.   rN   ry   )r&   r'   r(   r]   r„   r‰   r*   r   r   r?   r?   Á   s_   € € € € € ğ'ğ 'ğ 'ğ 'ğ "ğ	ğ ğ ğ ğ ğ ğ"	"ğ 	"ğ 	"ğ 	"ğ 	"ğ 	"r   r?   c                  ó$   — e Zd ZU ded<   ded<   dS )r>   r?   rM   r@   rG   N)r&   r'   r(   Ú__annotations__r*   r   r   r>   r>   ã   s%   € € € € € € ØĞĞÑØ€L€LL€L€Lr   r>   rO   rP   r   ÚcharsúIterable[str]c                ó\   — 	 | |         |v r|dz  }| |         |v °n# t           $ r Y nw xY w|S )Nr	   )rD   )rO   rP   rŒ   s      r   rB   rB   è   sV   € ğØ#Œh˜%ĞĞØ1‰HˆCğ #Œh˜%ĞĞøøåğ ğ ğ Øˆğøøøà€Js   ‚ œ
)¨)ÚexpectÚerror_onúfrozenset[str]Úerror_on_eofrp   c               óB  — 	 |                       ||¦  «        }n6# t          $ r) t          | ¦  «        }|rt          | |d|›¦  «        d ‚Y nw xY w|                     | ||…         ¦  «        s3| |         |vr|dz  }| |         |v°t          | |d| |         ›¦  «        ‚|S )Nz	Expected r	   zFound invalid character )ÚindexÚ
ValueErrorÚlenrK   Ú
isdisjoint)rO   rP   r   r   r’   Únew_poss         r   Ú
skip_untilr™   ñ   sè   € ğOØ—)’)˜F CÑ(Ô(ˆˆøİğ Oğ Oğ Oİc‘(”(ˆØğ 	Oİ˜s GĞ-C¸Ğ-CĞ-CÑDÔDÈ$ĞNğ	Oğ 	OğOøøøğ
 ×Ò˜s 3 w ;Ô/Ñ0Ô0ğ NØ#Œh˜hĞ&Ğ&Ø1‰HˆCğ #Œh˜hĞ&Ğ&å˜3 Ğ%LÀÀCÄĞ%LĞ%LÑMÔMĞMØ€Ns   ‚ ™0AÁAc                ó‚   — 	 | |         }n# t           $ r d }Y nw xY w|dk    rt          | |dz   dt          d¬¦  «        S |S )Nr<   r	   r   F©r   r’   )rD   r™   ÚILLEGAL_COMMENT_CHARS)rO   rP   rS   s      r   rL   rL     sm   € ğØ˜sœ8ˆˆøİğ ğ ğ Øˆˆˆğøøøàˆs‚{€{İØq‘˜$Õ)>ÈUğ
ñ 
ô 
ğ 	
ğ €Jó   ‚ ‹™c                óf   — 	 |}t          | |t          ¦  «        }t          | |¦  «        }||k    r|S Œ1r   )rB   ÚTOML_WS_AND_NEWLINErL   )rO   rP   Úpos_before_skips      r   Úskip_comments_and_array_wsr¡     sB   € ğØˆİ˜˜cÕ#6Ñ7Ô7ˆİ˜3 Ñ$Ô$ˆØ/Ò!Ğ!ØˆJğr   rQ   útuple[Pos, Key]c                ó>  — |dz  }t          | |t          ¦  «        }t          | |¦  «        \  }}|j                             |t
          j        ¦  «        s%|j                             |t
          j        ¦  «        rt          | |d|› d¦  «        ‚|j         	                    |t
          j        d¬¦  «         	 |j
                             |¦  «         n # t          $ r t          | |d¦  «        d ‚w xY w|                      d|¦  «        st          | |d¦  «        ‚|dz   |fS )	Nr	   zCannot declare z twiceFrf   úCannot overwrite a valueú]z.Expected ']' at the end of a table declaration)rB   rC   Ú	parse_keyrG   rw   r@   r{   rz   rK   rY   rM   r„   rƒ   Ú
startswith©rO   rP   rQ   r^   s       r   rJ   rJ     s-  € Øˆ1H€Cİ
S˜#wÑ
'Ô
'€Cİ˜˜cÑ"Ô"H€Cˆà
„y‡}‚}S%Ô-Ñ.Ô.ğ D°#´)·-²-ÀÅUÄ\Ñ2RÔ2Rğ Dİ˜3 Ğ%B°sĞ%BĞ%BĞ%BÑCÔCĞCØ„I‡M‚M#•uÔ*°e€MÑ<Ô<Ğ<ğKØŒ×#Ò# CÑ(Ô(Ğ(Ğ(øİğ Kğ Kğ Kİ˜3 Ğ%?Ñ@Ô@ÀdĞJğKøøøğ >Š>˜#˜sÑ#Ô#ğ Wİ˜3 Ğ%UÑVÔVĞVØ‰7Cˆ<Ğs   Â6C ÃC.c                ó&  — |dz  }t          | |t          ¦  «        }t          | |¦  «        \  }}|j                             |t
          j        ¦  «        rt          | |d|› ¦  «        ‚|j                             |¦  «         |j         	                    |t
          j
        d¬¦  «         	 |j                             |¦  «         n # t          $ r t          | |d¦  «        d ‚w xY w|                      d|¦  «        st          | |d¦  «        ‚|dz   |fS )Né   ú"Cannot mutate immutable namespace Frf   r¤   z]]z0Expected ']]' at the end of an array declaration)rB   rC   r¦   rG   rw   r@   rz   rK   ro   rY   r{   rM   r‰   rƒ   r§   r¨   s       r   rI   rI   .  s%  € Øˆ1H€Cİ
S˜#wÑ
'Ô
'€Cİ˜˜cÑ"Ô"H€Cˆà
„y‡}‚}S%œ,Ñ'Ô'ğ Qİ˜3 Ğ%OÈ#Ğ%OĞ%OÑPÔPĞPà„I×Ò˜ÑÔĞà„I‡M‚M#•uÔ*°e€MÑ<Ô<Ğ<ğKØŒ×$Ò$ SÑ)Ô)Ğ)Ğ)øİğ Kğ Kğ Kİ˜3 Ğ%?Ñ@Ô@ÀdĞJğKøøøğ >Š>˜$ Ñ$Ô$ğ Yİ˜3 Ğ%WÑXÔXĞXØ‰7Cˆ<Ğs   Â*C ÃC"rR   r   c                ó&  ‡‡— t          | ||¦  «        \  }Š}‰d d…         ‰d         }}‰|z   }ˆˆfd„t          dt          ‰¦  «        ¦  «        D ¦   «         }	|	D ]`}
|j                             |
t
          j        ¦  «        rt          | |d|
› ¦  «        ‚|j                             |
t
          j        ¦  «         Œa|j                             |t
          j	        ¦  «        rt          | |d|› ¦  «        ‚	 |j
                             |¦  «        }n # t          $ r t          | |d¦  «        d ‚w xY w||v rt          | |d¦  «        ‚t          |t          t          f¦  «        r*|j                             ‰‰z   t
          j	        d¬¦  «         |||<   |S )	Nrj   c              3  ó2   •K  — | ]}‰‰d |…         z   V — Œd S r   r*   )r   r   rR   r^   s     €€r   r   z!key_value_rule.<locals>.<genexpr>J  s0   øè è € ĞLĞL°A˜v¨¨B¨Q¨B¬Ñ/ĞLĞLĞLĞLĞLĞLr   r	   zCannot redefine namespace r«   r¤   Trf   )Úparse_key_value_pairÚranger–   rG   rw   r@   r{   rK   rd   rz   rM   r„   rƒ   r   rN   r‚   rY   )rO   rP   rQ   rR   r,   Úvaluers   rt   Úabs_key_parentÚrelative_path_cont_keysÚcont_keyÚnestr^   s      `        @r   rF   rF   C  s¿  øø€ õ +¨3°°[ÑAÔAO€CˆˆeØ˜s ˜sœ8 S¨¤W€JØ˜jÑ(€NàLĞLĞLĞLĞL½¸qÅ#ÀcÁ(Ä(Ñ9KÔ9KĞLÑLÔLĞØ+ğ =ğ =ˆàŒ9=Š=˜¥5Ô#6Ñ7Ô7ğ 	Rİ˜s CĞ)PÀhĞ)PĞ)PÑQÔQĞQğ 	Œ	×Ò˜h­Ô(;Ñ<Ô<Ğ<Ğ<à
„y‡}‚}^¥U¤\Ñ2Ô2ğ 
İØĞK¸>ĞKĞKñ
ô 
ğ 	
ğKØŒx×*Ò*¨>Ñ:Ô:ˆˆøİğ Kğ Kğ Kİ˜3 Ğ%?Ñ@Ô@ÀdĞJğKøøøà4ĞĞİ˜3 Ğ%?Ñ@Ô@Ğ@å%$¥˜Ñ&Ô&ğ BØŒ	Šf˜s‘l¥E¤L¸DˆÑAÔAĞAØ€DˆNØ€Js   Ã6D ÄD.útuple[Pos, Key, Any]c                óö   — t          | |¦  «        \  }}	 | |         }n# t          $ r d }Y nw xY w|dk    rt          | |d¦  «        ‚|dz  }t          | |t          ¦  «        }t          | ||¦  «        \  }}|||fS )Nú=z,Expected '=' after a key in a key/value pairr	   )r¦   rD   rK   rB   rC   Úparse_value)rO   rP   r,   r^   rS   r°   s         r   r®   r®   e  s¢   € õ ˜˜cÑ"Ô"H€CˆğØ˜sœ8ˆˆøİğ ğ ğ Øˆˆˆğøøøàˆs‚{€{İ˜3 Ğ%SÑTÔTĞTØˆ1H€Cİ
S˜#wÑ
'Ô
'€Cİ˜S # {Ñ3Ô3J€CˆØUˆ?Ğs   • -¬-c                ó>  — t          | |¦  «        \  }}|f}t          | |t          ¦  «        }	 	 | |         }n# t          $ r d }Y nw xY w|dk    r||fS |dz  }t          | |t          ¦  «        }t          | |¦  «        \  }}||fz  }t          | |t          ¦  «        }Œq)NTú.r	   )Úparse_key_partrB   rC   rD   )rO   rP   Úkey_partr^   rS   s        r   r¦   r¦   u  sÇ   € İ" 3¨Ñ,Ô,M€CˆØˆ{€Cİ
S˜#wÑ
'Ô
'€Cğ,ğ	Ø" 3œxˆDˆDøİğ 	ğ 	ğ 	ØˆDˆDˆDğ	øøøà3Š;ˆ;Ø˜8ˆOØˆq‰ˆİ˜˜c¥7Ñ+Ô+ˆİ& s¨CÑ0Ô0‰ˆˆXØˆ{Ñˆİ˜˜c¥7Ñ+Ô+ˆğ,s   ¯8 ¸AÁAútuple[Pos, str]c                ó  — 	 | |         }n# t           $ r d }Y nw xY w|t          v r$|}t          | |t          ¦  «        }|| ||…         fS |dk    rt          | |¦  «        S |dk    rt	          | |¦  «        S t          | |d¦  «        ‚)Nú'r"   z(Invalid initial character for a key part)rD   ÚBARE_KEY_CHARSrB   Úparse_literal_strÚparse_one_line_basic_strrK   )rO   rP   rS   Ú	start_poss       r   r»   r»   ‡  s°   € ğØ˜sœ8ˆˆøİğ ğ ğ Øˆˆˆğøøøà~ĞĞØˆ	İ˜˜c¥>Ñ2Ô2ˆØC˜	 #˜Ô&Ğ&Ğ&Øˆs‚{€{İ   cÑ*Ô*Ğ*Øˆs‚{€{İ'¨¨SÑ1Ô1Ğ1İ
s˜CĞ!KÑ
LÔ
LĞLr   c                ó0   — |dz  }t          | |d¬¦  «        S )Nr	   F©Ú	multiline)Úparse_basic_str©rO   rP   s     r   rÂ   rÂ   —  s    € Øˆ1H€Cİ˜3 ¨uĞ5Ñ5Ô5Ğ5r   útuple[Pos, list]c                ó¦  — |dz  }g }t          | |¦  «        }|                      d|¦  «        r|dz   |fS 	 t          | ||¦  «        \  }}|                     |¦  «         t          | |¦  «        }| ||dz   …         }|dk    r|dz   |fS |dk    rt	          | |d¦  «        ‚|dz  }t          | |¦  «        }|                      d|¦  «        r|dz   |fS Œ)Nr	   r¥   Tú,zUnclosed array)r¡   r§   r¸   r†   rK   )rO   rP   r,   ÚarrayÚvalÚcs         r   Úparse_arrayrÏ   œ  s  € Øˆ1H€CØ€Eå
$ S¨#Ñ
.Ô
.€CØ
‡~‚~c˜3ÑÔğ ØQ‰w˜ˆ~Ğğ"İ˜s C¨Ñ5Ô5‰ˆˆSØŠSÑÔĞİ(¨¨cÑ2Ô2ˆàc˜A‘gÔˆØŠ8ˆ8Ø˜‘7˜E>Ğ!ØŠ8ˆ8İ˜s CĞ)9Ñ:Ô:Ğ:Øˆq‰ˆå(¨¨cÑ2Ô2ˆØ>Š>˜#˜sÑ#Ô#ğ 	"Ø˜‘7˜E>Ğ!ğ"r   útuple[Pos, dict]c                óf  — |dz  }t          ¦   «         }t          ¦   «         }t          | |t          ¦  «        }|                      d|¦  «        r|dz   |j        fS 	 t          | ||¦  «        \  }}}|d d…         |d         }}|                     |t          j        ¦  «        rt          | |d|› ¦  «        ‚	 | 
                    |d¬¦  «        }	n # t          $ r t          | |d¦  «        d ‚w xY w||	v rt          | |d	|›¦  «        ‚||	|<   t          | |t          ¦  «        }| ||dz   …         }
|
dk    r|dz   |j        fS |
d
k    rt          | |d¦  «        ‚t          |t
          t          f¦  «        r"|                     |t          j        d¬¦  «         |dz  }t          | |t          ¦  «        }ŒX)Nr	   ú}Trj   r«   Fr~   r¤   zDuplicate inline table key rË   zUnclosed inline tablerf   )r?   r@   rB   rC   r§   rN   r®   rw   rz   rK   r„   rƒ   r   r‚   rY   )rO   rP   r,   Únested_dictrG   r^   r°   rs   rt   r´   rÎ   s              r   Úparse_inline_tablerÔ   ´  sç  € Øˆ1H€Cİ‘,”,€Kİ‰GŒG€Eå
S˜#wÑ
'Ô
'€CØ
‡~‚~c˜3ÑÔğ )ØQ‰w˜Ô(Ğ(Ğ(ğ,İ.¨s°C¸ÑEÔE‰ˆˆS%Ø" 3 B 3œx¨¨R¬Hˆ
Ø9Š9S%œ,Ñ'Ô'ğ 	Uİ˜s CĞ)SÈcĞ)SĞ)SÑTÔTĞTğ	OØ×1Ò1°*È5Ğ1ÑQÔQˆDˆDøİğ 	Oğ 	Oğ 	Oİ˜s CĞ)CÑDÔDÈ$ĞNğ	OøøøàtĞĞİ˜s CĞ)SÀxĞ)SĞ)SÑTÔTĞTØˆˆX‰İ˜˜c¥7Ñ+Ô+ˆØc˜A‘gÔˆØŠ8ˆ8Ø˜‘7˜KÔ,Ğ,Ğ,ØŠ8ˆ8İ˜s CĞ)@ÑAÔAĞAİed¥D˜\Ñ*Ô*ğ 	9ØIŠIc5œ<°4ˆIÑ8Ô8Ğ8Øˆq‰ˆİ˜˜c¥7Ñ+Ô+ˆñ+,s   Â7C ÃC,FrÅ   rÆ   c               óÎ  — | ||dz   …         }|dz  }|rt|dv rp|dk    rPt          | |t          ¦  «        }	 | |         }n# t          $ r |dfcY S w xY w|dk    rt          | |d¦  «        ‚|dz  }t          | |t          ¦  «        }|dfS |dk    rt          | |d	¦  «        S |d
k    rt          | |d¦  «        S 	 |t          |         fS # t          $ r t          | |d¦  «        d ‚w xY w)Nrª   >   ú\	ú\ ú\
rØ   Ú r   zUnescaped '\' in a stringr	   z\ué   z\Ué   )rB   rC   rD   rK   rŸ   Úparse_hex_charÚBASIC_STR_ESCAPE_REPLACEMENTSrƒ   )rO   rP   rÆ   Ú	escape_idrS   s        r   Úparse_basic_str_escaperß   Ô  sM  € ğ C˜# ™'MÔ"€IØˆ1H€CØğ YĞ"9Ğ9Ğ9ğ ˜ÒĞİ˜S #¥wÑ/Ô/ˆCğØ˜3”xøİğ ğ ğ Ø˜BwğøøøàtŠ|ˆ|İ" 3¨Ğ-IÑJÔJĞJØ1‰HˆCİ˜˜cÕ#6Ñ7Ô7ˆØBˆwˆØEÒĞİ˜c 3¨Ñ*Ô*Ğ*ØEÒĞİ˜c 3¨Ñ*Ô*Ğ*ğMØÕ1°)Ô<Ğ<Ğ<øİğ Mğ Mğ Mİ˜3 Ğ%AÑBÔBÈĞLğMøøøs   ¶? ¿AÁAÂ8C ÃC$c                ó&   — t          | |d¬¦  «        S )NTrÅ   )rß   rÈ   s     r   Ú parse_basic_str_escape_multilinerá   ñ  s   € İ! # s°dĞ;Ñ;Ô;Ğ;r   Úhex_lenr`   c                ó$  — | |||z   …         }t          |¦  «        |k    st                               |¦  «        st          | |d¦  «        ‚||z  }t	          |d¦  «        }t          |¦  «        st          | |d¦  «        ‚|t          |¦  «        fS )NzInvalid hex valueé   z/Escaped character is not a Unicode scalar value)r–   ÚHEXDIGIT_CHARSÚ
issupersetrK   r`   Úis_unicode_scalar_valuer   )rO   rP   râ   Úhex_strÚhex_ints        r   rÜ   rÜ   õ  s™   € Ø#˜˜g™Ğ%Ô&€Gİ
ˆ7|„|wÒĞ¥n×&?Ò&?ÀÑ&HÔ&HĞİ˜3 Ğ%8Ñ9Ô9Ğ9Øˆ7N€Cİ'˜2ÑÔ€Gİ" 7Ñ+Ô+ğ Xİ˜3 Ğ%VÑWÔWĞWØ•G‘”ĞĞr   c                ó`   — |dz  }|}t          | |dt          d¬¦  «        }|dz   | ||…         fS )Nr	   r¿   Tr›   )r™   ÚILLEGAL_LITERAL_STR_CHARS)rO   rP   rÃ   s      r   rÁ   rÁ      sJ   € Øˆ1H€CØ€Iİ
ØˆS#Õ 9Èğñ ô €Cğ ‰7C˜	 #˜Ô&Ğ&Ğ&r   Úliteralc               ó`  — |dz  }|                       d|¦  «        r|dz  }|r+d}t          | |dt          d¬¦  «        }| ||…         }|dz   }nd}t          | |d¬	¦  «        \  }}|                       ||¦  «        s||fS |dz  }|                       ||¦  «        s|||z   fS |dz  }|||d
z  z   fS )Né   r   r	   r¿   ú'''Tr›   r"   rÅ   rª   )r§   r™   Ú#ILLEGAL_MULTILINE_LITERAL_STR_CHARSrÇ   )rO   rP   rì   ÚdelimÚend_posÚresults         r   Úparse_multiline_strrô   	  s   € Øˆ1H€CØ
‡~‚~d˜CÑ Ô ğ Øˆq‰ˆàğ @ØˆİØØØİ8Øğ
ñ 
ô 
ˆğ S˜[Ô!ˆØ˜‰kˆˆàˆİ% c¨3¸$Ğ?Ñ?Ô?‰ˆˆVğ >Š>˜% Ñ%Ô%ğ ØFˆ{ĞØˆ1H€CØ>Š>˜% Ñ%Ô%ğ #ØF˜U‘NĞ"Ğ"Øˆ1H€CØ˜% !™)Ñ$Ğ$Ğ$r   c               ó¾  — |rt           }t          }nt          }t          }d}|}	 	 | |         }n # t          $ r t          | |d¦  «        d ‚w xY w|dk    rB|s|dz   || ||…         z   fS |                      d|¦  «        r|dz   || ||…         z   fS |dz  }Œs|dk    r$|| ||…         z  } || |¦  «        \  }}||z  }|}Œ||v rt          | |d	|›¦  «        ‚|dz  }Œº)
NrÙ   TzUnterminated stringr"   r	   ú"""rî   r#   zIllegal character )Ú!ILLEGAL_MULTILINE_BASIC_STR_CHARSrá   ÚILLEGAL_BASIC_STR_CHARSrß   rD   rK   r§   )	rO   rP   rÆ   r   Úparse_escapesró   rÃ   rS   Úparsed_escapes	            r   rÇ   rÇ   (  sY  € Øğ /İ4ˆİ8ˆˆå*ˆİ.ˆØ€FØ€Iğğ	JØs”8ˆDˆDøİğ 	Jğ 	Jğ 	Jİ˜s CĞ)>Ñ?Ô?ÀTĞIğ	Jøøøà3Š;ˆ;Øğ <Ø˜Q‘w ¨¨Y°s¨]Ô);Ñ ;Ğ;Ğ;Ø~Š~˜e SÑ)Ô)ğ <Ø˜Q‘w ¨¨Y°s¨]Ô);Ñ ;Ğ;Ğ;Ø1‰HˆCØØ4Š<ˆ<Øc˜) C˜-Ô(Ñ(ˆFØ!. ¨s°CÑ!8Ô!8ÑˆCØmÑ#ˆFØˆIØØ8ĞĞİ˜s CĞ)F¸dĞ)FĞ)FÑGÔGĞGØˆq‰ˆğ)s	   ¦/ ¯Aútuple[Pos, Any]c                ón  — 	 | |         }n# t           $ r d }Y nw xY w|dk    r8|                      d|¦  «        rt          | |d¬¦  «        S t          | |¦  «        S |dk    r8|                      d|¦  «        rt          | |d¬¦  «        S t	          | |¦  «        S |dk    r|                      d	|¦  «        r|d
z   dfS |dk    r|                      d|¦  «        r|dz   dfS |dk    rt          | ||¦  «        S |dk    rt          | ||¦  «        S t          j        | |¦  «        }|rK	 t          |¦  «        }n$# t          $ r}t          | |d¦  «        |‚d }~ww xY w|                     ¦   «         |fS t          j        | |¦  «        }|r#|                     ¦   «         t          |¦  «        fS t          j        | |¦  «        }|r$|                     ¦   «         t!          ||¦  «        fS | ||dz   …         }	|	dv r|dz    ||	¦  «        fS | ||d
z   …         }
|
dv r|d
z    ||
¦  «        fS t          | |d¦  «        ‚)Nr"   rö   F)rì   r¿   rï   TÚtÚtruerÚ   ÚfÚfalseé   r;   ú{zInvalid date or datetimerî   >   ÚinfÚnan>   ú+infú+nanú-infú-nanzInvalid value)rD   r§   rô   rÂ   rÁ   rÏ   rÔ   r
   Úmatchr   r•   rK   Úendr   r   r   r   )rO   rP   r,   rS   Údatetime_matchÚdatetime_objÚeÚlocaltime_matchÚnumber_matchÚfirst_threeÚ
first_fours              r   r¸   r¸   H  sÒ  € ğØ˜sœ8ˆˆøİğ ğ ğ Øˆˆˆğøøøğ ˆs‚{€{Ø>Š>˜% Ñ%Ô%ğ 	@İ& s¨C¸Ğ?Ñ?Ô?Ğ?İ'¨¨SÑ1Ô1Ğ1ğ ˆs‚{€{Ø>Š>˜% Ñ%Ô%ğ 	?İ& s¨C¸Ğ>Ñ>Ô>Ğ>İ   cÑ*Ô*Ğ*ğ ˆs‚{€{Ø>Š>˜& #Ñ&Ô&ğ 	!Ø˜‘7˜D=Ğ Øˆs‚{€{Ø>Š>˜' 3Ñ'Ô'ğ 	"Ø˜‘7˜E>Ğ!ğ ˆs‚{€{İ˜3  [Ñ1Ô1Ğ1ğ ˆs‚{€{İ! # s¨KÑ8Ô8Ğ8õ !Ô& s¨CÑ0Ô0€NØğ 2ğ	Lİ,¨^Ñ<Ô<ˆLˆLøİğ 	Lğ 	Lğ 	Lİ˜s CĞ)CÑDÔDÈ!ĞKøøøøğ	Løøøà×!Ò!Ñ#Ô# \Ğ1Ğ1İ"Ô(¨¨cÑ2Ô2€OØğ JØ×"Ò"Ñ$Ô$Õ&8¸Ñ&IÔ&IĞIĞIõ
 ”? 3¨Ñ,Ô,€LØğ NØ×ÒÑ!Ô!¥?°<ÀÑ#MÔ#MĞMĞMğ c˜C !™GmÔ$€KØnĞ$Ğ$ØQ‰w˜˜ KÑ0Ô0Ğ0Ğ0ØS˜3 ™7]Ô#€JØĞ5Ğ5Ğ5ØQ‰w˜˜ JÑ/Ô/Ğ/Ğ/å
s˜C Ñ
1Ô
1Ğ1s$   ‚ ‹™Ä%D5 Ä5
EÄ?EÅEÚmsgc                óH   — d	d„}t          |› d || |¦  «        › d¦  «        S )
zZReturn a `TOMLDecodeError` where error message is suffixed with
    coordinates in source.rO   r9   rP   r   r.   c                ó¼   — |t          | ¦  «        k    rdS |                      dd|¦  «        dz   }|dk    r|dz   }n||                      dd|¦  «        z
  }d|› d|› S )Nzend of documentr   r   r	   zline z	, column )r–   ÚcountÚrindex)rO   rP   ÚlineÚcolumns       r   Ú
coord_reprz suffixed_err.<locals>.coord_repr  su   € Ø•#c‘(”(Š?ˆ?Ø$Ğ$ØyŠy˜˜q #Ñ&Ô&¨Ñ*ˆØ1Š9ˆ9Ø˜1‘WˆFˆFà˜3Ÿ:š: d¨A¨sÑ3Ô3Ñ3ˆFØ.tĞ.Ğ. fĞ.Ğ.Ğ.r   z (at ú))rO   r9   rP   r   r.   r9   )r%   )rO   rP   r  r  s       r   rK   rK   Œ  sC   € ğ/ğ /ğ /ğ /õ ˜cĞ?Ğ?¨
¨
°3¸Ñ(<Ô(<Ğ?Ğ?Ğ?Ñ@Ô@Ğ@r   Ú	codepointc                óB   — d| cxk    odk    nc pd| cxk    odk    nc S )Nr   iÿ×  i à  iÿÿ r*   )r  s    r   rç   rç     sE   € ØĞ#Ğ#Ò#Ğ#˜eÒ#Ğ#Ğ#Ğ#ĞG¨°)Ğ)FĞ)FÒ)FĞ)F¸wÒ)FĞ)FĞ)FĞ)FĞGr   c                ó4   ‡ — ‰ t           u rt           S dˆ fd„}|S )a%  A decorator to make `parse_float` safe.

    `parse_float` must not return dicts or lists, because these types
    would be mixed with parsed TOML tables and arrays, thus confusing
    the parser. The returned decorated callable raises `ValueError`
    instead of returning illegal types.
    Ú	float_strr9   r.   r   c                ót   •—  ‰| ¦  «        }t          |t          t          f¦  «        rt          d¦  «        ‚|S )Nz*parse_float must not return dicts or lists)r   rN   r‚   r•   )r  Úfloat_valuer,   s     €r   Úsafe_parse_floatz/make_safe_parse_float.<locals>.safe_parse_float­  s>   ø€ Ø!k )Ñ,Ô,ˆİk¥D­$ <Ñ0Ô0ğ 	KİĞIÑJÔJĞJØĞr   )r  r9   r.   r   )Úfloat)r,   r!  s   ` r   rA   rA   ¡  s;   ø€ ğ •eĞĞİˆğğ ğ ğ ğ ğ ğ Ğr   )r-   r   r,   r   r.   r/   )r7   r9   r,   r   r.   r/   )rO   r9   rP   r   rŒ   r   r.   r   )rO   r9   rP   r   r   r9   r   r‘   r’   rp   r.   r   )rO   r9   rP   r   r.   r   )rO   r9   rP   r   rQ   r>   r.   r¢   )rO   r9   rP   r   rQ   r>   rR   r   r,   r   r.   r   )rO   r9   rP   r   r,   r   r.   rµ   )rO   r9   rP   r   r.   r¢   )rO   r9   rP   r   r.   r½   )rO   r9   rP   r   r,   r   r.   rÉ   )rO   r9   rP   r   r,   r   r.   rĞ   )rO   r9   rP   r   rÆ   rp   r.   r½   )rO   r9   rP   r   râ   r`   r.   r½   )rO   r9   rP   r   rì   rp   r.   r½   )rO   r9   rP   r   r,   r   r.   rû   )rO   r9   rP   r   r  r9   r.   r%   )r  r`   r.   rp   )r,   r   r.   r   )GÚ
__future__r   Úcollections.abcr   ÚstringÚtypesr   Útypingr   r   r   Ú_rer
   r   r   r   r   r   Ú_typesr   r   r   Ú	frozensetr¯   r   Ú
ASCII_CTRLrø   r÷   rë   rğ   rœ   rC   rŸ   Úascii_lettersÚdigitsrÀ   rE   Ú	hexdigitsrå   rİ   r•   r%   r"  r8   r5   r@   r?   r>   rB   r™   rL   r¡   rJ   rI   rF   r®   r¦   r»   rÂ   rÏ   rÔ   rß   rá   rÜ   rÁ   rô   rÇ   r¸   rK   rç   rA   r*   r   r   ú<module>r/     sÒ  ğğ
 #Ğ "Ğ "Ğ "Ğ "Ğ "à $Ğ $Ğ $Ğ $Ğ $Ğ $Ø €€€Ø "Ğ "Ğ "Ğ "Ğ "Ğ "Ø ,Ğ ,Ğ ,Ğ ,Ğ ,Ğ ,Ğ ,Ğ ,Ğ ,Ğ ,ğğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ ğ )Ğ (Ğ (Ğ (Ğ (Ğ (Ğ (Ğ (Ğ (Ğ (àˆYĞ1Ğ1 u u¨R¡y¤yĞ1Ñ1Ô1Ñ1Ô1°I°I¸c¸cÀ#¹h¼hÑ4GÔ4GÑG€
ğ % y y°¡¤Ñ6Ğ Ø$.°°¸6Ñ1BÔ1BÑ$BĞ !à3Ğ Ø&GĞ #à/Ğ à
ˆ)EÑ
Ô
€Ø 	 	¨$¡¤Ñ/Ğ Ø˜6Ô/°&´-Ñ?À$ÑFÑGÔG€Ø" Y Y¨uÑ%5Ô%5Ñ5Ğ Ø˜6Ô+Ñ,Ô,€à 0Ğ 0àØØØØØØğğ ñ
!ô 
!Ğ ğ;ğ ;ğ ;ğ ;ğ ;jñ ;ô ;ğ ;ğ 8=ğ 	-ğ 	-ğ 	-ğ 	-ğ 	-ğ 	-ğ 38ğ ?ğ ?ğ ?ğ ?ğ ?ğ ?ğD7ğ 7ğ 7ğ 7ğ 7ñ 7ô 7ğ 7ğt"ğ "ğ "ğ "ğ "ñ "ô "ğ "ğDğ ğ ğ ğ ˆZñ ô ğ ğ
ğ ğ ğ ğğ ğ ğ ğ,	ğ 	ğ 	ğ 	ğğ ğ ğ ğğ ğ ğ ğ$ğ ğ ğ ğ*ğ ğ ğ ğDğ ğ ğ ğ ,ğ ,ğ ,ğ ,ğ$Mğ Mğ Mğ Mğ 6ğ 6ğ 6ğ 6ğ
"ğ "ğ "ğ "ğ0,ğ ,ğ ,ğ ,ğB .3ğMğ Mğ Mğ Mğ Mğ Mğ:<ğ <ğ <ğ <ğğ ğ ğ ğ'ğ 'ğ 'ğ 'ğ%ğ %ğ %ğ %ğ>ğ ğ ğ ğ@A2ğ A2ğ A2ğ A2ğHAğ Ağ Ağ Ağ"Hğ Hğ Hğ Hğğ ğ ğ ğ ğ r                                                                                                                                                                                                                                                                                                                                                                                                                                                  usr/lib/python3.11/tomllib/__pycache__/_re.cpython-311.pyc                                          0000644 0000000 0000000 00000010533 14714551121 021573  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        §
    Nüäf  ã                  ó*  — d dl mZ d dlmZmZmZmZmZmZ d dlm	Z	 d dl
Z
d dlmZ ddlmZ dZ e
j        d	e
j        ¬
¦  «        Z e
j        e¦  «        Z e
j        de› de
j        ¬
¦  «        Zdd„Z e	d¬¦  «        d d„¦   «         Zd!d„Zd"d„ZdS )#é    )Úannotations)ÚdateÚdatetimeÚtimeÚ	timedeltaÚtimezoneÚtzinfo)Ú	lru_cacheN)ÚAnyé   )Ú
ParseFloatzE([01][0-9]|2[0-3]):([0-5][0-9]):([0-5][0-9])(?:\.([0-9]{1,6})[0-9]*)?a`  
0
(?:
    x[0-9A-Fa-f](?:_?[0-9A-Fa-f])*   # hex
    |
    b[01](?:_?[01])*                 # bin
    |
    o[0-7](?:_?[0-7])*               # oct
)
|
[+-]?(?:0|[1-9](?:_?[0-9])*)         # dec, integer part
(?P<floatpart>
    (?:\.[0-9](?:_?[0-9])*)?         # optional fractional part
    (?:[eE][+-]?[0-9](?:_?[0-9])*)?  # optional exponent part
)
)Úflagsz`
([0-9]{4})-(0[1-9]|1[0-2])-(0[1-9]|[12][0-9]|3[01])  # date, e.g. 1988-10-27
(?:
    [Tt ]
    zR
    (?:([Zz])|([+-])([01][0-9]|2[0-3]):([0-5][0-9]))?  # optional time offset
)?
Úmatchúre.MatchÚreturnúdatetime | datec                óâ  — |                       ¦   «         \  }}}}}}}}}	}
}t          |¦  «        t          |¦  «        t          |¦  «        }}}|€t          |||¦  «        S t          |¦  «        t          |¦  «        t          |¦  «        }}}|r#t          |                     dd¦  «        ¦  «        nd}|	rt	          |
||	¦  «        }n|rt
          j        }nd}t          ||||||||¬¦  «        S )z¦Convert a `RE_DATETIME` match to `datetime.datetime` or `datetime.date`.

    Raises ValueError if the match does not correspond to a valid date
    or datetime.
    Né   Ú0r   )r	   )ÚgroupsÚintr   ÚljustÚ	cached_tzr   Úutcr   )r   Úyear_strÚ	month_strÚday_strÚhour_strÚ
minute_strÚsec_strÚ
micros_strÚ	zulu_timeÚoffset_sign_strÚoffset_hour_strÚoffset_minute_strÚyearÚmonthÚdayÚhourÚminuteÚsecÚmicrosÚtzs                       ú"/usr/lib/python3.11/tomllib/_re.pyÚmatch_to_datetimer/   4   s
  € ğ$ 	Š‰ŒñØØØØØØØØØØØå˜8‘}”}¥c¨)¡n¤nµc¸'±l´lˆ%€DØĞİD˜% Ñ%Ô%Ğ%İ˜H™œ¥s¨:¡¤½¸G¹¼#ˆ&€DØ.8Ğ?S×!Ò! ! SÑ)Ô)Ñ*Ô*Ğ*¸a€FØğ İ%ØĞ.°ñ
ô 
ˆˆğ 
ğ İŒ\ˆˆàˆİD˜%  d¨F°C¸ÈĞKÑKÔKĞKó    )Úmaxsizer   Ústrr   Úsign_strr   c           	     ó’   — |dk    rdnd}t          t          |t          | ¦  «        z  |t          |¦  «        z  ¬¦  «        ¦  «        S )Nú+r   éÿÿÿÿ)ÚhoursÚminutes)r   r   r   )r   r   r3   Úsigns       r.   r   r   W   sS   € à˜C’ˆ1ˆ1 R€DİİØ˜X™œÑ&Ø3˜z™?œ?Ñ*ğ	
ñ 	
ô 	
ñô ğ r0   r   c                óô   — |                       ¦   «         \  }}}}|r#t          |                     dd¦  «        ¦  «        nd}t          t          |¦  «        t          |¦  «        t          |¦  «        |¦  «        S )Nr   r   r   )r   r   r   r   )r   r   r   r    r!   r,   s         r.   Úmatch_to_localtimer;   b   se   € Ø05·²±´Ñ-€Hˆj˜' :Ø.8Ğ?S×!Ò! ! SÑ)Ô)Ñ*Ô*Ğ*¸a€Fİ•H‘”s :™œµ°G±´¸fÑEÔEĞEr0   Úparse_floatr   r   c                óª   — |                       d¦  «        r ||                       ¦   «         ¦  «        S t          |                       ¦   «         d¦  «        S )NÚ	floatpartr   )Úgroupr   )r   r<   s     r.   Úmatch_to_numberr@   h   sF   € Ø‡{‚{;ÑÔğ *Øˆ{˜5Ÿ;š;™=œ=Ñ)Ô)Ğ)İˆu{Š{‰}Œ}˜aÑ Ô Ğ r0   )r   r   r   r   )r   r2   r   r2   r3   r2   r   r   )r   r   r   r   )r   r   r<   r   r   r   )Ú
__future__r   r   r   r   r   r   r	   Ú	functoolsr
   ÚreÚtypingr   Ú_typesr   Ú_TIME_RE_STRÚcompileÚVERBOSEÚ	RE_NUMBERÚRE_LOCALTIMEÚRE_DATETIMEr/   r   r;   r@   © r0   r.   ú<module>rM      s|  ğğ
 #Ğ "Ğ "Ğ "Ğ "Ğ "à FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FĞ FØ Ğ Ğ Ğ Ğ Ğ Ø 	€	€	€	Ø Ğ Ğ Ğ Ğ Ğ à Ğ Ğ Ğ Ğ Ğ ğ
 X€àˆBŒJğğ  Œ*ğ#ñ ô €	ğ& ˆrŒz˜,Ñ'Ô'€ØˆbŒjğğ ğ	ğ ğ ğ Œ*ğ
ñ 
ô 
€ğ Lğ  Lğ  Lğ  LğF €4ĞÑÔğğ ğ ñ ÔğğFğ Fğ Fğ Fğ!ğ !ğ !ğ !ğ !ğ !r0                                                                                                                                                                        usr/lib/python3.11/tomllib/__pycache__/_types.cpython-311.pyc                                       0000644 0000000 0000000 00000000544 14714551121 022332  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        §
    Nüäfş   ã                   óH   — d dl mZmZmZ eegef         Zeedf         ZeZdS )é    )ÚAnyÚCallableÚTuple.N)	Útypingr   r   r   ÚstrÚ
ParseFloatÚKeyÚintÚPos© ó    ú%/usr/lib/python3.11/tomllib/_types.pyú<module>r      sM   ğğ
 (Ğ 'Ğ 'Ğ 'Ğ 'Ğ 'Ğ 'Ğ 'Ğ 'Ğ 'ğ se˜SjÔ!€
ØˆCˆH„o€Ø	€€€r                                                                                                                                                               usr/lib/python3.11/tomllib/_parser.py                                                               0000644 0000000 0000000 00000054147 14671176116 016143  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # SPDX-License-Identifier: MIT
# SPDX-FileCopyrightText: 2021 Taneli Hukkinen
# Licensed to PSF under a Contributor Agreement.

from __future__ import annotations

from collections.abc import Iterable
import string
from types import MappingProxyType
from typing import Any, BinaryIO, NamedTuple

from ._re import (
    RE_DATETIME,
    RE_LOCALTIME,
    RE_NUMBER,
    match_to_datetime,
    match_to_localtime,
    match_to_number,
)
from ._types import Key, ParseFloat, Pos

ASCII_CTRL = frozenset(chr(i) for i in range(32)) | frozenset(chr(127))

# Neither of these sets include quotation mark or backslash. They are
# currently handled as separate cases in the parser functions.
ILLEGAL_BASIC_STR_CHARS = ASCII_CTRL - frozenset("\t")
ILLEGAL_MULTILINE_BASIC_STR_CHARS = ASCII_CTRL - frozenset("\t\n")

ILLEGAL_LITERAL_STR_CHARS = ILLEGAL_BASIC_STR_CHARS
ILLEGAL_MULTILINE_LITERAL_STR_CHARS = ILLEGAL_MULTILINE_BASIC_STR_CHARS

ILLEGAL_COMMENT_CHARS = ILLEGAL_BASIC_STR_CHARS

TOML_WS = frozenset(" \t")
TOML_WS_AND_NEWLINE = TOML_WS | frozenset("\n")
BARE_KEY_CHARS = frozenset(string.ascii_letters + string.digits + "-_")
KEY_INITIAL_CHARS = BARE_KEY_CHARS | frozenset("\"'")
HEXDIGIT_CHARS = frozenset(string.hexdigits)

BASIC_STR_ESCAPE_REPLACEMENTS = MappingProxyType(
    {
        "\\b": "\u0008",  # backspace
        "\\t": "\u0009",  # tab
        "\\n": "\u000A",  # linefeed
        "\\f": "\u000C",  # form feed
        "\\r": "\u000D",  # carriage return
        '\\"': "\u0022",  # quote
        "\\\\": "\u005C",  # backslash
    }
)


class TOMLDecodeError(ValueError):
    """An error raised if a document is not valid TOML."""


def load(fp: BinaryIO, /, *, parse_float: ParseFloat = float) -> dict[str, Any]:
    """Parse TOML from a binary file object."""
    b = fp.read()
    try:
        s = b.decode()
    except AttributeError:
        raise TypeError(
            "File must be opened in binary mode, e.g. use `open('foo.toml', 'rb')`"
        ) from None
    return loads(s, parse_float=parse_float)


def loads(s: str, /, *, parse_float: ParseFloat = float) -> dict[str, Any]:  # noqa: C901
    """Parse TOML from a string."""

    # The spec allows converting "\r\n" to "\n", even in string
    # literals. Let's do so to simplify parsing.
    src = s.replace("\r\n", "\n")
    pos = 0
    out = Output(NestedDict(), Flags())
    header: Key = ()
    parse_float = make_safe_parse_float(parse_float)

    # Parse one statement at a time
    # (typically means one line in TOML source)
    while True:
        # 1. Skip line leading whitespace
        pos = skip_chars(src, pos, TOML_WS)

        # 2. Parse rules. Expect one of the following:
        #    - end of file
        #    - end of line
        #    - comment
        #    - key/value pair
        #    - append dict to list (and move to its namespace)
        #    - create dict (and move to its namespace)
        # Skip trailing whitespace when applicable.
        try:
            char = src[pos]
        except IndexError:
            break
        if char == "\n":
            pos += 1
            continue
        if char in KEY_INITIAL_CHARS:
            pos = key_value_rule(src, pos, out, header, parse_float)
            pos = skip_chars(src, pos, TOML_WS)
        elif char == "[":
            try:
                second_char: str | None = src[pos + 1]
            except IndexError:
                second_char = None
            out.flags.finalize_pending()
            if second_char == "[":
                pos, header = create_list_rule(src, pos, out)
            else:
                pos, header = create_dict_rule(src, pos, out)
            pos = skip_chars(src, pos, TOML_WS)
        elif char != "#":
            raise suffixed_err(src, pos, "Invalid statement")

        # 3. Skip comment
        pos = skip_comment(src, pos)

        # 4. Expect end of line or end of file
        try:
            char = src[pos]
        except IndexError:
            break
        if char != "\n":
            raise suffixed_err(
                src, pos, "Expected newline or end of document after a statement"
            )
        pos += 1

    return out.data.dict


class Flags:
    """Flags that map to parsed keys/namespaces."""

    # Marks an immutable namespace (inline array or inline table).
    FROZEN = 0
    # Marks a nest that has been explicitly created and can no longer
    # be opened using the "[table]" syntax.
    EXPLICIT_NEST = 1

    def __init__(self) -> None:
        self._flags: dict[str, dict] = {}
        self._pending_flags: set[tuple[Key, int]] = set()

    def add_pending(self, key: Key, flag: int) -> None:
        self._pending_flags.add((key, flag))

    def finalize_pending(self) -> None:
        for key, flag in self._pending_flags:
            self.set(key, flag, recursive=False)
        self._pending_flags.clear()

    def unset_all(self, key: Key) -> None:
        cont = self._flags
        for k in key[:-1]:
            if k not in cont:
                return
            cont = cont[k]["nested"]
        cont.pop(key[-1], None)

    def set(self, key: Key, flag: int, *, recursive: bool) -> None:  # noqa: A003
        cont = self._flags
        key_parent, key_stem = key[:-1], key[-1]
        for k in key_parent:
            if k not in cont:
                cont[k] = {"flags": set(), "recursive_flags": set(), "nested": {}}
            cont = cont[k]["nested"]
        if key_stem not in cont:
            cont[key_stem] = {"flags": set(), "recursive_flags": set(), "nested": {}}
        cont[key_stem]["recursive_flags" if recursive else "flags"].add(flag)

    def is_(self, key: Key, flag: int) -> bool:
        if not key:
            return False  # document root has no flags
        cont = self._flags
        for k in key[:-1]:
            if k not in cont:
                return False
            inner_cont = cont[k]
            if flag in inner_cont["recursive_flags"]:
                return True
            cont = inner_cont["nested"]
        key_stem = key[-1]
        if key_stem in cont:
            cont = cont[key_stem]
            return flag in cont["flags"] or flag in cont["recursive_flags"]
        return False


class NestedDict:
    def __init__(self) -> None:
        # The parsed content of the TOML document
        self.dict: dict[str, Any] = {}

    def get_or_create_nest(
        self,
        key: Key,
        *,
        access_lists: bool = True,
    ) -> dict:
        cont: Any = self.dict
        for k in key:
            if k not in cont:
                cont[k] = {}
            cont = cont[k]
            if access_lists and isinstance(cont, list):
                cont = cont[-1]
            if not isinstance(cont, dict):
                raise KeyError("There is no nest behind this key")
        return cont

    def append_nest_to_list(self, key: Key) -> None:
        cont = self.get_or_create_nest(key[:-1])
        last_key = key[-1]
        if last_key in cont:
            list_ = cont[last_key]
            if not isinstance(list_, list):
                raise KeyError("An object other than list found behind this key")
            list_.append({})
        else:
            cont[last_key] = [{}]


class Output(NamedTuple):
    data: NestedDict
    flags: Flags


def skip_chars(src: str, pos: Pos, chars: Iterable[str]) -> Pos:
    try:
        while src[pos] in chars:
            pos += 1
    except IndexError:
        pass
    return pos


def skip_until(
    src: str,
    pos: Pos,
    expect: str,
    *,
    error_on: frozenset[str],
    error_on_eof: bool,
) -> Pos:
    try:
        new_pos = src.index(expect, pos)
    except ValueError:
        new_pos = len(src)
        if error_on_eof:
            raise suffixed_err(src, new_pos, f"Expected {expect!r}") from None

    if not error_on.isdisjoint(src[pos:new_pos]):
        while src[pos] not in error_on:
            pos += 1
        raise suffixed_err(src, pos, f"Found invalid character {src[pos]!r}")
    return new_pos


def skip_comment(src: str, pos: Pos) -> Pos:
    try:
        char: str | None = src[pos]
    except IndexError:
        char = None
    if char == "#":
        return skip_until(
            src, pos + 1, "\n", error_on=ILLEGAL_COMMENT_CHARS, error_on_eof=False
        )
    return pos


def skip_comments_and_array_ws(src: str, pos: Pos) -> Pos:
    while True:
        pos_before_skip = pos
        pos = skip_chars(src, pos, TOML_WS_AND_NEWLINE)
        pos = skip_comment(src, pos)
        if pos == pos_before_skip:
            return pos


