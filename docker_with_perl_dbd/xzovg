};

/*
 * The ib_uverbs_sge structure isn't used anywhere, since we assume
 * the ib_sge structure is packed the same way on 32-bit and 64-bit
 * architectures in both kernel and user space.  It's just here to
 * document the ABI.
 */
struct ib_uverbs_sge {
	__aligned_u64 addr;
	__u32 length;
	__u32 lkey;
};

enum ib_uverbs_wr_opcode {
	IB_UVERBS_WR_RDMA_WRITE = 0,
	IB_UVERBS_WR_RDMA_WRITE_WITH_IMM = 1,
	IB_UVERBS_WR_SEND = 2,
	IB_UVERBS_WR_SEND_WITH_IMM = 3,
	IB_UVERBS_WR_RDMA_READ = 4,
	IB_UVERBS_WR_ATOMIC_CMP_AND_SWP = 5,
	IB_UVERBS_WR_ATOMIC_FETCH_AND_ADD = 6,
	IB_UVERBS_WR_LOCAL_INV = 7,
	IB_UVERBS_WR_BIND_MW = 8,
	IB_UVERBS_WR_SEND_WITH_INV = 9,
	IB_UVERBS_WR_TSO = 10,
	IB_UVERBS_WR_RDMA_READ_WITH_INV = 11,
	IB_UVERBS_WR_MASKED_ATOMIC_CMP_AND_SWP = 12,
	IB_UVERBS_WR_MASKED_ATOMIC_FETCH_AND_ADD = 13,
	/* Review enum ib_wr_opcode before modifying this */
};

struct ib_uverbs_send_wr {
	__aligned_u64 wr_id;
	__u32 num_sge;
	__u32 opcode;		/* see enum ib_uverbs_wr_opcode */
	__u32 send_flags;
	union {
		__be32 imm_data;
		__u32 invalidate_rkey;
	} ex;
	union {
		struct {
			__aligned_u64 remote_addr;
			__u32 rkey;
			__u32 reserved;
		} rdma;
		struct {
			__aligned_u64 remote_addr;
			__aligned_u64 compare_add;
			__aligned_u64 swap;
			__u32 rkey;
			__u32 reserved;
		} atomic;
		struct {
			__u32 ah;
			__u32 remote_qpn;
			__u32 remote_qkey;
			__u32 reserved;
		} ud;
	} wr;
};

struct ib_uverbs_post_send {
	__aligned_u64 response;
	__u32 qp_handle;
	__u32 wr_count;
	__u32 sge_count;
	__u32 wqe_size;
	struct ib_uverbs_send_wr send_wr[];
};

struct ib_uverbs_post_send_resp {
	__u32 bad_wr;
};

struct ib_uverbs_recv_wr {
	__aligned_u64 wr_id;
	__u32 num_sge;
	__u32 reserved;
};

struct ib_uverbs_post_recv {
	__aligned_u64 response;
	__u32 qp_handle;
	__u32 wr_count;
	__u32 sge_count;
	__u32 wqe_size;
	struct ib_uverbs_recv_wr recv_wr[];
};

struct ib_uverbs_post_recv_resp {
	__u32 bad_wr;
};

struct ib_uverbs_post_srq_recv {
	__aligned_u64 response;
	__u32 srq_handle;
	__u32 wr_count;
	__u32 sge_count;
	__u32 wqe_size;
	struct ib_uverbs_recv_wr recv[];
};

struct ib_uverbs_post_srq_recv_resp {
	__u32 bad_wr;
};

struct ib_uverbs_create_ah {
	__aligned_u64 response;
	__aligned_u64 user_handle;
	__u32 pd_handle;
	__u32 reserved;
	struct ib_uverbs_ah_attr attr;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_create_ah_resp {
	__u32 ah_handle;
	__u32 driver_data[];
};

struct ib_uverbs_destroy_ah {
	__u32 ah_handle;
};

struct ib_uverbs_attach_mcast {
	__u8  gid[16];
	__u32 qp_handle;
	__u16 mlid;
	__u16 reserved;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_detach_mcast {
	__u8  gid[16];
	__u32 qp_handle;
	__u16 mlid;
	__u16 reserved;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_flow_spec_hdr {
	__u32 type;
	__u16 size;
	__u16 reserved;
	/* followed by flow_spec */
	__aligned_u64 flow_spec_data[0];
};

struct ib_uverbs_flow_eth_filter {
	__u8  dst_mac[6];
	__u8  src_mac[6];
	__be16 ether_type;
	__be16 vlan_tag;
};

struct ib_uverbs_flow_spec_eth {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_eth_filter val;
	struct ib_uverbs_flow_eth_filter mask;
};

struct ib_uverbs_flow_ipv4_filter {
	__be32 src_ip;
	__be32 dst_ip;
	__u8	proto;
	__u8	tos;
	__u8	ttl;
	__u8	flags;
};

struct ib_uverbs_flow_spec_ipv4 {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_ipv4_filter val;
	struct ib_uverbs_flow_ipv4_filter mask;
};

struct ib_uverbs_flow_tcp_udp_filter {
	__be16 dst_port;
	__be16 src_port;
};

struct ib_uverbs_flow_spec_tcp_udp {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_tcp_udp_filter val;
	struct ib_uverbs_flow_tcp_udp_filter mask;
};

struct ib_uverbs_flow_ipv6_filter {
	__u8    src_ip[16];
	__u8    dst_ip[16];
	__be32	flow_label;
	__u8	next_hdr;
	__u8	traffic_class;
	__u8	hop_limit;
	__u8	reserved;
};

struct ib_uverbs_flow_spec_ipv6 {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_ipv6_filter val;
	struct ib_uverbs_flow_ipv6_filter mask;
};

struct ib_uverbs_flow_spec_action_tag {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	__u32			      tag_id;
	__u32			      reserved1;
};

struct ib_uverbs_flow_spec_action_drop {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
};

struct ib_uverbs_flow_spec_action_handle {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	__u32			      handle;
	__u32			      reserved1;
};

struct ib_uverbs_flow_spec_action_count {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	__u32			      handle;
	__u32			      reserved1;
};

struct ib_uverbs_flow_tunnel_filter {
	__be32 tunnel_id;
};

struct ib_uverbs_flow_spec_tunnel {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_tunnel_filter val;
	struct ib_uverbs_flow_tunnel_filter mask;
};

struct ib_uverbs_flow_spec_esp_filter {
	__u32 spi;
	__u32 seq;
};

struct ib_uverbs_flow_spec_esp {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_spec_esp_filter val;
	struct ib_uverbs_flow_spec_esp_filter mask;
};

struct ib_uverbs_flow_gre_filter {
	/* c_ks_res0_ver field is bits 0-15 in offset 0 of a standard GRE header:
	 * bit 0 - C - checksum bit.
	 * bit 1 - reserved. set to 0.
	 * bit 2 - key bit.
	 * bit 3 - sequence number bit.
	 * bits 4:12 - reserved. set to 0.
	 * bits 13:15 - GRE version.
	 */
	__be16 c_ks_res0_ver;
	__be16 protocol;
	__be32 key;
};

struct ib_uverbs_flow_spec_gre {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_gre_filter     val;
	struct ib_uverbs_flow_gre_filter     mask;
};

struct ib_uverbs_flow_mpls_filter {
	/* The field includes the entire MPLS label:
	 * bits 0:19 - label field.
	 * bits 20:22 - traffic class field.
	 * bits 23 - bottom of stack bit.
	 * bits 24:31 - ttl field.
	 */
	__be32 label;
};

struct ib_uverbs_flow_spec_mpls {
	union {
		struct ib_uverbs_flow_spec_hdr hdr;
		struct {
			__u32 type;
			__u16 size;
			__u16 reserved;
		};
	};
	struct ib_uverbs_flow_mpls_filter     val;
	struct ib_uverbs_flow_mpls_filter     mask;
};

struct ib_uverbs_flow_attr {
	__u32 type;
	__u16 size;
	__u16 priority;
	__u8  num_of_specs;
	__u8  reserved[2];
	__u8  port;
	__u32 flags;
	/* Following are the optional layers according to user request
	 * struct ib_flow_spec_xxx
	 * struct ib_flow_spec_yyy
	 */
	struct ib_uverbs_flow_spec_hdr flow_specs[];
};

struct ib_uverbs_create_flow  {
	__u32 comp_mask;
	__u32 qp_handle;
	struct ib_uverbs_flow_attr flow_attr;
};

struct ib_uverbs_create_flow_resp {
	__u32 comp_mask;
	__u32 flow_handle;
};

struct ib_uverbs_destroy_flow  {
	__u32 comp_mask;
	__u32 flow_handle;
};

struct ib_uverbs_create_srq {
	__aligned_u64 response;
	__aligned_u64 user_handle;
	__u32 pd_handle;
	__u32 max_wr;
	__u32 max_sge;
	__u32 srq_limit;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_create_xsrq {
	__aligned_u64 response;
	__aligned_u64 user_handle;
	__u32 srq_type;
	__u32 pd_handle;
	__u32 max_wr;
	__u32 max_sge;
	__u32 srq_limit;
	__u32 max_num_tags;
	__u32 xrcd_handle;
	__u32 cq_handle;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_create_srq_resp {
	__u32 srq_handle;
	__u32 max_wr;
	__u32 max_sge;
	__u32 srqn;
	__u32 driver_data[];
};

struct ib_uverbs_modify_srq {
	__u32 srq_handle;
	__u32 attr_mask;
	__u32 max_wr;
	__u32 srq_limit;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_query_srq {
	__aligned_u64 response;
	__u32 srq_handle;
	__u32 reserved;
	__aligned_u64 driver_data[];
};

struct ib_uverbs_query_srq_resp {
	__u32 max_wr;
	__u32 max_sge;
	__u32 srq_limit;
	__u32 reserved;
};

struct ib_uverbs_destroy_srq {
	__aligned_u64 response;
	__u32 srq_handle;
	__u32 reserved;
};

struct ib_uverbs_destroy_srq_resp {
	__u32 events_reported;
};

struct ib_uverbs_ex_create_wq  {
	__u32 comp_mask;
	__u32 wq_type;
	__aligned_u64 user_handle;
	__u32 pd_handle;
	__u32 cq_handle;
	__u32 max_wr;
	__u32 max_sge;
	__u32 create_flags; /* Use enum ib_wq_flags */
	__u32 reserved;
};

struct ib_uverbs_ex_create_wq_resp {
	__u32 comp_mask;
	__u32 response_length;
	__u32 wq_handle;
	__u32 max_wr;
	__u32 max_sge;
	__u32 wqn;
};

struct ib_uverbs_ex_destroy_wq  {
	__u32 comp_mask;
	__u32 wq_handle;
};

struct ib_uverbs_ex_destroy_wq_resp {
	__u32 comp_mask;
	__u32 response_length;
	__u32 events_reported;
	__u32 reserved;
};

struct ib_uverbs_ex_modify_wq  {
	__u32 attr_mask;
	__u32 wq_handle;
	__u32 wq_state;
	__u32 curr_wq_state;
	__u32 flags; /* Use enum ib_wq_flags */
	__u32 flags_mask; /* Use enum ib_wq_flags */
};

/* Prevent memory allocation rather than max expected size */
#define IB_USER_VERBS_MAX_LOG_IND_TBL_SIZE 0x0d
struct ib_uverbs_ex_create_rwq_ind_table  {
	__u32 comp_mask;
	__u32 log_ind_tbl_size;
	/* Following are the wq handles according to log_ind_tbl_size
	 * wq_handle1
	 * wq_handle2
	 */
	__u32 wq_handles[];
};

struct ib_uverbs_ex_create_rwq_ind_table_resp {
	__u32 comp_mask;
	__u32 response_length;
	__u32 ind_tbl_handle;
	__u32 ind_tbl_num;
};

struct ib_uverbs_ex_destroy_rwq_ind_table  {
	__u32 comp_mask;
	__u32 ind_tbl_handle;
};

struct ib_uverbs_cq_moderation {
	__u16 cq_count;
	__u16 cq_period;
};

struct ib_uverbs_ex_modify_cq {
	__u32 cq_handle;
	__u32 attr_mask;
	struct ib_uverbs_cq_moderation attr;
	__u32 reserved;
};

#define IB_DEVICE_NAME_MAX 64

/*
 * bits 9, 15, 16, 19, 22, 27, 30, 31, 32, 33, 35 and 37 may be set by old
 * kernels and should not be used.
 */
enum ib_uverbs_device_cap_flags {
	IB_UVERBS_DEVICE_RESIZE_MAX_WR = 1 << 0,
	IB_UVERBS_DEVICE_BAD_PKEY_CNTR = 1 << 1,
	IB_UVERBS_DEVICE_BAD_QKEY_CNTR = 1 << 2,
	IB_UVERBS_DEVICE_RAW_MULTI = 1 << 3,
	IB_UVERBS_DEVICE_AUTO_PATH_MIG = 1 << 4,
	IB_UVERBS_DEVICE_CHANGE_PHY_PORT = 1 << 5,
	IB_UVERBS_DEVICE_UD_AV_PORT_ENFORCE = 1 << 6,
	IB_UVERBS_DEVICE_CURR_QP_STATE_MOD = 1 << 7,
	IB_UVERBS_DEVICE_SHUTDOWN_PORT = 1 << 8,
	/* IB_UVERBS_DEVICE_INIT_TYPE = 1 << 9, (not in use) */
	IB_UVERBS_DEVICE_PORT_ACTIVE_EVENT = 1 << 10,
	IB_UVERBS_DEVICE_SYS_IMAGE_GUID = 1 << 11,
	IB_UVERBS_DEVICE_RC_RNR_NAK_GEN = 1 << 12,
	IB_UVERBS_DEVICE_SRQ_RESIZE = 1 << 13,
	IB_UVERBS_DEVICE_N_NOTIFY_CQ = 1 << 14,
	IB_UVERBS_DEVICE_MEM_WINDOW = 1 << 17,
	IB_UVERBS_DEVICE_UD_IP_CSUM = 1 << 18,
	IB_UVERBS_DEVICE_XRC = 1 << 20,
	IB_UVERBS_DEVICE_MEM_MGT_EXTENSIONS = 1 << 21,
	IB_UVERBS_DEVICE_MEM_WINDOW_TYPE_2A = 1 << 23,
	IB_UVERBS_DEVICE_MEM_WINDOW_TYPE_2B = 1 << 24,
	IB_UVERBS_DEVICE_RC_IP_CSUM = 1 << 25,
	/* Deprecated. Please use IB_UVERBS_RAW_PACKET_CAP_IP_CSUM. */
	IB_UVERBS_DEVICE_RAW_IP_CSUM = 1 << 26,
	IB_UVERBS_DEVICE_MANAGED_FLOW_STEERING = 1 << 29,
	/* Deprecated. Please use IB_UVERBS_RAW_PACKET_CAP_SCATTER_FCS. */
	IB_UVERBS_DEVICE_RAW_SCATTER_FCS = 1ULL << 34,
	IB_UVERBS_DEVICE_PCI_WRITE_END_PADDING = 1ULL << 36,
};

enum ib_uverbs_raw_packet_caps {
	IB_UVERBS_RAW_PACKET_CAP_CVLAN_STRIPPING = 1 << 0,
	IB_UVERBS_RAW_PACKET_CAP_SCATTER_FCS = 1 << 1,
	IB_UVERBS_RAW_PACKET_CAP_IP_CSUM = 1 << 2,
	IB_UVERBS_RAW_PACKET_CAP_DELAY_DROP = 1 << 3,
};

#endif /* IB_USER_VERBS_H */
                                                                                                                                                                                                                                                                    usr/include/rdma/irdma-abi.h                                                                        0000644 0000000 0000000 00000004370 14711053711 014425  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        /* SPDX-License-Identifier: (GPL-2.0 WITH Linux-syscall-note) OR Linux-OpenIB */
/*
 * Copyright (c) 2006 - 2021 Intel Corporation.  All rights reserved.
 * Copyright (c) 2005 Topspin Communications.  All rights reserved.
 * Copyright (c) 2005 Cisco Systems.  All rights reserved.
 * Copyright (c) 2005 Open Grid Computing, Inc. All rights reserved.
 */

#ifndef IRDMA_ABI_H
#define IRDMA_ABI_H

#include <linux/types.h>

/* irdma must support legacy GEN_1 i40iw kernel
 * and user-space whose last ABI ver is 5
 */
#define IRDMA_ABI_VER 5

enum irdma_memreg_type {
	IRDMA_MEMREG_TYPE_MEM  = 0,
	IRDMA_MEMREG_TYPE_QP   = 1,
	IRDMA_MEMREG_TYPE_CQ   = 2,
};

enum {
	IRDMA_ALLOC_UCTX_USE_RAW_ATTR = 1 << 0,
};

struct irdma_alloc_ucontext_req {
	__u32 rsvd32;
	__u8 userspace_ver;
	__u8 rsvd8[3];
	__aligned_u64 comp_mask;
};

struct irdma_alloc_ucontext_resp {
	__u32 max_pds;
	__u32 max_qps;
	__u32 wq_size; /* size of the WQs (SQ+RQ) in the mmaped area */
	__u8 kernel_ver;
	__u8 rsvd[3];
	__aligned_u64 feature_flags;
	__aligned_u64 db_mmap_key;
	__u32 max_hw_wq_frags;
	__u32 max_hw_read_sges;
	__u32 max_hw_inline;
	__u32 max_hw_rq_quanta;
	__u32 max_hw_wq_quanta;
	__u32 min_hw_cq_size;
	__u32 max_hw_cq_size;
	__u16 max_hw_sq_chunk;
	__u8 hw_rev;
	__u8 rsvd2;
	__aligned_u64 comp_mask;
};

struct irdma_alloc_pd_resp {
	__u32 pd_id;
	__u8 rsvd[4];
};

struct irdma_resize_cq_req {
	__aligned_u64 user_cq_buffer;
};

struct irdma_create_cq_req {
	__aligned_u64 user_cq_buf;
	__aligned_u64 user_shadow_area;
};

struct irdma_create_qp_req {
	__aligned_u64 user_wqe_bufs;
	__aligned_u64 user_compl_ctx;
};

struct irdma_mem_reg_req {
	__u16 reg_type; /* enum irdma_memreg_type */
	__u16 cq_pages;
	__u16 rq_pages;
	__u16 sq_pages;
};

struct irdma_modify_qp_req {
	__u8 sq_flush;
	__u8 rq_flush;
	__u8 rsvd[6];
};

struct irdma_create_cq_resp {
	__u32 cq_id;
	__u32 cq_size;
};

struct irdma_create_qp_resp {
	__u32 qp_id;
	__u32 actual_sq_size;
	__u32 actual_rq_size;
	__u32 irdma_drv_opt;
	__u16 push_idx;
	__u8 lsmm;
	__u8 rsvd;
	__u32 qp_caps;
};

struct irdma_modify_qp_resp {
	__aligned_u64 push_wqe_mmap_key;
	__aligned_u64 push_db_mmap_key;
	__u16 push_offset;
	__u8 push_valid;
	__u8 rsvd[5];
};

struct irdma_create_ah_resp {
	__u32 ah_id;
	__u8 rsvd[4];
};
#endif /* IRDMA_ABI_H */
                                                                                                                                                                                                                                                                        usr/include/rdma/mlx4-abi.h                                                                         0000644 0000000 0000000 00000011775 14711053711 014224  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        /* SPDX-License-Identifier: ((GPL-2.0 WITH Linux-syscall-note) OR Linux-OpenIB) */
/*
 * Copyright (c) 2007 Cisco Systems, Inc. All rights reserved.
 * Copyright (c) 2007, 2008 Mellanox Technologies. All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *      - Redistributions of source code must retain the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer.
 *
 *      - Redistributions in binary form must reproduce the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer in the documentation and/or other materials
 *        provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX4_ABI_USER_H
#define MLX4_ABI_USER_H

#include <linux/types.h>

/*
 * Increment this value if any changes that break userspace ABI
 * compatibility are made.
 */

#define MLX4_IB_UVERBS_NO_DEV_CAPS_ABI_VERSION	3
#define MLX4_IB_UVERBS_ABI_VERSION		4

/*
 * Make sure that all structs defined in this file remain laid out so
 * that they pack the same way on 32-bit and 64-bit architectures (to
 * avoid incompatibility between 32-bit userspace and 64-bit kernels).
 * In particular do not use pointer types -- pass pointers in __u64
 * instead.
 */

struct mlx4_ib_alloc_ucontext_resp_v3 {
	__u32	qp_tab_size;
	__u16	bf_reg_size;
	__u16	bf_regs_per_page;
};

enum {
	MLX4_USER_DEV_CAP_LARGE_CQE	= 1L << 0,
};

struct mlx4_ib_alloc_ucontext_resp {
	__u32	dev_caps;
	__u32	qp_tab_size;
	__u16	bf_reg_size;
	__u16	bf_regs_per_page;
	__u32	cqe_size;
};

struct mlx4_ib_alloc_pd_resp {
	__u32	pdn;
	__u32	reserved;
};

struct mlx4_ib_create_cq {
	__aligned_u64 buf_addr;
	__aligned_u64 db_addr;
};

struct mlx4_ib_create_cq_resp {
	__u32	cqn;
	__u32	reserved;
};

struct mlx4_ib_resize_cq {
	__aligned_u64 buf_addr;
};

struct mlx4_ib_create_srq {
	__aligned_u64 buf_addr;
	__aligned_u64 db_addr;
};

struct mlx4_ib_create_srq_resp {
	__u32	srqn;
	__u32	reserved;
};

struct mlx4_ib_create_qp_rss {
	__aligned_u64 rx_hash_fields_mask; /* Use  enum mlx4_ib_rx_hash_fields */
	__u8    rx_hash_function; /* Use enum mlx4_ib_rx_hash_function_flags */
	__u8    reserved[7];
	__u8    rx_hash_key[40];
	__u32   comp_mask;
	__u32   reserved1;
};

struct mlx4_ib_create_qp {
	__aligned_u64 buf_addr;
	__aligned_u64 db_addr;
	__u8	log_sq_bb_count;
	__u8	log_sq_stride;
	__u8	sq_no_prefetch;
	__u8	reserved;
	__u32	inl_recv_sz;
};

struct mlx4_ib_create_wq {
	__aligned_u64 buf_addr;
	__aligned_u64 db_addr;
	__u8	log_range_size;
	__u8	reserved[3];
	__u32   comp_mask;
};

struct mlx4_ib_modify_wq {
	__u32	comp_mask;
	__u32	reserved;
};

struct mlx4_ib_create_rwq_ind_tbl_resp {
	__u32	response_length;
	__u32	reserved;
};

/* RX Hash function flags */
enum mlx4_ib_rx_hash_function_flags {
	MLX4_IB_RX_HASH_FUNC_TOEPLITZ	= 1 << 0,
};

/*
 * RX Hash flags, these flags allows to set which incoming packet's field should
 * participates in RX Hash. Each flag represent certain packet's field,
 * when the flag is set the field that is represented by the flag will
 * participate in RX Hash calculation.
 */
enum mlx4_ib_rx_hash_fields {
	MLX4_IB_RX_HASH_SRC_IPV4	= 1 << 0,
	MLX4_IB_RX_HASH_DST_IPV4	= 1 << 1,
	MLX4_IB_RX_HASH_SRC_IPV6	= 1 << 2,
	MLX4_IB_RX_HASH_DST_IPV6	= 1 << 3,
	MLX4_IB_RX_HASH_SRC_PORT_TCP	= 1 << 4,
	MLX4_IB_RX_HASH_DST_PORT_TCP	= 1 << 5,
	MLX4_IB_RX_HASH_SRC_PORT_UDP	= 1 << 6,
	MLX4_IB_RX_HASH_DST_PORT_UDP	= 1 << 7,
	MLX4_IB_RX_HASH_INNER		= 1ULL << 31,
};

struct mlx4_ib_rss_caps {
	__aligned_u64 rx_hash_fields_mask; /* enum mlx4_ib_rx_hash_fields */
	__u8 rx_hash_function; /* enum mlx4_ib_rx_hash_function_flags */
	__u8 reserved[7];
};

enum query_device_resp_mask {
	MLX4_IB_QUERY_DEV_RESP_MASK_CORE_CLOCK_OFFSET = 1UL << 0,
};

struct mlx4_ib_tso_caps {
	__u32 max_tso; /* Maximum tso payload size in bytes */
	/* Corresponding bit will be set if qp type from
	 * 'enum ib_qp_type' is supported.
	 */
	__u32 supported_qpts;
};

struct mlx4_uverbs_ex_query_device_resp {
	__u32			comp_mask;
	__u32			response_length;
	__aligned_u64		hca_core_clock_offset;
	__u32			max_inl_recv_sz;
	__u32			reserved;
	struct mlx4_ib_rss_caps	rss_caps;
	struct mlx4_ib_tso_caps tso_caps;
};

#endif /* MLX4_ABI_USER_H */
   usr/include/rdma/mlx5-abi.h                                                                         0000644 0000000 0000000 00000033055 14711053711 014220  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        /* SPDX-License-Identifier: ((GPL-2.0 WITH Linux-syscall-note) OR Linux-OpenIB) */
/*
 * Copyright (c) 2013-2015, Mellanox Technologies. All rights reserved.
 *
 * This software is available to you under a choice of one of two
 * licenses.  You may choose to be licensed under the terms of the GNU
 * General Public License (GPL) Version 2, available from the file
 * COPYING in the main directory of this source tree, or the
 * OpenIB.org BSD license below:
 *
 *     Redistribution and use in source and binary forms, with or
 *     without modification, are permitted provided that the following
 *     conditions are met:
 *
 *      - Redistributions of source code must retain the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer.
 *
 *      - Redistributions in binary form must reproduce the above
 *        copyright notice, this list of conditions and the following
 *        disclaimer in the documentation and/or other materials
 *        provided with the distribution.
 *
 * THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND,
 * EXPRESS OR IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF
 * MERCHANTABILITY, FITNESS FOR A PARTICULAR PURPOSE AND
 * NONINFRINGEMENT. IN NO EVENT SHALL THE AUTHORS OR COPYRIGHT HOLDERS
 * BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER LIABILITY, WHETHER IN AN
 * ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM, OUT OF OR IN
 * CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
 * SOFTWARE.
 */

#ifndef MLX5_ABI_USER_H
#define MLX5_ABI_USER_H

#include <linux/types.h>
#include <linux/if_ether.h>	/* For ETH_ALEN. */
#include <rdma/ib_user_ioctl_verbs.h>

enum {
	MLX5_QP_FLAG_SIGNATURE		= 1 << 0,
	MLX5_QP_FLAG_SCATTER_CQE	= 1 << 1,
	MLX5_QP_FLAG_TUNNEL_OFFLOADS	= 1 << 2,
	MLX5_QP_FLAG_BFREG_INDEX	= 1 << 3,
	MLX5_QP_FLAG_TYPE_DCT		= 1 << 4,
	MLX5_QP_FLAG_TYPE_DCI		= 1 << 5,
	MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_UC = 1 << 6,
	MLX5_QP_FLAG_TIR_ALLOW_SELF_LB_MC = 1 << 7,
	MLX5_QP_FLAG_ALLOW_SCATTER_CQE	= 1 << 8,
	MLX5_QP_FLAG_PACKET_BASED_CREDIT_MODE	= 1 << 9,
	MLX5_QP_FLAG_UAR_PAGE_INDEX = 1 << 10,
	MLX5_QP_FLAG_DCI_STREAM	= 1 << 11,
};

enum {
	MLX5_SRQ_FLAG_SIGNATURE		= 1 << 0,
};

enum {
	MLX5_WQ_FLAG_SIGNATURE		= 1 << 0,
};

/* Increment this value if any changes that break userspace ABI
 * compatibility are made.
 */
#define MLX5_IB_UVERBS_ABI_VERSION	1

/* Make sure that all structs defined in this file remain laid out so
 * that they pack the same way on 32-bit and 64-bit architectures (to
 * avoid incompatibility between 32-bit userspace and 64-bit kernels).
 * In particular do not use pointer types -- pass pointers in __u64
 * instead.
 */

struct mlx5_ib_alloc_ucontext_req {
	__u32	total_num_bfregs;
	__u32	num_low_latency_bfregs;
};

enum mlx5_lib_caps {
	MLX5_LIB_CAP_4K_UAR	= (__u64)1 << 0,
	MLX5_LIB_CAP_DYN_UAR	= (__u64)1 << 1,
};

enum mlx5_ib_alloc_uctx_v2_flags {
	MLX5_IB_ALLOC_UCTX_DEVX	= 1 << 0,
};
struct mlx5_ib_alloc_ucontext_req_v2 {
	__u32	total_num_bfregs;
	__u32	num_low_latency_bfregs;
	__u32	flags;
	__u32	comp_mask;
	__u8	max_cqe_version;
	__u8	reserved0;
	__u16	reserved1;
	__u32	reserved2;
	__aligned_u64 lib_caps;
};

enum mlx5_ib_alloc_ucontext_resp_mask {
	MLX5_IB_ALLOC_UCONTEXT_RESP_MASK_CORE_CLOCK_OFFSET = 1UL << 0,
	MLX5_IB_ALLOC_UCONTEXT_RESP_MASK_DUMP_FILL_MKEY    = 1UL << 1,
	MLX5_IB_ALLOC_UCONTEXT_RESP_MASK_ECE               = 1UL << 2,
	MLX5_IB_ALLOC_UCONTEXT_RESP_MASK_SQD2RTS           = 1UL << 3,
	MLX5_IB_ALLOC_UCONTEXT_RESP_MASK_REAL_TIME_TS	   = 1UL << 4,
