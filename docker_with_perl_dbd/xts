The class has methods using which the data can be stored to disk in a file under
.hg/ directory.

We store the data on disk in cbor, for which we use the CBOR format to encode
the data.
"""


import contextlib

from .i18n import _

from . import (
    error,
    pycompat,
    util,
)
from .utils import cborutil

if pycompat.TYPE_CHECKING:
    from typing import (
        Any,
        Dict,
    )

    for t in (Any, Dict):
        assert t


class cmdstate:
    """a wrapper class to store the state of commands like `rebase`, `graft`,
    `histedit`, `shelve` etc. Extensions can also use this to write state files.

    All the data for the state is stored in the form of key-value pairs in a
    dictionary.

    The class object can write all the data to a file in .hg/ directory and
    can populate the object data reading that file.

    Uses cbor to serialize and deserialize data while writing and reading from
    disk.
    """

    def __init__(self, repo, fname):
        """repo is the repo object
        fname is the file name in which data should be stored in .hg directory
        """
        self._repo = repo
        self.fname = fname

    def read(self):
        # type: () -> Dict[bytes, Any]
        """read the existing state file and return a dict of data stored"""
        return self._read()

    def save(self, version, data):
        """write all the state data stored to .hg/<filename> file

        we use third-party library cbor to serialize data to write in the file.
        """
        if not isinstance(version, int):
            raise error.ProgrammingError(
                b"version of state file should be an integer"
            )

        with self._repo.vfs(self.fname, b'wb', atomictemp=True) as fp:
            fp.write(b'%d\n' % version)
            for chunk in cborutil.streamencode(data):
                fp.write(chunk)

    def _read(self):
        """reads the state file and returns a dictionary which contain
        data in the same format as it was before storing"""
        with self._repo.vfs(self.fname, b'rb') as fp:
            try:
                int(fp.readline())
            except ValueError:
                raise error.CorruptedState(
                    b"unknown version of state file found"
                )

            return cborutil.decodeall(fp.read())[0]

    def delete(self):
        """drop the state file if exists"""
        util.unlinkpath(self._repo.vfs.join(self.fname), ignoremissing=True)

    def exists(self):
        """check whether the state file exists or not"""
        return self._repo.vfs.exists(self.fname)


class _statecheck:
    """a utility class that deals with multistep operations like graft,
    histedit, bisect, update etc and check whether such commands
    are in an unfinished conditition or not and return appropriate message
    and hint.
    It also has the ability to register and determine the states of any new
    multistep operation or multistep command extension.
    """

    def __init__(
        self,
        opname,
        fname,
        clearable,
        allowcommit,
        reportonly,
        continueflag,
        stopflag,
        childopnames,
        cmdmsg,
        cmdhint,
        statushint,
        abortfunc,
        continuefunc,
    ):
        self._opname = opname
        self._fname = fname
        self._clearable = clearable
        self._allowcommit = allowcommit
        self._reportonly = reportonly
        self._continueflag = continueflag
        self._stopflag = stopflag
        self._childopnames = childopnames
        self._delegating = False
        self._cmdmsg = cmdmsg
        self._cmdhint = cmdhint
        self._statushint = statushint
        self.abortfunc = abortfunc
        self.continuefunc = continuefunc

    def statusmsg(self):
        """returns the hint message corresponding to the command for
        hg status --verbose
        """
        if not self._statushint:
            hint = _(
                b'To continue:    hg %s --continue\n'
                b'To abort:       hg %s --abort'
            ) % (self._opname, self._opname)
            if self._stopflag:
                hint = hint + (
                    _(b'\nTo stop:        hg %s --stop') % (self._opname)
                )
            return hint
        return self._statushint

    def hint(self):
        """returns the hint message corresponding to an interrupted
        operation
        """
        if not self._cmdhint:
            if not self._stopflag:
                return _(b"use 'hg %s --continue' or 'hg %s --abort'") % (
                    self._opname,
                    self._opname,
                )
            else:
                return _(
                    b"use 'hg %s --continue', 'hg %s --abort', "
                    b"or 'hg %s --stop'"
                ) % (
                    self._opname,
                    self._opname,
                    self._opname,
                )

        return self._cmdhint

    def msg(self):
        """returns the status message corresponding to the command"""
        if not self._cmdmsg:
            return _(b'%s in progress') % (self._opname)
        return self._cmdmsg

    def continuemsg(self):
        """returns appropriate continue message corresponding to command"""
        return _(b'hg %s --continue') % (self._opname)

    def isunfinished(self, repo):
        """determines whether a multi-step operation is in progress
        or not
        """
        if self._opname == b'merge':
            return len(repo[None].parents()) > 1
        elif self._delegating:
            return False
        else:
            return repo.vfs.exists(self._fname)


# A list of statecheck objects for multistep operations like graft.
_unfinishedstates = []
_unfinishedstatesbyname = {}


def addunfinished(
    opname,
    fname,
    clearable=False,
    allowcommit=False,
    reportonly=False,
    continueflag=False,
    stopflag=False,
    childopnames=None,
    cmdmsg=b"",
    cmdhint=b"",
    statushint=b"",
    abortfunc=None,
    continuefunc=None,
):
    """this registers a new command or operation to unfinishedstates
    opname is the name the command or operation
    fname is the file name in which data should be stored in .hg directory.
    It is None for merge command.
    clearable boolean determines whether or not interrupted states can be
    cleared by running `hg update -C .` which in turn deletes the
    state file.
    allowcommit boolean decides whether commit is allowed during interrupted
    state or not.
    reportonly flag is used for operations like bisect where we just
    need to detect the operation using 'hg status --verbose'
    continueflag is a boolean determines whether or not a command supports
    `--continue` option or not.
    stopflag is a boolean that determines whether or not a command supports
    --stop flag
    childopnames is a list of other opnames this op uses as sub-steps of its
    own execution. They must already be added.
    cmdmsg is used to pass a different status message in case standard
    message of the format "abort: cmdname in progress" is not desired.
    cmdhint is used to pass a different hint message in case standard
    message of the format "To continue: hg cmdname --continue
    To abort: hg cmdname --abort" is not desired.
    statushint is used to pass a different status message in case standard
    message of the format ('To continue:    hg cmdname --continue'
    'To abort:       hg cmdname --abort') is not desired
    abortfunc stores the function required to abort an unfinished state.
    continuefunc stores the function required to finish an interrupted
    operation.
    """
    childopnames = childopnames or []
    statecheckobj = _statecheck(
        opname,
        fname,
        clearable,
        allowcommit,
        reportonly,
        continueflag,
        stopflag,
        childopnames,
        cmdmsg,
        cmdhint,
        statushint,
        abortfunc,
        continuefunc,
    )

    if opname == b'merge':
        _unfinishedstates.append(statecheckobj)
    else:
        # This check enforces that for any op 'foo' which depends on op 'bar',
        # 'foo' comes before 'bar' in _unfinishedstates. This ensures that
        # getrepostate() always returns the most specific applicable answer.
        for childopname in childopnames:
            if childopname not in _unfinishedstatesbyname:
                raise error.ProgrammingError(
                    _(b'op %s depends on unknown op %s') % (opname, childopname)
                )

        _unfinishedstates.insert(0, statecheckobj)

    if opname in _unfinishedstatesbyname:
        raise error.ProgrammingError(_(b'op %s registered twice') % opname)
    _unfinishedstatesbyname[opname] = statecheckobj


def _getparentandchild(opname, childopname):
    p = _unfinishedstatesbyname.get(opname, None)
    if not p:
        raise error.ProgrammingError(_(b'unknown op %s') % opname)
    if childopname not in p._childopnames:
        raise error.ProgrammingError(
            _(b'op %s does not delegate to %s') % (opname, childopname)
        )
    c = _unfinishedstatesbyname[childopname]
    return p, c


@contextlib.contextmanager
def delegating(repo, opname, childopname):
    """context wrapper for delegations from opname to childopname.

    requires that childopname was specified when opname was registered.

    Usage:
      def my_command_foo_that_uses_rebase(...):
        ...
        with state.delegating(repo, 'foo', 'rebase'):
          _run_rebase(...)
        ...
    """

    p, c = _getparentandchild(opname, childopname)
    if p._delegating:
        raise error.ProgrammingError(
            _(b'cannot delegate from op %s recursively') % opname
        )
    p._delegating = True
    try:
        yield
    except error.ConflictResolutionRequired as e:
        # Rewrite conflict resolution advice for the parent opname.
        if e.opname == childopname:
            raise error.ConflictResolutionRequired(opname)
        raise e
    finally:
        p._delegating = False


def ischildunfinished(repo, opname, childopname):
    """Returns true if both opname and childopname are unfinished."""

    p, c = _getparentandchild(opname, childopname)
    return (p._delegating or p.isunfinished(repo)) and c.isunfinished(repo)


def continuechild(ui, repo, opname, childopname):
    """Checks that childopname is in progress, and continues it."""

    p, c = _getparentandchild(opname, childopname)
    if not ischildunfinished(repo, opname, childopname):
        raise error.ProgrammingError(
            _(b'child op %s of parent %s is not unfinished')
            % (childopname, opname)
        )
    if not c.continuefunc:
        raise error.ProgrammingError(
            _(b'op %s has no continue function') % childopname
        )
    return c.continuefunc(ui, repo)


addunfinished(
    b'update',
    fname=b'updatestate',
    clearable=True,
    cmdmsg=_(b'last update was interrupted'),
    cmdhint=_(b"use 'hg update' to get a consistent checkout"),
    statushint=_(b"To continue:    hg update ."),
)
addunfinished(
    b'bisect',
    fname=b'bisect.state',
    allowcommit=True,
    reportonly=True,
    cmdhint=_(b"use 'hg bisect --reset'"),
    statushint=_(
        b'To mark the changeset good:    hg bisect --good\n'
        b'To mark the changeset bad:     hg bisect --bad\n'
        b'To abort:                      hg bisect --reset\n'
    ),
)


def getrepostate(repo):
    # experimental config: commands.status.skipstates
    skip = set(repo.ui.configlist(b'commands', b'status.skipstates'))
    for state in _unfinishedstates:
        if state._opname in skip:
            continue
        if state.isunfinished(repo):
            return (state._opname, state.statusmsg())
                         usr/lib/python3/dist-packages/mercurial/statichttprepo.py                                           0000644 0000000 0000000 00000017367 14355257011 022401  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # statichttprepo.py - simple http repository class for mercurial
#
# This provides read-only repo access to repositories exported via static http
#
# Copyright 2005-2007 Olivia Mackall <olivia@selenic.com>
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


import errno

from .i18n import _
from .node import sha1nodeconstants
from . import (
    branchmap,
    changelog,
    error,
    localrepo,
    manifest,
    namespaces,
    pathutil,
    pycompat,
    requirements as requirementsmod,
    url,
    util,
    vfs as vfsmod,
)
from .utils import (
    urlutil,
)

urlerr = util.urlerr
urlreq = util.urlreq


class httprangereader:
    def __init__(self, url, opener):
        # we assume opener has HTTPRangeHandler
        self.url = url
        self.pos = 0
        self.opener = opener
        self.name = url

    def __enter__(self):
        return self

    def __exit__(self, exc_type, exc_value, traceback):
        self.close()

    def seek(self, pos):
        self.pos = pos

    def read(self, bytes=None):
        req = urlreq.request(pycompat.strurl(self.url))
        end = b''
        if bytes:
            end = self.pos + bytes - 1
        if self.pos or end:
            req.add_header('Range', 'bytes=%d-%s' % (self.pos, end))

        try:
            f = self.opener.open(req)
            data = f.read()
            code = f.code
        except urlerr.httperror as inst:
            num = inst.code == 404 and errno.ENOENT or None
            # Explicitly convert the exception to str as Py3 will try
            # convert it to local encoding and with as the HTTPResponse
            # instance doesn't support encode.
            raise IOError(num, str(inst))
        except urlerr.urlerror as inst:
            raise IOError(None, inst.reason)

        if code == 200:
            # HTTPRangeHandler does nothing if remote does not support
            # Range headers and returns the full entity. Let's slice it.
            if bytes:
                data = data[self.pos : self.pos + bytes]
            else:
                data = data[self.pos :]
        elif bytes:
            data = data[:bytes]
        self.pos += len(data)
        return data

    def readlines(self):
        return self.read().splitlines(True)

    def __iter__(self):
        return iter(self.readlines())

    def close(self):
        pass


# _RangeError and _HTTPRangeHandler were originally in byterange.py,
# which was itself extracted from urlgrabber. See the last version of
# byterange.py from history if you need more information.
class _RangeError(IOError):
    """Error raised when an unsatisfiable range is requested."""


class _HTTPRangeHandler(urlreq.basehandler):
    """Handler that enables HTTP Range headers.

    This was extremely simple. The Range header is a HTTP feature to
    begin with so all this class does is tell urllib2 that the
    "206 Partial Content" response from the HTTP server is what we
    expected.
    """

    def http_error_206(self, req, fp, code, msg, hdrs):
        # 206 Partial Content Response
        r = urlreq.addinfourl(fp, hdrs, req.get_full_url())
        r.code = code
        r.msg = msg
        return r

    def http_error_416(self, req, fp, code, msg, hdrs):
        # HTTP's Range Not Satisfiable error
        raise _RangeError(b'Requested Range Not Satisfiable')


def build_opener(ui, authinfo):
    # urllib cannot handle URLs with embedded user or passwd
    urlopener = url.opener(ui, authinfo)
    urlopener.add_handler(_HTTPRangeHandler())

    class statichttpvfs(vfsmod.abstractvfs):
        def __init__(self, base):
            self.base = base
            self.options = {}

        def __call__(self, path, mode=b'r', *args, **kw):
            if mode not in (b'r', b'rb'):
                raise IOError(b'Permission denied')
            f = b"/".join((self.base, urlreq.quote(path)))
            return httprangereader(f, urlopener)

        def join(self, path):
            if path:
                return pathutil.join(self.base, path)
            else:
                return self.base

    return statichttpvfs


class statichttppeer(localrepo.localpeer):
    def local(self):
        return None

    def canpush(self):
        return False


class statichttprepository(
    localrepo.localrepository, localrepo.revlogfilestorage
):
    supported = localrepo.localrepository._basesupported

    def __init__(self, ui, path):
        self._url = path
        self.ui = ui

        self.root = path
        u = urlutil.url(path.rstrip(b'/') + b"/.hg")
        self.path, authinfo = u.authinfo()

        vfsclass = build_opener(ui, authinfo)
        self.vfs = vfsclass(self.path)
        self.cachevfs = vfsclass(self.vfs.join(b'cache'))
        self._phasedefaults = []

        self.names = namespaces.namespaces()
        self.filtername = None
        self._extrafilterid = None
        self._wanted_sidedata = set()
        self.features = set()

        try:
            requirements = set(self.vfs.read(b'requires').splitlines())
        except FileNotFoundError:
            requirements = set()

            # check if it is a non-empty old-style repository
            try:
                fp = self.vfs(b"00changelog.i")
                fp.read(1)
                fp.close()
            except FileNotFoundError:
                # we do not care about empty old-style repositories here
                msg = _(b"'%s' does not appear to be an hg repository") % path
                raise error.RepoError(msg)
        if requirementsmod.SHARESAFE_REQUIREMENT in requirements:
            storevfs = vfsclass(self.vfs.join(b'store'))
            requirements |= set(storevfs.read(b'requires').splitlines())

        supportedrequirements = localrepo.gathersupportedrequirements(ui)
        localrepo.ensurerequirementsrecognized(
            requirements, supportedrequirements
        )
        localrepo.ensurerequirementscompatible(ui, requirements)
        self.nodeconstants = sha1nodeconstants
        self.nullid = self.nodeconstants.nullid

        # setup store
        self.store = localrepo.makestore(requirements, self.path, vfsclass)
        self.spath = self.store.path
        self.svfs = self.store.opener
        self.sjoin = self.store.join
        self._filecache = {}
        self.requirements = requirements

        rootmanifest = manifest.manifestrevlog(self.nodeconstants, self.svfs)
        self.manifestlog = manifest.manifestlog(
            self.svfs, self, rootmanifest, self.narrowmatch()
        )
        self.changelog = changelog.changelog(self.svfs)
        self._tags = None
        self.nodetagscache = None
        self._branchcaches = branchmap.BranchMapCache()
        self._revbranchcache = None
        self.encodepats = None
        self.decodepats = None
        self._transref = None

    def _restrictcapabilities(self, caps):
        caps = super(statichttprepository, self)._restrictcapabilities(caps)
        return caps.difference([b"pushkey"])

    def url(self):
        return self._url

    def local(self):
        return False

    def peer(self):
        return statichttppeer(self)

    def wlock(self, wait=True):
        raise error.LockUnavailable(
            0,
            _(b'lock not available'),
            b'lock',
            _(b'cannot lock static-http repository'),
        )

    def lock(self, wait=True):
        raise error.LockUnavailable(
            0,
            _(b'lock not available'),
            b'lock',
            _(b'cannot lock static-http repository'),
        )

    def _writecaches(self):
        pass  # statichttprepository are read only


def instance(ui, path, create, intents=None, createopts=None):
    if create:
        raise error.Abort(_(b'cannot create new static-http repository'))
    return statichttprepository(ui, path[7:])
                                                                                                                                                                                                                                                                         usr/lib/python3/dist-packages/mercurial/statprof.py                                                 0000644 0000000 0000000 00000077645 14355257011 021173  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        ## statprof.py
## Copyright (C) 2012 Bryan O'Sullivan <bos@serpentine.com>
## Copyright (C) 2011 Alex Fraser <alex at phatcore dot com>
## Copyright (C) 2004,2005 Andy Wingo <wingo at pobox dot com>
## Copyright (C) 2001 Rob Browning <rlb at defaultvalue dot org>

## This library is free software; you can redistribute it and/or
## modify it under the terms of the GNU Lesser General Public
## License as published by the Free Software Foundation; either
## version 2.1 of the License, or (at your option) any later version.
##
## This library is distributed in the hope that it will be useful,
## but WITHOUT ANY WARRANTY; without even the implied warranty of
## MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the GNU
## Lesser General Public License for more details.
##
## You should have received a copy of the GNU Lesser General Public
## License along with this program; if not, contact:
##
## Free Software Foundation           Voice:  +1-617-542-5942
## 59 Temple Place - Suite 330        Fax:    +1-617-542-2652
## Boston, MA  02111-1307,  USA       gnu@gnu.org

"""
statprof is intended to be a fairly simple statistical profiler for
python. It was ported directly from a statistical profiler for guile,
also named statprof, available from guile-lib [0].

[0] http://wingolog.org/software/guile-lib/statprof/

To start profiling, call statprof.start():
>>> start()

Then run whatever it is that you want to profile, for example:
>>> import test.pystone; test.pystone.pystones()

Then stop the profiling and print out the results:
>>> stop()
>>> display()
  %   cumulative      self
 time    seconds   seconds  name
 26.72      1.40      0.37  pystone.py:79:Proc0
 13.79      0.56      0.19  pystone.py:133:Proc1
 13.79      0.19      0.19  pystone.py:208:Proc8
 10.34      0.16      0.14  pystone.py:229:Func2
  6.90      0.10      0.10  pystone.py:45:__init__
  4.31      0.16      0.06  pystone.py:53:copy
    ...

All of the numerical data is statistically approximate. In the
following column descriptions, and in all of statprof, "time" refers
to execution time (both user and system), not wall clock time.

% time
    The percent of the time spent inside the procedure itself (not
    counting children).

cumulative seconds
    The total number of seconds spent in the procedure, including
    children.

self seconds
    The total number of seconds spent in the procedure itself (not
    counting children).

name
    The name of the procedure.

By default statprof keeps the data collected from previous runs. If you
want to clear the collected data, call reset():
>>> reset()

reset() can also be used to change the sampling frequency from the
default of 1000 Hz. For example, to tell statprof to sample 50 times a
second:
>>> reset(50)

This means that statprof will sample the call stack after every 1/50 of
a second of user + system time spent running on behalf of the python
process. When your process is idle (for example, blocking in a read(),
as is the case at the listener), the clock does not advance. For this
reason statprof is not currently not suitable for profiling io-bound
operations.

The profiler uses the hash of the code object itself to identify the
procedures, so it won't confuse different procedures with the same name.
They will show up as two different rows in the output.

Right now the profiler is quite simplistic.  I cannot provide
call-graphs or other higher level information.  What you see in the
table is pretty much all there is. Patches are welcome :-)


Threading
---------

Because signals only get delivered to the main thread in Python,
statprof only profiles the main thread. However because the time
reporting function uses per-process timers, the results can be
significantly off if other threads' work patterns are not similar to the
main thread's work patterns.
"""
# no-check-code

import collections
import contextlib
import getopt
import inspect
import json
import os
import signal
import sys
import threading
import time

from .pycompat import open
from . import (
    encoding,
    pycompat,
)

defaultdict = collections.defaultdict
contextmanager = contextlib.contextmanager

__all__ = [b'start', b'stop', b'reset', b'display', b'profile']

skips = {
    "util.py:check",
    "extensions.py:closure",
    "color.py:colorcmd",
    "dispatch.py:checkargs",
    "dispatch.py:<lambda>",
    "dispatch.py:_runcatch",
    "dispatch.py:_dispatch",
    "dispatch.py:_runcommand",
    "pager.py:pagecmd",
    "dispatch.py:run",
    "dispatch.py:dispatch",
    "dispatch.py:runcommand",
    "hg.py:<module>",
    "evolve.py:warnobserrors",
}

###########################################################################
## Utils


def clock():
    times = os.times()
    return (times[0] + times[1], times[4])


###########################################################################
## Collection data structures


class ProfileState:
    def __init__(self, frequency=None):
        self.reset(frequency)
        self.track = b'cpu'

    def reset(self, frequency=None):
        # total so far
        self.accumulated_time = (0.0, 0.0)
        # start_time when timer is active
        self.last_start_time = None
        # a float
        if frequency:
            self.sample_interval = 1.0 / frequency
        elif not pycompat.hasattr(self, 'sample_interval'):
            # default to 1000 Hz
            self.sample_interval = 1.0 / 1000.0
        else:
            # leave the frequency as it was
            pass
        self.remaining_prof_time = None
        # for user start/stop nesting
        self.profile_level = 0

        self.samples = []

    def accumulate_time(self, stop_time):
        increment = (
            stop_time[0] - self.last_start_time[0],
            stop_time[1] - self.last_start_time[1],
        )
        self.accumulated_time = (
            self.accumulated_time[0] + increment[0],
            self.accumulated_time[1] + increment[1],
        )

    def seconds_per_sample(self):
        return self.accumulated_time[self.timeidx] / len(self.samples)

    @property
    def timeidx(self):
        if self.track == b'real':
            return 1
        return 0


state = ProfileState()


class CodeSite:
    cache = {}

    __slots__ = ('path', 'lineno', 'function', 'source')

    def __init__(self, path, lineno, function):
        assert isinstance(path, bytes)
        self.path = path
        self.lineno = lineno
        assert isinstance(function, bytes)
        self.function = function
        self.source = None

    def __eq__(self, other):
        try:
            return self.lineno == other.lineno and self.path == other.path
        except:
            return False

    def __hash__(self):
        return hash((self.lineno, self.path))

    @classmethod
    def get(cls, path, lineno, function):
        k = (path, lineno)
        try:
            return cls.cache[k]
        except KeyError:
            v = cls(path, lineno, function)
            cls.cache[k] = v
            return v

    def getsource(self, length):
        if self.source is None:
            try:
                lineno = self.lineno - 1  # lineno can be None
                with open(self.path, b'rb') as fp:
                    for i, line in enumerate(fp):
                        if i == lineno:
                            self.source = line.strip()
                            break
            except:
                pass
            if self.source is None:
                self.source = b''

        source = self.source
        if len(source) > length:
            source = source[: (length - 3)] + b"..."
        return source

    def filename(self):
        return os.path.basename(self.path)

    def skipname(self):
        return '%s:%s' % (self.filename(), self.function)


class Sample:
    __slots__ = ('stack', 'time')

    def __init__(self, stack, time):
        self.stack = stack
        self.time = time

    @classmethod
    def from_frame(cls, frame, time):
        stack = []

        while frame:
            stack.append(
                CodeSite.get(
                    pycompat.sysbytes(frame.f_code.co_filename),
                    frame.f_lineno,
                    pycompat.sysbytes(frame.f_code.co_name),
                )
            )
            frame = frame.f_back

        return Sample(stack, time)


###########################################################################
## SIGPROF handler


def profile_signal_handler(signum, frame):
    if state.profile_level > 0:
        now = clock()
        state.accumulate_time(now)

        timestamp = state.accumulated_time[state.timeidx]
        state.samples.append(Sample.from_frame(frame, timestamp))

        signal.setitimer(signal.ITIMER_PROF, state.sample_interval, 0.0)
        state.last_start_time = now


stopthread = threading.Event()


def samplerthread(tid):
    while not stopthread.is_set():
        now = clock()
        state.accumulate_time(now)

        frame = sys._current_frames()[tid]

        timestamp = state.accumulated_time[state.timeidx]
        state.samples.append(Sample.from_frame(frame, timestamp))

        state.last_start_time = now
        time.sleep(state.sample_interval)

    stopthread.clear()


###########################################################################
## Profiling API


def is_active():
    return state.profile_level > 0


lastmechanism = None


def start(mechanism=b'thread', track=b'cpu'):
    '''Install the profiling signal handler, and start profiling.'''
    state.track = track  # note: nesting different mode won't work
    state.profile_level += 1
    if state.profile_level == 1:
        state.last_start_time = clock()
        rpt = state.remaining_prof_time
        state.remaining_prof_time = None

        global lastmechanism
        lastmechanism = mechanism

        if mechanism == b'signal':
            signal.signal(signal.SIGPROF, profile_signal_handler)
            signal.setitimer(
                signal.ITIMER_PROF, rpt or state.sample_interval, 0.0
            )
        elif mechanism == b'thread':
            frame = inspect.currentframe()
            tid = [k for k, f in sys._current_frames().items() if f == frame][0]
            state.thread = threading.Thread(
                target=samplerthread, args=(tid,), name="samplerthread"
            )
            state.thread.start()


def stop():
    '''Stop profiling, and uninstall the profiling signal handler.'''
    state.profile_level -= 1
    if state.profile_level == 0:
