def _destupdatebook(repo, clean):
    """decide on an update destination from active bookmark"""
    # we also move the active bookmark, if any
    node = None
    activemark, movemark = bookmarks.calculateupdate(repo.ui, repo)
    if activemark is not None:
        node = repo._bookmarks[activemark]
    return node, movemark, activemark


def _destupdatebranch(repo, clean):
    """decide on an update destination from current branch

    This ignores closed branch heads.
    """
    wc = repo[None]
    movemark = node = None
    currentbranch = wc.branch()

    if clean:
        currentbranch = repo[b'.'].branch()

    if currentbranch in repo.branchmap():
        heads = repo.branchheads(currentbranch)
        if heads:
            node = repo.revs(b'max(.::(%ln))', heads).first()
        if bookmarks.isactivewdirparent(repo):
            movemark = repo[b'.'].node()
    elif currentbranch == b'default' and not wc.p1():
        # "null" parent belongs to "default" branch, but it doesn't exist, so
        # update to the tipmost non-closed branch head
        node = repo.revs(b'max(head() and not closed())').first()
    else:
        node = repo[b'.'].node()
    return node, movemark, None


def _destupdatebranchfallback(repo, clean):
    """decide on an update destination from closed heads in current branch"""
    wc = repo[None]
    currentbranch = wc.branch()
    movemark = None
    if currentbranch in repo.branchmap():
        # here, all descendant branch heads are closed
        heads = repo.branchheads(currentbranch, closed=True)
        assert heads, b"any branch has at least one head"
        node = repo.revs(b'max(.::(%ln))', heads).first()
        assert (
            node is not None
        ), b"any revision has at least one descendant branch head"
        if bookmarks.isactivewdirparent(repo):
            movemark = repo[b'.'].node()
    else:
        # here, no "default" branch, and all branches are closed
        node = repo.lookup(b'tip')
        assert node is not None, b"'tip' exists even in empty repository"
    return node, movemark, None


# order in which each step should be evaluated
# steps are run until one finds a destination
destupdatesteps = [b'evolution', b'bookmark', b'branch', b'branchfallback']
# mapping to ease extension overriding steps.
destupdatestepmap = {
    b'evolution': _destupdateobs,
    b'bookmark': _destupdatebook,
    b'branch': _destupdatebranch,
    b'branchfallback': _destupdatebranchfallback,
}


def destupdate(repo, clean=False):
    """destination for bare update operation

    return (rev, movemark, activemark)

    - rev: the revision to update to,
    - movemark: node to move the active bookmark from
                (cf bookmark.calculate update),
    - activemark: a bookmark to activate at the end of the update.
    """
    node = movemark = activemark = None

    for step in destupdatesteps:
        node, movemark, activemark = destupdatestepmap[step](repo, clean)
        if node is not None:
            break
    rev = repo[node].rev()

    return rev, movemark, activemark


msgdestmerge = {
    # too many matching divergent bookmark
    b'toomanybookmarks': {
        b'merge': (
            _(
                b"multiple matching bookmarks to merge -"
                b" please merge with an explicit rev or bookmark"
            ),
            _(b"run 'hg heads' to see all heads, specify rev with -r"),
        ),
        b'rebase': (
            _(
                b"multiple matching bookmarks to rebase -"
                b" please rebase to an explicit rev or bookmark"
            ),
            _(b"run 'hg heads' to see all heads, specify destination with -d"),
        ),
    },
    # no other matching divergent bookmark
    b'nootherbookmarks': {
        b'merge': (
            _(
                b"no matching bookmark to merge - "
                b"please merge with an explicit rev or bookmark"
            ),
            _(b"run 'hg heads' to see all heads, specify rev with -r"),
        ),
        b'rebase': (
            _(
                b"no matching bookmark to rebase - "
                b"please rebase to an explicit rev or bookmark"
            ),
            _(b"run 'hg heads' to see all heads, specify destination with -d"),
        ),
    },
    # branch have too many unbookmarked heads, no obvious destination
    b'toomanyheads': {
        b'merge': (
            _(b"branch '%s' has %d heads - please merge with an explicit rev"),
            _(b"run 'hg heads .' to see heads, specify rev with -r"),
        ),
        b'rebase': (
            _(b"branch '%s' has %d heads - please rebase to an explicit rev"),
            _(b"run 'hg heads .' to see heads, specify destination with -d"),
        ),
    },
    # branch have no other unbookmarked heads
    b'bookmarkedheads': {
        b'merge': (
            _(b"heads are bookmarked - please merge with an explicit rev"),
            _(b"run 'hg heads' to see all heads, specify rev with -r"),
        ),
        b'rebase': (
            _(b"heads are bookmarked - please rebase to an explicit rev"),
            _(b"run 'hg heads' to see all heads, specify destination with -d"),
        ),
    },
    # branch have just a single heads, but there is other branches
    b'nootherbranchheads': {
        b'merge': (
            _(b"branch '%s' has one head - please merge with an explicit rev"),
            _(b"run 'hg heads' to see all heads, specify rev with -r"),
        ),
        b'rebase': (
            _(b"branch '%s' has one head - please rebase to an explicit rev"),
            _(b"run 'hg heads' to see all heads, specify destination with -d"),
        ),
    },
    # repository have a single head
    b'nootherheads': {
        b'merge': (_(b'nothing to merge'), None),
        b'rebase': (_(b'nothing to rebase'), None),
    },
    # repository have a single head and we are not on it
    b'nootherheadsbehind': {
        b'merge': (_(b'nothing to merge'), _(b"use 'hg update' instead")),
        b'rebase': (_(b'nothing to rebase'), _(b"use 'hg update' instead")),
    },
    # We are not on a head
    b'notatheads': {
        b'merge': (
            _(b'working directory not at a head revision'),
            _(b"use 'hg update' or merge with an explicit revision"),
        ),
        b'rebase': (
            _(b'working directory not at a head revision'),
            _(b"use 'hg update' or rebase to an explicit revision"),
        ),
    },
    b'emptysourceset': {
        b'merge': (_(b'source set is empty'), None),
        b'rebase': (_(b'source set is empty'), None),
    },
    b'multiplebranchessourceset': {
        b'merge': (_(b'source set is rooted in multiple branches'), None),
        b'rebase': (
            _(b'rebaseset is rooted in multiple named branches'),
            _(b'specify an explicit destination with --dest'),
        ),
    },
}


def _destmergebook(repo, action=b'merge', sourceset=None, destspace=None):
    """find merge destination in the active bookmark case"""
    node = None
    bmheads = bookmarks.headsforactive(repo)
    curhead = repo._bookmarks[repo._activebookmark]
    if len(bmheads) == 2:
        if curhead == bmheads[0]:
            node = bmheads[1]
        else:
            node = bmheads[0]
    elif len(bmheads) > 2:
        msg, hint = msgdestmerge[b'toomanybookmarks'][action]
        raise error.ManyMergeDestAbort(msg, hint=hint)
    elif len(bmheads) <= 1:
        msg, hint = msgdestmerge[b'nootherbookmarks'][action]
        raise error.NoMergeDestAbort(msg, hint=hint)
    assert node is not None
    return node


def _destmergebranch(
    repo, action=b'merge', sourceset=None, onheadcheck=True, destspace=None
):
    """find merge destination based on branch heads"""
    node = None

    if sourceset is None:
        sourceset = [repo[repo.dirstate.p1()].rev()]
        branch = repo.dirstate.branch()
    elif not sourceset:
        msg, hint = msgdestmerge[b'emptysourceset'][action]
        raise error.NoMergeDestAbort(msg, hint=hint)
    else:
        branch = None
        for ctx in repo.set(b'roots(%ld::%ld)', sourceset, sourceset):
            if branch is not None and ctx.branch() != branch:
                msg, hint = msgdestmerge[b'multiplebranchessourceset'][action]
                raise error.ManyMergeDestAbort(msg, hint=hint)
            branch = ctx.branch()

    bheads = repo.branchheads(branch)
    onhead = repo.revs(b'%ld and %ln', sourceset, bheads)
    if onheadcheck and not onhead:
        # Case A: working copy if not on a head. (merge only)
        #
        # This is probably a user mistake We bailout pointing at 'hg update'
        if len(repo.heads()) <= 1:
            msg, hint = msgdestmerge[b'nootherheadsbehind'][action]
        else:
            msg, hint = msgdestmerge[b'notatheads'][action]
        raise error.Abort(msg, hint=hint)
    # remove heads descendants of source from the set
    bheads = list(repo.revs(b'%ln - (%ld::)', bheads, sourceset))
    # filters out bookmarked heads
    nbhs = list(repo.revs(b'%ld - bookmark()', bheads))

    if destspace is not None:
        # restrict search space
        # used in the 'hg pull --rebase' case, see issue 5214.
        nbhs = list(repo.revs(b'%ld and %ld', destspace, nbhs))

    if len(nbhs) > 1:
        # Case B: There is more than 1 other anonymous heads
        #
        # This means that there will be more than 1 candidate. This is
        # ambiguous. We abort asking the user to pick as explicit destination
        # instead.
        msg, hint = msgdestmerge[b'toomanyheads'][action]
        msg %= (branch, len(bheads) + 1)
        raise error.ManyMergeDestAbort(msg, hint=hint)
    elif not nbhs:
        # Case B: There is no other anonymous heads
        #
        # This means that there is no natural candidate to merge with.
        # We abort, with various messages for various cases.
        if bheads:
            msg, hint = msgdestmerge[b'bookmarkedheads'][action]
        elif len(repo.heads()) > 1:
            msg, hint = msgdestmerge[b'nootherbranchheads'][action]
            msg %= branch
        elif not onhead:
            # if 'onheadcheck == False' (rebase case),
            # this was not caught in Case A.
            msg, hint = msgdestmerge[b'nootherheadsbehind'][action]
        else:
            msg, hint = msgdestmerge[b'nootherheads'][action]
        raise error.NoMergeDestAbort(msg, hint=hint)
    else:
        node = nbhs[0]
    assert node is not None
    return node


def destmerge(
    repo, action=b'merge', sourceset=None, onheadcheck=True, destspace=None
):
    """return the default destination for a merge

    (or raise exception about why it can't pick one)

    :action: the action being performed, controls emitted error message
    """
    # destspace is here to work around issues with `hg pull --rebase` see
    # issue5214 for details
    if repo._activebookmark:
        node = _destmergebook(
            repo, action=action, sourceset=sourceset, destspace=destspace
        )
    else:
        node = _destmergebranch(
            repo,
            action=action,
            sourceset=sourceset,
            onheadcheck=onheadcheck,
            destspace=destspace,
        )
    return repo[node].rev()


def desthistedit(ui, repo):
    """Default base revision to edit for `hg histedit`."""
    default = ui.config(b'histedit', b'defaultrev')

    if default is None:
        revs = stack.getstack(repo)
    elif default:
        revs = scmutil.revrange(repo, [default])
    else:
        raise error.ConfigError(
            _(b"config option histedit.defaultrev can't be empty")
        )

    if revs:
        # Take the first revision of the revset as the root
        return revs.min()

    return None


def stackbase(ui, repo):
    revs = stack.getstack(repo)
    return revs.first() if revs else None


def _statusotherbook(ui, repo):
    bmheads = bookmarks.headsforactive(repo)
    curhead = repo._bookmarks[repo._activebookmark]
    if repo.revs(b'%n and parents()', curhead):
        # we are on the active bookmark
        bmheads = [b for b in bmheads if curhead != b]
        if bmheads:
            msg = _(b'%i other divergent bookmarks for "%s"\n')
            ui.status(msg % (len(bmheads), repo._activebookmark))


def _statusotherbranchheads(ui, repo):
    currentbranch = repo.dirstate.branch()
    allheads = repo.branchheads(currentbranch, closed=True)
    heads = repo.branchheads(currentbranch)
    if repo.revs(b'%ln and parents()', allheads):
        # we are on a head, even though it might be closed
        #
        #  on closed otherheads
        #  ========= ==========
        #      o        0       all heads for current branch are closed
        #               N       only descendant branch heads are closed
        #      x        0       there is only one non-closed branch head
        #               N       there are some non-closed branch heads
        #  ========= ==========
        otherheads = repo.revs(b'%ln - parents()', heads)
        if repo[b'.'].closesbranch():
            ui.warn(
                _(
                    b'no open descendant heads on branch "%s", '
                    b'updating to a closed head\n'
                )
                % currentbranch
            )
            if otherheads:
                ui.warn(
                    _(
                        b"(committing will reopen the head, "
                        b"use 'hg heads .' to see %i other heads)\n"
                    )
                    % (len(otherheads))
                )
            else:
                ui.warn(
                    _(b'(committing will reopen branch "%s")\n') % currentbranch
                )
        elif otherheads:
            curhead = repo[b'.']
            ui.status(
                _(b'updated to "%s: %s"\n')
                % (curhead, curhead.description().split(b'\n')[0])
            )
            ui.status(
                _(b'%i other heads for branch "%s"\n')
                % (len(otherheads), currentbranch)
            )


def statusotherdests(ui, repo):
    """Print message about other head"""
    # XXX we should probably include a hint:
    # - about what to do
    # - how to see such heads
    if repo._activebookmark:
        _statusotherbook(ui, repo)
    else:
        _statusotherbranchheads(ui, repo)
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           usr/lib/python3/dist-packages/mercurial/diffhelper.py                                               0000644 0000000 0000000 00000004374 14355257011 021426  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # diffhelper.py - helper routines for patch
#
# Copyright 2009 Olivia Mackall <olivia@selenic.com> and others
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


from .i18n import _

from . import (
    error,
)

MISSING_NEWLINE_MARKER = b'\\ No newline at end of file\n'


def addlines(fp, hunk, lena, lenb, a, b):
    """Read lines from fp into the hunk

    The hunk is parsed into two arrays, a and b. a gets the old state of
    the text, b gets the new state. The control char from the hunk is saved
    when inserting into a, but not b (for performance while deleting files.)
    """
    while True:
        todoa = lena - len(a)
        todob = lenb - len(b)
        num = max(todoa, todob)
        if num == 0:
            break
        for i in range(num):
            s = fp.readline()
            if not s:
                raise error.ParseError(_(b'incomplete hunk'))
            if s == MISSING_NEWLINE_MARKER:
                fixnewline(hunk, a, b)
                continue
            if s == b'\n' or s == b'\r\n':
                # Some patches may be missing the control char
                # on empty lines. Supply a leading space.
                s = b' ' + s
            hunk.append(s)
            if s.startswith(b'+'):
                b.append(s[1:])
            elif s.startswith(b'-'):
                a.append(s)
            else:
                b.append(s[1:])
                a.append(s)


def fixnewline(hunk, a, b):
    """Fix up the last lines of a and b when the patch has no newline at EOF"""
    l = hunk[-1]
    # tolerate CRLF in last line
    if l.endswith(b'\r\n'):
        hline = l[:-2]
    else:
        hline = l[:-1]

    if hline.startswith((b' ', b'+')):
        b[-1] = hline[1:]
    if hline.startswith((b' ', b'-')):
        a[-1] = hline
    hunk[-1] = hline


def testhunk(a, b, bstart):
    """Compare the lines in a with the lines in b

    a is assumed to have a control char at the start of each line, this char
    is ignored in the compare.
    """
    alen = len(a)
    blen = len(b)
    if alen > blen - bstart or bstart < 0:
        return False
    for i in range(alen):
        if a[i][1:] != b[i + bstart]:
            return False
    return True
                                                                                                                                                                                                                                                                    usr/lib/python3/dist-packages/mercurial/diffutil.py                                                 0000644 0000000 0000000 00000010756 14355257011 021125  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # diffutil.py - utility functions related to diff and patch
#
# Copyright 2006 Brendan Cully <brendan@kublai.com>
# Copyright 2007 Chris Mason <chris.mason@oracle.com>
# Copyright 2018 Octobus <octobus@octobus.net>
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


from .i18n import _

from . import (
    mdiff,
    pycompat,
)


def diffallopts(
    ui, opts=None, untrusted=False, section=b'diff', configprefix=b''
):
    '''return diffopts with all features supported and parsed'''
    return difffeatureopts(
        ui,
        opts=opts,
        untrusted=untrusted,
        section=section,
        git=True,
        whitespace=True,
        formatchanging=True,
        configprefix=configprefix,
    )


def difffeatureopts(
    ui,
    opts=None,
    untrusted=False,
    section=b'diff',
    git=False,
    whitespace=False,
    formatchanging=False,
    configprefix=b'',
):
    """return diffopts with only opted-in features parsed

    Features:
    - git: git-style diffs
    - whitespace: whitespace options like ignoreblanklines and ignorews
    - formatchanging: options that will likely break or cause correctness issues
      with most diff parsers
    """

    def get(key, name=None, getter=ui.configbool, forceplain=None):
        if opts:
            v = opts.get(key)
            # diffopts flags are either None-default (which is passed
            # through unchanged, so we can identify unset values), or
            # some other falsey default (eg --unified, which defaults
            # to an empty string). We only want to override the config
            # entries from hgrc with command line values if they
            # appear to have been set, which is any truthy value,
            # True, or False.
            if v or isinstance(v, bool):
                return v
        if forceplain is not None and ui.plain():
            return forceplain
        return getter(
            section, configprefix + (name or key), untrusted=untrusted
        )

    # core options, expected to be understood by every diff parser
    buildopts = {
        b'nodates': get(b'nodates'),
        b'showfunc': get(b'show_function', b'showfunc'),
        b'context': get(b'unified', getter=ui.config),
    }
    buildopts[b'xdiff'] = ui.configbool(b'experimental', b'xdiff')

    if git:
        buildopts[b'git'] = get(b'git')

        # since this is in the experimental section, we need to call
        # ui.configbool directory
        buildopts[b'showsimilarity'] = ui.configbool(
            b'experimental', b'extendedheader.similarity'
        )

        # need to inspect the ui object instead of using get() since we want to
        # test for an int
        hconf = ui.config(b'experimental', b'extendedheader.index')
        if hconf is not None:
            hlen = None
            try:
                # the hash config could be an integer (for length of hash) or a
                # word (e.g. short, full, none)
                hlen = int(hconf)
                if hlen < 0 or hlen > 40:
                    msg = _(b"invalid length for extendedheader.index: '%d'\n")
                    ui.warn(msg % hlen)
            except ValueError:
                # default value
                if hconf == b'short' or hconf == b'':
                    hlen = 12
                elif hconf == b'full':
                    hlen = 40
                elif hconf != b'none':
                    msg = _(b"invalid value for extendedheader.index: '%s'\n")
                    ui.warn(msg % hconf)
            finally:
                buildopts[b'index'] = hlen

    if whitespace:
        buildopts[b'ignorews'] = get(b'ignore_all_space', b'ignorews')
        buildopts[b'ignorewsamount'] = get(
            b'ignore_space_change', b'ignorewsamount'
        )
        buildopts[b'ignoreblanklines'] = get(
            b'ignore_blank_lines', b'ignoreblanklines'
        )
        buildopts[b'ignorewseol'] = get(b'ignore_space_at_eol', b'ignorewseol')
    if formatchanging:
        buildopts[b'text'] = opts and opts.get(b'text')
        binary = None if opts is None else opts.get(b'binary')
        buildopts[b'nobinary'] = (
            not binary
            if binary is not None
            else get(b'nobinary', forceplain=False)
        )
        buildopts[b'noprefix'] = get(b'noprefix', forceplain=False)
        buildopts[b'worddiff'] = get(
            b'word_diff', b'word-diff', forceplain=False
        )

    return mdiff.diffopts(**pycompat.strkwargs(buildopts))
                  usr/lib/python3/dist-packages/mercurial/dirstate.py                                                 0000644 0000000 0000000 00000156412 14374730616 021146  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        # dirstate.py - working directory tracking for mercurial
#
# Copyright 2005-2007 Olivia Mackall <olivia@selenic.com>
#
# This software may be used and distributed according to the terms of the
# GNU General Public License version 2 or any later version.


import collections
import contextlib
import os
import stat
import uuid

from .i18n import _
from .pycompat import delattr

from hgdemandimport import tracing

from . import (
    dirstatemap,
    encoding,
    error,
    match as matchmod,
    node,
    pathutil,
    policy,
    pycompat,
    scmutil,
    util,
)

from .dirstateutils import (
    docket as docketmod,
    timestamp,
)

from .interfaces import (
    dirstate as intdirstate,
    util as interfaceutil,
)

parsers = policy.importmod('parsers')
rustmod = policy.importrust('dirstate')

HAS_FAST_DIRSTATE_V2 = rustmod is not None

propertycache = util.propertycache
filecache = scmutil.filecache
_rangemask = dirstatemap.rangemask

DirstateItem = dirstatemap.DirstateItem


class repocache(filecache):
    """filecache for files in .hg/"""

    def join(self, obj, fname):
        return obj._opener.join(fname)


class rootcache(filecache):
    """filecache for files in the repository root"""

    def join(self, obj, fname):
        return obj._join(fname)


def requires_parents_change(func):
    def wrap(self, *args, **kwargs):
        if not self.pendingparentchange():
            msg = 'calling `%s` outside of a parentchange context'
            msg %= func.__name__
            raise error.ProgrammingError(msg)
        return func(self, *args, **kwargs)

    return wrap


def requires_no_parents_change(func):
    def wrap(self, *args, **kwargs):
        if self.pendingparentchange():
            msg = 'calling `%s` inside of a parentchange context'
            msg %= func.__name__
            raise error.ProgrammingError(msg)
        return func(self, *args, **kwargs)

    return wrap


@interfaceutil.implementer(intdirstate.idirstate)
class dirstate:
    def __init__(
        self,
        opener,
        ui,
        root,
        validate,
        sparsematchfn,
        nodeconstants,
        use_dirstate_v2,
        use_tracked_hint=False,
    ):
        """Create a new dirstate object.

        opener is an open()-like callable that can be used to open the
        dirstate file; root is the root of the directory tracked by
        the dirstate.
        """
        self._use_dirstate_v2 = use_dirstate_v2
        self._use_tracked_hint = use_tracked_hint
        self._nodeconstants = nodeconstants
        self._opener = opener
        self._validate = validate
        self._root = root
        # Either build a sparse-matcher or None if sparse is disabled
        self._sparsematchfn = sparsematchfn
        # ntpath.join(root, '') of Python 2.7.9 does not add sep if root is
        # UNC path pointing to root share (issue4557)
        self._rootdir = pathutil.normasprefix(root)
        # True is any internal state may be different
        self._dirty = False
        # True if the set of tracked file may be different
        self._dirty_tracked_set = False
        self._ui = ui
        self._filecache = {}
        self._parentwriters = 0
        self._filename = b'dirstate'
        self._filename_th = b'dirstate-tracked-hint'
        self._pendingfilename = b'%s.pending' % self._filename
        self._plchangecallbacks = {}
        self._origpl = None
        self._mapcls = dirstatemap.dirstatemap
        # Access and cache cwd early, so we don't access it for the first time
        # after a working-copy update caused it to not exist (accessing it then
        # raises an exception).
        self._cwd

    def prefetch_parents(self):
        """make sure the parents are loaded

        Used to avoid a race condition.
        """
        self._pl

    @contextlib.contextmanager
    def parentchange(self):
        """Context manager for handling dirstate parents.

        If an exception occurs in the scope of the context manager,
        the incoherent dirstate won't be written when wlock is
        released.
        """
        self._parentwriters += 1
        yield
        # Typically we want the "undo" step of a context manager in a
        # finally block so it happens even when an exception
        # occurs. In this case, however, we only want to decrement
        # parentwriters if the code in the with statement exits
        # normally, so we don't have a try/finally here on purpose.
        self._parentwriters -= 1

    def pendingparentchange(self):
        """Returns true if the dirstate is in the middle of a set of changes
        that modify the dirstate parent.
        """
        return self._parentwriters > 0

    @propertycache
    def _map(self):
        """Return the dirstate contents (see documentation for dirstatemap)."""
        self._map = self._mapcls(
            self._ui,
            self._opener,
            self._root,
            self._nodeconstants,
            self._use_dirstate_v2,
        )
        return self._map

    @property
    def _sparsematcher(self):
        """The matcher for the sparse checkout.

        The working directory may not include every file from a manifest. The
        matcher obtained by this property will match a path if it is to be
        included in the working directory.

        When sparse if disabled, return None.
        """
        if self._sparsematchfn is None:
            return None
        # TODO there is potential to cache this property. For now, the matcher
        # is resolved on every access. (But the called function does use a
        # cache to keep the lookup fast.)
        return self._sparsematchfn()

    @repocache(b'branch')
    def _branch(self):
        try:
            return self._opener.read(b"branch").strip() or b"default"
        except FileNotFoundError:
            return b"default"

    @property
    def _pl(self):
        return self._map.parents()

    def hasdir(self, d):
        return self._map.hastrackeddir(d)

    @rootcache(b'.hgignore')
    def _ignore(self):
        files = self._ignorefiles()
        if not files:
            return matchmod.never()

        pats = [b'include:%s' % f for f in files]
        return matchmod.match(self._root, b'', [], pats, warn=self._ui.warn)

    @propertycache
    def _slash(self):
        return self._ui.configbool(b'ui', b'slash') and pycompat.ossep != b'/'

    @propertycache
    def _checklink(self):
        return util.checklink(self._root)

    @propertycache
    def _checkexec(self):
        return bool(util.checkexec(self._root))

    @propertycache
    def _checkcase(self):
        return not util.fscasesensitive(self._join(b'.hg'))

    def _join(self, f):
        # much faster than os.path.join()
        # it's safe because f is always a relative path
        return self._rootdir + f

    def flagfunc(self, buildfallback):
        """build a callable that returns flags associated with a filename

        The information is extracted from three possible layers:
        1. the file system if it supports the information
        2. the "fallback" information stored in the dirstate if any
        3. a more expensive mechanism inferring the flags from the parents.
        """

        # small hack to cache the result of buildfallback()
        fallback_func = []

        def get_flags(x):
            entry = None
            fallback_value = None
            try:
                st = os.lstat(self._join(x))
            except OSError:
                return b''

            if self._checklink:
                if util.statislink(st):
                    return b'l'
            else:
                entry = self.get_entry(x)
                if entry.has_fallback_symlink:
                    if entry.fallback_symlink:
                        return b'l'
                else:
                    if not fallback_func:
                        fallback_func.append(buildfallback())
                    fallback_value = fallback_func[0](x)
                    if b'l' in fallback_value:
                        return b'l'

            if self._checkexec:
                if util.statisexec(st):
                    return b'x'
            else:
                if entry is None:
                    entry = self.get_entry(x)
                if entry.has_fallback_exec:
                    if entry.fallback_exec:
                        return b'x'
                else:
                    if fallback_value is None:
                        if not fallback_func:
                            fallback_func.append(buildfallback())
                        fallback_value = fallback_func[0](x)
                    if b'x' in fallback_value:
                        return b'x'
            return b''

        return get_flags

    @propertycache
    def _cwd(self):
        # internal config: ui.forcecwd
        forcecwd = self._ui.config(b'ui', b'forcecwd')
        if forcecwd:
            return forcecwd
        return encoding.getcwd()

    def getcwd(self):
        """Return the path from which a canonical path is calculated.

        This path should be used to resolve file patterns or to convert
        canonical paths back to file paths for display. It shouldn't be
        used to get real file paths. Use vfs functions instead.
        """
        cwd = self._cwd
        if cwd == self._root:
            return b''
        # self._root ends with a path separator if self._root is '/' or 'C:\'
        rootsep = self._root
        if not util.endswithsep(rootsep):
            rootsep += pycompat.ossep
        if cwd.startswith(rootsep):
            return cwd[len(rootsep) :]
        else:
            # we're outside the repo. return an absolute path.
            return cwd

    def pathto(self, f, cwd=None):
        if cwd is None:
            cwd = self.getcwd()
        path = util.pathto(self._root, cwd, f)
        if self._slash:
            return util.pconvert(path)
        return path

    def get_entry(self, path):
        """return a DirstateItem for the associated path"""
        entry = self._map.get(path)
        if entry is None:
            return DirstateItem()
        return entry

    def __contains__(self, key):
        return key in self._map

    def __iter__(self):
        return iter(sorted(self._map))

    def items(self):
        return self._map.items()

    iteritems = items

    def parents(self):
        return [self._validate(p) for p in self._pl]

    def p1(self):
        return self._validate(self._pl[0])

    def p2(self):
        return self._validate(self._pl[1])

    @property
    def in_merge(self):
        """True if a merge is in progress"""
        return self._pl[1] != self._nodeconstants.nullid

    def branch(self):
        return encoding.tolocal(self._branch)

    def setparents(self, p1, p2=None):
        """Set dirstate parents to p1 and p2.

        When moving from two parents to one, "merged" entries a
        adjusted to normal and previous copy records discarded and
        returned by the call.

        See localrepo.setparents()
        """
        if p2 is None:
            p2 = self._nodeconstants.nullid
