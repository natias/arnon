
=item * test_porting

This runs some basic sanity tests on the source tree and helps catch
basic errors before you submit a patch.

=item * minitest

Run F<miniperl> on F<t/base>, F<t/comp>, F<t/cmd>, F<t/run>, F<t/io>,
F<t/op>, F<t/uni> and F<t/mro> tests.

F<miniperl> is a minimalistic perl built to bootstrap building
extensions, utilties, documentation etc.  It doesn't support dynamic
loading and depending on the point in the build process will only have
access to a limited set of core modules.  F<miniperl> is not intended
for day to day use.

=item * test.valgrind check.valgrind

(Only in Linux) Run all the tests using the memory leak + naughty
memory access tool "valgrind".  The log files will be named
F<testname.valgrind>.

=item * test_harness

Run the test suite with the F<t/harness> controlling program, instead
of F<t/TEST>.  F<t/harness> is more sophisticated, and uses the
L<Test::Harness> module, thus using this test target supposes that perl
mostly works.  The main advantage for our purposes is that it prints a
detailed summary of failed tests at the end.  Also, unlike F<t/TEST>,
it doesn't redirect stderr to stdout.

Note that under Win32 F<t/harness> is always used instead of F<t/TEST>,
so there is no special "test_harness" target.

Under the Unix build process you may use the TEST_ARGS and TEST_FILES
parameters to pass arguments through to the underlying harness call.
This means that for instance you could do

    make test_harness TEST_ARGS="-v -re pat"

which would make, and then run the test harness in verbose mode over
files which contain "pat". Or you could do

    make test_harness TEST_ARGS="-torture" TEST_FILES="op/*.t"

and run torture tests on files matching the glob "op/*.t".

Under Win32's "test" target you may use the TEST_SWITCHES and
TEST_FILES environment variables to control the behaviour of
F<t/harness>.  This means you can say

    nmake test TEST_FILES="op/*.t"
    nmake test TEST_SWITCHES="-torture" TEST_FILES="op/*.t"

Note that for compatibility with the unix build process TEST_ARGS
may also be used instead of the traditional TEST_SWITCHES argument.

=item * test-notty test_notty

Sets PERL_SKIP_TTY_TEST to true before running normal test.

=back

=head2 Parallel tests

The core distribution can now run its regression tests in parallel on
Unix-like and Windows platforms.  On Unix, instead of running C<make
test>, set C<TEST_JOBS> in your environment to the number of tests to
run in parallel, and run C<make test_harness>.  On a Bourne-like shell,
this can be done as

    TEST_JOBS=3 make test_harness  # Run 3 tests in parallel

An environment variable is used, rather than parallel make itself,
because L<TAP::Harness> needs to be able to schedule individual
non-conflicting test scripts itself, and there is no standard interface
to C<make> utilities to interact with their job schedulers.

Tests are normally run in a logical order, with the sanity tests first,
then the main tests of the Perl core functionality, then the tests for
the non-core modules.  On many-core systems, this may not use the
hardware as effectively as possible.  By also specifying

 TEST_JOBS=19 PERL_TEST_HARNESS_ASAP=1 make -j19 test_harness

you signal that you want the tests to finish in wall-clock time as short
as possible.  After the sanity tests are completed, this causes the
remaining ones to be packed into the available cores as tightly as
we know how.  This has its greatest effect on slower, many-core systems.
Throughput was sped up by 20% on an outmoded 24-core system; less on
more recent faster ones with fewer cores.

Note that the command line above added a C<-j> parameter to make, so as
to cause parallel compilation.  This may or may not work on your
platform.

Normally data on how long tests take is stored in F<t/test_state>,
however you can change this to use a different filename by setting the
C<PERL_TEST_STATE_FILE> environment variable to something different, or
to a false value (0 or the empty string) to disable use of the state
mechanism entirely.  There are no protections against the format of the
state file changing over time, so if you have any issues related to this
file it is up to you to delete the file manually and then let the
harness recreate it, although the file format does not change frequently
so this should not be necessary very often.

=head2 Running tests by hand

You can run part of the test suite by hand by using one of the
following commands from the F<t/> directory:

    ./perl -I../lib TEST list-of-.t-files

or

    ./perl -I../lib harness list-of-.t-files

(If you don't specify test scripts, the whole test suite will be run.)

=head2 Using F<t/harness> for testing

If you use C<harness> for testing, you have several command line
options available to you.  The arguments are as follows, and are in the
order that they must appear if used together.

    harness -v -torture -re=pattern LIST OF FILES TO TEST
    harness -v -torture -re LIST OF PATTERNS TO MATCH

If C<LIST OF FILES TO TEST> is omitted, the file list is obtained from
the manifest.  The file list may include shell wildcards which will be
expanded out.

=over 4

=item * -v

Run the tests under verbose mode so you can see what tests were run,
and debug output.

=item * -torture

Run the torture tests as well as the normal set.

=item * -re=PATTERN

Filter the file list so that all the test files run match PATTERN.
Note that this form is distinct from the B<-re LIST OF PATTERNS> form
below in that it allows the file list to be provided as well.

=item * -re LIST OF PATTERNS

Filter the file list so that all the test files run match
/(LIST|OF|PATTERNS)/.  Note that with this form the patterns are joined
by '|' and you cannot supply a list of files, instead the test files
are obtained from the MANIFEST.

=back

You can run an individual test by a command similar to

    ./perl -I../lib path/to/foo.t

except that the harnesses set up some environment variables that may
affect the execution of the test:

=over 4

=item * PERL_CORE=1

indicates that we're running this test as part of the perl core test
suite.  This is useful for modules that have a dual life on CPAN.

=item * PERL_DESTRUCT_LEVEL=2

is set to 2 if it isn't set already (see
L<perlhacktips/PERL_DESTRUCT_LEVEL>).

=item * PERL

(used only by F<t/TEST>) if set, overrides the path to the perl
executable that should be used to run the tests (the default being
F<./perl>).

=item * PERL_SKIP_TTY_TEST

if set, tells to skip the tests that need a terminal.  It's actually
set automatically by the Makefile, but can also be forced artificially
by running 'make test_notty'.

=back

=head3 Other environment variables that may influence tests

=over 4

=item * PERL_TEST_Net_Ping

Setting this variable runs all the Net::Ping modules tests, otherwise
some tests that interact with the outside world are skipped.  See
L<perl58delta>.

=item * PERL_TEST_NOVREXX

Setting this variable skips the vrexx.t tests for OS2::REXX.

=item * PERL_TEST_NUMCONVERTS

This sets a variable in op/numconvert.t.

=item * PERL_TEST_MEMORY

Setting this variable includes the tests in F<t/bigmem/>.  This should
be set to the number of gigabytes of memory available for testing, eg.
C<PERL_TEST_MEMORY=4> indicates that tests that require 4GiB of
available memory can be run safely.

=back

See also the documentation for the Test and Test::Harness modules, for
more environment variables that affect testing.

=head2 Performance testing

The file F<t/perf/benchmarks> contains snippets of perl code which are
intended to be benchmarked across a range of perls by the
F<Porting/bench.pl> tool. If you fix or enhance a performance issue, you
may want to add a representative code sample to the file, then run
F<bench.pl> against the previous and current perls to see what difference
it has made, and whether anything else has slowed down as a consequence.

The file F<t/perf/opcount.t> is designed to test whether a particular
code snippet has been compiled into an optree containing specified
numbers of particular op types. This is good for testing whether
optimisations which alter ops, such as converting an C<aelem> op into an
C<aelemfast> op, are really doing that.

The files F<t/perf/speed.t> and F<t/re/speed.t> are designed to test
things that run thousands of times slower if a particular optimisation
is broken (for example, the utf8 length cache on long utf8 strings).
Add a test that will take a fraction of a second normally, and minutes
otherwise, causing the test file to time out on failure.

=head2 Building perl at older commits

In the course of hacking on the Perl core distribution, you may have occasion
to configure, build and test perl at an old commit.  Sometimes C<make> will
fail during this process.  If that happens, you may be able to salvage the
situation by using the Devel::PatchPerl library from CPAN (not included in the
core) to bring the source code at that commit to a buildable state.

Here's a real world example, taken from work done to resolve
L<perl #10118|https://github.com/Perl/perl5/issues/10118>.
Use of F<Porting/bisect.pl> had identified commit
C<ba77e4cc9d1ceebf472c9c5c18b2377ee47062e6> as the commit in which a bug was
corrected.  To confirm, a P5P developer wanted to configure and build perl at
commit C<ba77e4c^> (presumably "bad") and then at C<ba77e4c> (presumably
"good").  Normal configuration and build was attempted:

    $ sh ./Configure -des -Dusedevel
    $ make test_prep

C<make>, however, failed with output (excerpted) like this:

    cc -fstack-protector -L/usr/local/lib -o miniperl \
      gv.o toke.o perly.o pad.o regcomp.o dump.o util.o \
      mg.o reentr.o mro.o hv.o av.o run.o pp_hot.o sv.o \
      pp.o scope.o pp_ctl.o pp_sys.o doop.o doio.o regexec.o \
      utf8.o taint.o deb.o universal.o globals.o perlio.o \
      numeric.o mathoms.o locale.o pp_pack.o pp_sort.o  \
      miniperlmain.o opmini.o perlmini.o
    pp.o: In function `Perl_pp_pow':
    pp.c:(.text+0x2db9): undefined reference to `pow'
    ...
    collect2: error: ld returned 1 exit status
    makefile:348: recipe for target 'miniperl' failed
    make: *** [miniperl] Error 1

Another P5P contributor recommended installation and use of Devel::PatchPerl
for this situation, first to determine the version of perl at the commit in
question, then to patch the source code at that point to facilitate a build.

 $ perl -MDevel::PatchPerl -e \
     'print Devel::PatchPerl->determine_version("/path/to/sourcecode"),
            "\n";'
 5.11.1
 $ perl -MDevel::PatchPerl -e \
     'Devel::PatchPerl->patch_source("5.11.1", "/path/to/sourcecode");'

Once the source was patched, C<./Configure> and C<make test_prep> were called
and completed successfully, enabling confirmation of the findings in RT
#72414.

=head1 MORE READING FOR GUTS HACKERS

To hack on the Perl guts, you'll need to read the following things:

=over 4

=item * L<perlsource>

An overview of the Perl source tree.  This will help you find the files
you're looking for.

=item * L<perlinterp>

An overview of the Perl interpreter source code and some details on how
Perl does what it does.

=item * L<perlhacktut>

This document walks through the creation of a small patch to Perl's C
code.  If you're just getting started with Perl core hacking, this will
help you understand how it works.

=item * L<perlhacktips>

More details on hacking the Perl core.  This document focuses on lower
level details such as how to write tests, compilation issues,
portability, debugging, etc.

If you plan on doing serious C hacking, make sure to read this.

=item * L<perlguts>

This is of paramount importance, since it's the documentation of what
goes where in the Perl source.  Read it over a couple of times and it
might start to make sense - don't worry if it doesn't yet, because the
best way to study it is to read it in conjunction with poking at Perl
source, and we'll do that later on.

Gisle Aas's "illustrated perlguts", also known as I<illguts>, has very
helpful pictures:

L<https://metacpan.org/release/RURBAN/illguts-0.49>

=item * L<perlxstut> and L<perlxs>

A working knowledge of XSUB programming is incredibly useful for core
hacking; XSUBs use techniques drawn from the PP code, the portion of
the guts that actually executes a Perl program.  It's a lot gentler to
learn those techniques from simple examples and explanation than from
the core itself.

=item * L<perlapi>

The documentation for the Perl API explains what some of the internal
functions do, as well as the many macros used in the source.

=item * F<Porting/pumpkin.pod>

This is a collection of words of wisdom for a Perl porter; some of it
is only useful to the pumpkin holders, but most of it applies to anyone
wanting to go about Perl development.

=back

=head1 CPAN TESTERS AND PERL SMOKERS

The CPAN testers ( L<https://cpantesters.org/> ) are a group of volunteers
who test CPAN modules on a variety of platforms.

Perl Smokers ( L<https://www.nntp.perl.org/group/perl.daily-build/> and
L<https://www.nntp.perl.org/group/perl.daily-build.reports/> )
automatically test Perl source releases on platforms with various
configurations.

Both efforts welcome volunteers.  In order to get involved in smoke
testing of the perl itself visit
L<https://metacpan.org/release/Test-Smoke>.  In order to start smoke
testing CPAN modules visit
L<https://metacpan.org/release/CPANPLUS-YACSmoke> or
L<https://metacpan.org/release/minismokebox> or
L<https://metacpan.org/release/CPAN-Reporter>.

=head1 WHAT NEXT?

If you've read all the documentation in the document and the ones
listed above, you're more than ready to hack on Perl.

Here's some more recommendations

=over 4

=item *

Subscribe to perl5-porters, follow the patches and try and understand
them; don't be afraid to ask if there's a portion you're not clear on -
who knows, you may unearth a bug in the patch...

=item *

Do read the README associated with your operating system, e.g.
README.aix on the IBM AIX OS.  Don't hesitate to supply patches to that
README if you find anything missing or changed over a new OS release.

=item *

Find an area of Perl that seems interesting to you, and see if you can
work out how it works.  Scan through the source, and step over it in
the debugger.  Play, poke, investigate, fiddle! You'll probably get to
understand not just your chosen area but a much wider range of
F<perl>'s activity as well, and probably sooner than you'd think.

=back

=head2 "The Road goes ever on and on, down from the door where it began."

If you can do these things, you've started on the long road to Perl
porting.  Thanks for wanting to help make Perl better - and happy
hacking!

=head2 Metaphoric Quotations

If you recognized the quote about the Road above, you're in luck.

Most software projects begin each file with a literal description of
each file's purpose.  Perl instead begins each with a literary allusion
to that file's purpose.

Like chapters in many books, all top-level Perl source files (along
with a few others here and there) begin with an epigrammatic
inscription that alludes, indirectly and metaphorically, to the
material you're about to read.

Quotations are taken from writings of J.R.R. Tolkien pertaining to his
Legendarium, almost always from I<The Lord of the Rings>.  Chapters and
page numbers are given using the following editions:

=over 4

=item *

I<The Hobbit>, by J.R.R. Tolkien.  The hardcover, 70th-anniversary
edition of 2007 was used, published in the UK by Harper Collins
Publishers and in the US by the Houghton Mifflin Company.

=item *

I<The Lord of the Rings>, by J.R.R. Tolkien.  The hardcover,
50th-anniversary edition of 2004 was used, published in the UK by
Harper Collins Publishers and in the US by the Houghton Mifflin
Company.

=item *

I<The Lays of Beleriand>, by J.R.R. Tolkien and published posthumously
by his son and literary executor, C.J.R. Tolkien, being the 3rd of the
12 volumes in Christopher's mammoth I<History of Middle Earth>.  Page
numbers derive from the hardcover edition, first published in 1983 by
George Allen & Unwin; no page numbers changed for the special 3-volume
omnibus edition of 2002 or the various trade-paper editions, all again
now by Harper Collins or Houghton Mifflin.

=back

Other JRRT books fair game for quotes would thus include I<The
Adventures of Tom Bombadil>, I<The Silmarillion>, I<Unfinished Tales>,
and I<The Tale of the Children of Hurin>, all but the first
posthumously assembled by CJRT.  But I<The Lord of the Rings> itself is
perfectly fine and probably best to quote from, provided you can find a
suitable quote there.

So if you were to supply a new, complete, top-level source file to add
to Perl, you should conform to this peculiar practice by yourself
selecting an appropriate quotation from Tolkien, retaining the original
spelling and punctuation and using the same format the rest of the
quotes are in.  Indirect and oblique is just fine; remember, it's a
metaphor, so being meta is, after all, what it's for.

=head1 AUTHOR

This document was originally written by Nathan Torkington, and is
maintained by the perl5-porters mailing list.
                           usr/local/lib/perl5/5.40.0/pod/perlhacktips.pod                                                     0000644 0000000 0000000 00000224575 14714567415 017504  0                                                                                                    ustar 00                                                                0000000 0000000                                                                                                                                                                        
=encoding utf8

=for comment
Consistent formatting of this file is achieved with:
  perl ./Porting/podtidy pod/perlhacktips.pod

=head1 NAME

perlhacktips - Tips for Perl core C code hacking

=head1 DESCRIPTION

This document will help you learn the best way to go about hacking on
the Perl core C code.  It covers common problems, debugging, profiling,
and more.

If you haven't read L<perlhack> and L<perlhacktut> yet, you might want
to do that first.

=head1 COMMON PROBLEMS

Perl source now permits some specific C99 features which we know are
supported by all platforms, but mostly plays by ANSI C89 rules.  You
don't care about some particular platform having broken Perl?  I hear
there is still a strong demand for J2EE programmers.

=head2 Perl environment problems

=over 4

=item *

Not compiling with threading

Compiling with threading (-Duseithreads) completely rewrites the
function prototypes of Perl.  You better try your changes with that.
Related to this is the difference between "Perl_-less" and "Perl_-ly"
APIs, for example:

  Perl_sv_setiv(aTHX_ ...);
  sv_setiv(...);

The first one explicitly passes in the context, which is needed for
e.g. threaded builds.  The second one does that implicitly; do not get
them mixed.  If you are not passing in a aTHX_, you will need to do a
dTHX as the first thing in the function.

See L<perlguts/"How multiple interpreters and concurrency are
supported"> for further discussion about context.

=item *

Not compiling with -DDEBUGGING

The DEBUGGING define exposes more code to the compiler, therefore more
ways for things to go wrong.  You should try it.

=item *

Introducing (non-read-only) globals

Do not introduce any modifiable globals, truly global or file static.
They are bad form and complicate multithreading and other forms of
concurrency.  The right way is to introduce them as new interpreter
variables, see F<intrpvar.h> (at the very end for binary
compatibility).

Introducing read-only (const) globals is okay, as long as you verify
with e.g. C<nm libperl.a|egrep -v ' [TURtr] '> (if your C<nm> has
BSD-style output) that the data you added really is read-only.  (If it
is, it shouldn't show up in the output of that command.)

If you want to have static strings, make them constant:

  static const char etc[] = "...";

If you want to have arrays of constant strings, note carefully the
right combination of C<const>s:

    static const char * const yippee[] =
        {"hi", "ho", "silver"};

=item *

Not exporting your new function

Some platforms (Win32, AIX, VMS, OS/2, to name a few) require any
function that is part of the public API (the shared Perl library) to be
explicitly marked as exported.  See the discussion about F<embed.pl> in
L<perlguts>.

=item *

Exporting your new function

The new shiny result of either genuine new functionality or your
arduous refactoring is now ready and correctly exported.  So what could
possibly go wrong?

Maybe simply that your function did not need to be exported in the
first place.  Perl has a long and not so glorious history of exporting
functions that it should not have.

If the function is used only inside one source code file, make it
static.  See the discussion about F<embed.pl> in L<perlguts>.

If the function is used across several files, but intended only for
Perl's internal use (and this should be the common case), do not export
it to the public API.  See the discussion about F<embed.pl> in
L<perlguts>.

=back

=head2 C99

Starting from 5.35.5 we now permit some C99 features in the core C
source. However, code in dual life extensions still needs to be C89
only, because it needs to compile against earlier version of Perl
running on older platforms.  Also note that our headers need to also be
valid as C++, because XS extensions written in C++ need to include
them, hence I<member structure initialisers> can't be used in headers.

C99 support is still far from complete on all platforms we currently
support. As a baseline we can only assume C89 semantics with the
specific C99 features described below, which we've verified work
everywhere.  It's fine to probe for additional C99 features and use
them where available, providing there is also a fallback for compilers
that don't support the feature.  For example, we use C11 thread local
storage when available, but fall back to POSIX thread specific APIs
otherwise, and we use C<char> for booleans if C<< <stdbool.h> >> isn't
available.

Code can use (and rely on) the following C99 features being present

=over

=item *

mixed declarations and code

=item *

64 bit integer types

For consistency with the existing source code, use the typedefs C<I64>
and C<U64>, instead of using C<long long> and C<unsigned long long>
directly.

=item *

variadic macros

    void greet(char *file, unsigned int line, char *format, ...);
    #define logged_greet(...) greet(__FILE__, __LINE__, __VA_ARGS__);

Note that C<__VA_OPT__> is standardized as of C23 and C++20.  Before
that it was a gcc extension.

=item *

declarations in for loops

    for (const char *p = message; *p; ++p) {
        putchar(*p);
    }

=item *

member structure initialisers

But not in headers, as support was only added to C++ relatively
recently.

Hence this is fine in C and XS code, but not headers:

    struct message {
        char *action;
        char *target;
    };

    struct message mcguffin = {
        .target = "member structure initialisers",
        .action = "Built"
     };

You cannot use the similar syntax for compound literals, since we also
build perl using C++ compilers:

    /* this is fine */
    struct message m = {
        .target = "some target",
        .action = "some action"
    };
    /* this is not valid in C++ */
    m = (struct message){
        .target = "some target",
        .action = "some action"
    };

While structure designators are usable, the related array designators
are not, since they aren't supported by C++ at all.

=item *

flexible array members

This is standards conformant:

    struct greeting {
        unsigned int len;
        char message[];
    };

However, the source code already uses the "unwarranted chumminess with
the compiler" hack in many places:

    struct greeting {
        unsigned int len;
        char message[1];
    };

Strictly it B<is> undefined behaviour accessing beyond C<message[0]>,
but this has been a commonly used hack since K&R times, and using it
hasn't been a practical issue anywhere (in the perl source or any other
common C code). Hence it's unclear what we would gain from actively
changing to the C99 approach.

=item *

C<//> comments

All compilers we tested support their use. Not all humans we tested
support their use.

=back

Code explicitly should not use any other C99 features. For example

=over 4

=item *

variable length arrays

Not supported by B<any> MSVC, and this is not going to change.

Even "variable" length arrays where the variable is a constant
expression are syntax errors under MSVC.

=item *

C99 types in C<< <stdint.h> >>

Use C<PERL_INT_FAST8_T> etc as defined in F<handy.h>

=item *

C99 format strings in C<< <inttypes.h> >>

C<snprintf> in the VMS libc only added support for C<PRIdN> etc very
recently, meaning that there are live supported installations without
this, or formats such as C<%zu>.

(perl's C<sv_catpvf> etc use parser code code in F<sv.c>, which
supports the C<z> modifier, along with perl-specific formats such as
C<SVf>.)

=back

If you want to use a C99 feature not listed above then you need to do
one of

=over 4

=item *

Probe for it in F<Configure>, set a variable in F<config.sh>, and add
fallback logic in the headers for platforms which don't have it.

=item *

Write test code and verify that it works on platforms we need to
support, before relying on it unconditionally.

=back

Likely you want to repeat the same plan as we used to get the current
C99 feature set. See the message at
L<https://markmail.org/thread/odr4fjrn72u2fkpz> for the C99 probes we
used before. Note that the two most "fussy" compilers appear to be MSVC
and the vendor compiler on VMS. To date all the *nix compilers have
been far more flexible in what they support.

On *nix platforms, F<Configure> attempts to set compiler flags
appropriately. All vendor compilers that we tested defaulted to C99 (or
C11) support. However, older versions of gcc default to C89, or permit
I<most> C99 (with warnings), but forbid I<declarations in for loops>
unless C<-std=gnu99> is added. The alternative C<-std=c99> B<might>
seem better, but using it on some platforms can prevent C<< <unistd.h>
>> declaring some prototypes being declared, which breaks the build.
gcc's C<-ansi> flag implies C<-std=c89> so we can no longer set that,
hence the Configure option C<-gccansipedantic> now only adds
C<-pedantic>.

The Perl core source code files (the ones at the top level of the
source code distribution) are automatically compiled with as many as
possible of the C<-std=gnu99>, C<-pedantic>, and a selection of C<-W>
flags (see cflags.SH). Files in F<ext/> F<dist/> F<cpan/> etc are
compiled with the same flags as the installed perl would use to compile
XS extensions.

Basically, it's safe to assume that F<Configure> and F<cflags.SH> have
picked the best combination of flags for the version of gcc on the
platform, and attempting to add more flags related to enforcing a C
dialect will cause problems either locally, or on other systems that
the code is shipped to.

We believe that the C99 support in gcc 3.1 is good enough for us, but
we don't have a 19 year old gcc handy to check this :-) If you have
ancient vendor compilers that don't default to C99, the flags you might
want to try are

=over 4

=item AIX

C<-qlanglvl=stdc99>

=item HP/UX

C<-AC99>

=item Solaris

C<-xc99>

=back

=head2 Symbol Names and Namespace Pollution

=head3 Choosing legal symbol names

C reserves for its implementation any symbol whose name begins with an
underscore followed immediately by either an uppercase letter C<[A-Z]>
or another underscore.  C++ further reserves any symbol containing two
consecutive underscores, and further reserves in the global name space
any symbol beginning with an underscore, not just ones followed by a
capital.  We care about C++ because header files (F<*.h>) need to be
compilable by it, and some people do all their development using a C++
compiler.

The consequences of failing to do this are probably none.  Unless you
stumble on a name that the implementation uses, things will work.
Indeed, the perl core has more than a few instances of using
implementation-reserved symbols.  (These are gradually being changed.)
But your code might stop working any time that the implementation
decides to use a name you already had chosen, potentially many years
before.

It's best then to:

=over

=item B<Don't begin a symbol name with an underscore>; (I<e.g.>, don't
use: C<_FOOBAR>)

=item B<Don't use two consecutive underscores in a symbol name>;
(I<e.g.>, don't use C<FOO__BAR>)

=back

POSIX also reserves many symbols.  See Section 2.2.2 in
L<https://pubs.opengroup.org/onlinepubs/9699919799/functions/V2_chap02.html>.
Perl also has conflicts with that.

Perl reserves for its use any symbol beginning with C<Perl>, C<perl>,
or C<PL_>.  Any time you introduce a macro into a header file that
doesn't follow that convention, you are creating the possiblity of a
namespace clash with an existing XS module, unless you restrict it by,
say,

 #ifdef PERL_CORE
 #  define my_symbol
 #endif

There are many symbols in header files that aren't of this form, and
which are accessible from XS namespace, intentionally or not, just
about anything in F<config.h>, for example.

Having to use one of these prefixes detracts from the readability of
the code, and hasn't been an actual issue for non-trivial names. Things
like perl defining its own C<MAX> macro have been problematic, but they
were quickly discovered, and a S<C<#ifdef PERL_CORE>> guard added.

So there's no rule imposed about using such symbols, just be aware of
the issues.

=head3 Choosing good symbol names

Ideally, a symbol name name should correctly and precisely describe its
intended purpose.  But there is a tension between that and getting
names that are overly long and hence awkward to type and read.
Metaphors could be helpful (a poetic name), but those tend to be
culturally specific, and may not translate for someone whose native
language isn't English, or even comes from a different cultural
background.  Besides, the talent of writing poetry seems to be rare in
programmers.

Certain symbol names don't reflect their purpose, but are nonetheless
fine to use because of long-standing conventions.  These often
originated in the field of Mathematics, where C<i> and C<j> are
frequently used as subscripts, and C<n> as a population count.  Since
at least the 1950's, computer programs have used C<i>, I<etc.> as loop
variables.

Our guidance is to choose a name that reasonably describes the purpose,
and to comment its declaration more precisely.

One certainly shouldn't use misleading nor ambiguous names. C<last_foo>
could mean either the final C<foo> or the previous C<foo>, and so could
be confusing to the reader, or even to the writer coming back to the
code after a few months of working on something else. Sometimes the
programmer has a particular line of thought in mind, and it doesn't
occur to them that ambiguity is present.

There are probably still many off-by-1 bugs around because the name
L<perlapi/C<av_len>> doesn't correspond to what other I<-len>
constructs mean, such as L<perlapi/C<sv_len>>.  Awkward (and
controversial) synonyms were created to use instead that conveyed its
true meaning (L<perlapi/C<av_top_index>>).  Eventually, though, someone
had the better idea to create a new name to signify what most people
think C<-len> signifies.  So L<perlapi/C<av_count>> was born.  And we
wish it had been thought up much earlier.

=head2 Writing safer macros

Macros are used extensively in the Perl core for such things as hiding
internal details from the caller, so that it doesn't have to be
concerned about them.  For example, most lines of code don't need to
know if they are running on a threaded versus unthreaded perl.  That
detail is automatically mostly hidden.

It is often better to use an inline function instead of a macro.  They
are immune to name collisions with the caller, and don't magnify
problems when called with parameters that are expressions with side
effects.  There was a time when one might choose a macro over an inline
function because compiler support for inline functions was quite
limited.  Some only would actually only inline the first two or three
encountered in a compilation.  But those days are long gone, and inline
functions are fully supported in modern compilers.

Nevertheless, there are situations where a function won't do, and a
macro is required.  One example is when a parameter can be any of
several types.  A function has to be declared with a single explicit

Or maybe the code involved is so trivial that a function would be just
complicating overkill, such as when the macro simply creates a mnemonic
name for some constant value.

If you do choose to use a non-trivial macro, be aware that there are
several avoidable pitfalls that can occur.  Keep in mind that a macro
is expanded within the lexical context of each place in the source it
is called.  If you have a token C<foo> in the macro and the source
happens also to have C<foo>, the meaning of the macro's C<foo> will
become that of the caller's.  Sometimes that is exactly the behavior
you want, but be aware that this tends to be confusing later on.  It
effectively turns C<foo> into a reserved word for any code that calls
the macro, and this fact is usually not documented nor considered.  It
is safer to pass C<foo> as a parameter, so that C<foo> remains freely
available to the caller and the macro interface is explicitly
specified.

Worse is when the equivalence between the two C<foo>'s is coincidental.
Suppose for example, that the macro declares a variable

 int foo

That works fine as long as the caller doesn't define the string C<foo>
in some way.  And it might not be until years later that someone comes
along with an instance where C<foo> is used.  For example a future
caller could do this:

 #define foo  bar

Then that declaration of C<foo> in the macro suddenly becomes

 int bar

That could mean that something completely different happens than
intended.  It is hard to debug; the macro and call may not even be in
the same file, so it would require some digging and gnashing of teeth
to figure out.

Therefore, if a macro does use variables, their names should be such
that it is very unlikely that they would collide with any caller, now
or forever.  One way to do that, now being used in the perl source, is
to include the name of the macro itself as part of the name of each
variable in the macro.  Suppose the macro is named C<SvPV>  Then we
could have

 int foo_svpv_ = 0;

This is harder to read than plain C<foo>, but it is pretty much
guaranteed that a caller will never naively use C<foo_svpv_> (and run
into problems).  (The lowercasing makes it clearer that this is a
variable, but assumes that there won't be two elements whose names
differ only in the case of their letters.)  The trailing underscore
makes it even more unlikely to clash, as those, by convention, signify
a private variable name.  (See L</Choosing legal symbol names> for
restrictions on what names you can use.)

This kind of name collision doesn't happen with the macro's formal
parameters, so they don't need to have complicated names.  But there
are pitfalls when a a parameter is an expression, or has some Perl
magic attached.  When calling a function, C will evaluate the parameter
once, and pass the result to the function.  But when calling a macro,
the parameter is copied as-is by the C preprocessor to each instance
inside the macro.  This means that when evaluating a parameter having
side effects, the function and macro results differ.  This is
particularly fraught when a parameter has overload magic, say it is a
tied variable that reads the next line in a file upon each evaluation.
Having it read multiple lines per call is probably not what the caller
intended.  If a macro refers to a potentially overloadable parameter
more than once, it should first make a copy and then use that copy the
rest of the time. There are macros in the perl core that violate this,
